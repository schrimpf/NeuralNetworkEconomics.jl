{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title       : \"Multiple Layer Networks\" \n",
    "subtitle    : \"\"\n",
    "author      : Paul Schrimpf\n",
    "date        : `j using Dates; print(Dates.today())`\n",
    "bibliography: \"../ml.bib\"\n",
    "options:\n",
    "      out_width : 100%\n",
    "      wrap : true\n",
    "      fig_width : 800\n",
    "      dpi : 192\n",
    "---\n",
    "\n",
    "[![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution-ShareAlike\n",
    "4.0 International\n",
    "License](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "\n",
    "### About this document \n",
    "\n",
    "This document was created using Weave.jl. The code is available in\n",
    "[on github](https://github.com/schrimpf/NeuralNetworkEconomics.jl). The same\n",
    "document generates both static webpages and associated [jupyter\n",
    "notebook](slp.ipynb). \n",
    "\n",
    "$$\n",
    "\\def\\indep{\\perp\\!\\!\\!\\perp}\n",
    "\\def\\Er{\\mathrm{E}}\n",
    "\\def\\R{\\mathbb{R}}\n",
    "\\def\\En{{\\mathbb{E}_n}}\n",
    "\\def\\Pr{\\mathrm{P}}\n",
    "\\newcommand{\\norm}[1]{\\left\\Vert {#1} \\right\\Vert}\n",
    "\\newcommand{\\abs}[1]{\\left\\vert {#1} \\right\\vert}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/.julia/dev/NeuralNetworkEconomics/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "source": [
    "markdown = try\n",
    "  \"md\" in keys(WEAVE_ARGS) && WEAVE_ARGS[\"md\"]\n",
    "catch\n",
    "  false\n",
    "end\n",
    "\n",
    "if !(\"DISPLAY\" ∈ keys(ENV))\n",
    "  # Make gr and pyplot backends for Plots work without a DISPLAY\n",
    "  ENV[\"GKSwstype\"]=\"nul\"\n",
    "  ENV[\"MPLBACKEND\"]=\"Agg\"\n",
    "end\n",
    "# Make gr backend work with λ and other unicode\n",
    "ENV[\"GKS_ENCODING\"] = \"utf-8\"\n",
    "\n",
    "using NeuralNetworkEconomics\n",
    "docdir = joinpath(dirname(Base.pathof(NeuralNetworkEconomics)), \"..\",\"docs\")\n",
    "\n",
    "using Pkg\n",
    "Pkg.activate(docdir)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[The previous notes](slp.md) discussed single layer neural\n",
    "networks. These notes will look at multiple layer networks.\n",
    "\n",
    "## Additional Reading\n",
    "\n",
    "- @goodfellow2016 [*Deep Learning*](http://www.deeplearningbook.org)\n",
    "- [`Knet.jl`\n",
    "  documentation](https://denizyuret.github.io/Knet.jl/latest/)\n",
    "  especially the textbook\n",
    "- @klok2019 *Statistics with Julia:Fundamentals for Data Science,\n",
    "  MachineLearning and Artificial Intelligence*\n",
    "    \n",
    "  \n",
    "# Multiple Layer Neural Networks\n",
    "\n",
    "- Many hidden layers\n",
    "    - $x^{(0)} = x$\n",
    "    - $x^{(\\ell)}_j = \\psi(a_j^{(\\ell)} x^{(\\ell-1)} + b_j^{(\\ell)})$\n",
    "\n",
    "There is a gap between applied use of neural networks and this\n",
    "statistical theory. These rate results are for networks with a single\n",
    "hidden layer. In prediction applications, the best performance is\n",
    "typically achieved by deep neural networks with many hidden\n",
    "layers. Intuitively, multiple hidden layers should do at least as well\n",
    "as a single hidden layer. \n",
    "\n",
    "There are some recent theoretical results that formalize this intuition.\n",
    "FIXME: ADD CITATIONS.\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Flux, Statistics, ColorSchemes\n",
    "# some function to estimate\n",
    "f(x) = sin(x^x)/2^((x^x-pi/2)/pi)\n",
    "function simulate(n,s=1)\n",
    "  x = rand(n,1).*pi\n",
    "  y = f.(x) .+ randn(n).*s\n",
    "  (x,y)\n",
    "end\n",
    "x, y = simulate(1000, 0.5)\n",
    "xt = reshape(x, 1, length(x))\n",
    "yt = reshape(y, 1, length(y))\n",
    "xg = 0:0.01:pi\n",
    "units = [5, 7, 9]\n",
    "cscheme = colorschemes[:BrBG_4];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Chain(#3, Dense(1, 15, leakyrelu), Dense(15, 1)), 1 iterations, loss=0.46546507\n",
      "Model Chain(#3, Dense(1, 15, leakyrelu), Dense(15, 1)), 60 iterations, loss=0.28682372\n",
      "Model Chain(#3, Dense(1, 15, leakyrelu), Dense(15, 1)), 120 iterations, loss=0.26754394\n",
      "Model Chain(#3, Dense(1, 15, leakyrelu), Dense(15, 1)), 180 iterations, loss=0.26247495\n",
      "Model Chain(#3, Dense(1, 15, leakyrelu), Dense(15, 1)), 240 iterations, loss=0.2610244\n",
      "Model Chain(#3, Dense(1, 15, leakyrelu), Dense(15, 1)), 300 iterations, loss=0.26012135\n",
      "Model Chain(#4, Dense(1, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 1)), 1 iterations, loss=0.70414084\n",
      "Model Chain(#4, Dense(1, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 1)), 60 iterations, loss=0.27061445\n",
      "Model Chain(#4, Dense(1, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 1)), 120 iterations, loss=0.26338327\n",
      "Model Chain(#4, Dense(1, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 1)), 180 iterations, loss=0.26214343\n",
      "Model Chain(#4, Dense(1, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 1)), 240 iterations, loss=0.2614232\n",
      "Model Chain(#4, Dense(1, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3, 1)), 300 iterations, loss=0.26075304\n"
     ]
    }
   ],
   "source": [
    "dimx = 1\n",
    "xt = reshape(Float32.(x), 1, length(x))\n",
    "yt = reshape(Float32.(y), 1, length(y))\n",
    "models = [ Chain(x->Flux.normalise(x, dims=2),\n",
    "                 Dense(dimx, 15, Flux.leakyrelu),\n",
    "                 Dense(15, 1)),\n",
    "           Chain(x->Flux.normalise(x, dims=2),\n",
    "                 Dense(dimx, 3, Flux.leakyrelu),\n",
    "                 Dense(3, 3, Flux.leakyrelu),\n",
    "                 Dense(3, 3, Flux.leakyrelu),\n",
    "                 Dense(3, 1))\n",
    "           ]\n",
    "\n",
    "figs = Array{typeof(plot(0)),1}(undef,length(models))\n",
    "initmfigs = Array{typeof(plot(0)),1}(undef,length(models))\n",
    "\n",
    "for r in eachindex(models)\n",
    "  m = models[r]\n",
    "  initmfigs[r] = plot(xg, Tracker.data(m[1:(end-1)](xg'))', lab=\"\", legend=false)\n",
    "  figs[r]=plot(xg, f.(xg), lab=\"\", title=\"Model $m\", color=:red)\n",
    "  figs[r]=scatter!(x,y, alpha=0.4, markersize=1, markerstrokewidth=0, lab=\"\")\n",
    "  maxiter = 300\n",
    "  for i = 1:maxiter\n",
    "    Flux.train!((x,y)->Flux.mse(m(x),y), Flux.params(m), [(xt, yt)], Flux.AMSGrad() ) #,\n",
    "                #cb = Flux.throttle(()->@show(Flux.mse(m(xt),yt)),100))\n",
    "    if i==1 || (i % (div(maxiter,5))==0)\n",
    "      l=Tracker.data(Flux.mse(m(xt), yt))\n",
    "      println(\"Model $(m), $i iterations, loss=$l\")\n",
    "      yg = Tracker.data(m(xg'))'\n",
    "      loc=Int64.(ceil(length(xg)*i/maxiter))\n",
    "      figs[r]=plot!(xg,yg, lab=\"\", color=get(cscheme, i/maxiter), alpha=1.0,\n",
    "                    annotations=(xg[loc], yg[loc],\n",
    "                                 Plots.text(\"i=$i\", i<maxiter/2 ? :left : :right, pointsize=10,\n",
    "                                            color=get(cscheme, i/maxiter)) )\n",
    "                    )\n",
    "    end\n",
    "  end\n",
    "  #display(figs[r])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
