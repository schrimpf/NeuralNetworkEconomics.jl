<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Recurrent -  </title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">
        <link href="../assets/extra.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href=".."> </a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="..">Package Docs</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">ML in Economics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../ml-intro/">Introduction</a>
</li>
                                    
<li >
    <a href="../ml-methods/">Methods</a>
</li>
                                    
<li >
    <a href="../ml-doubledebiased/">Inference</a>
</li>
                                    
<li >
    <a href="../mlExamplePKH/">Detecting heterogeneity</a>
</li>
                                    
<li >
    <a href="../ml-julia/">With Julia</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Neural Networks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../slp/">Introduction</a>
</li>
                                    
<li >
    <a href="../mlp/">Multi-Layer</a>
</li>
                                    
<li >
    <a href="../conv/">Convolutional</a>
</li>
                                    
<li class="active">
    <a href="./">Recurrent</a>
</li>
                                    
<li >
    <a href="../nn-semiparametric/">In semiparametric models</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../license/">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li >
                                <a rel="next" href="../conv/">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li >
                                <a rel="prev" href="../nn-semiparametric/">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl/edit/master/docs/rnn.md"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#about-this-document">About this document</a></li>
        <li class="main "><a href="#introduction">Introduction</a></li>
            <li><a href="#additional-reading">Additional Reading</a></li>
        <li class="main "><a href="#recurrent-networks">Recurrent Networks</a></li>
            <li><a href="#approximation-ability">Approximation Ability</a></li>
            <li><a href="#stability-and-gradients">Stability and Gradients</a></li>
            <li><a href="#truncating-gradients">Truncating Gradients</a></li>
            <li><a href="#lstm">LSTM</a></li>
        <li class="main "><a href="#example-generating-dylan-songs">Example : Generating Dylan Songs</a></li>
            <li><a href="#downloading-songs">Downloading Songs</a></li>
            <li><a href="#markovian-baseline">Markovian Baseline</a></li>
            <li><a href="#rnn">RNN</a></li>
        <li class="main "><a href="#references-references">References [references]</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h3 id="about-this-document">About this document<a class="headerlink" href="#about-this-document" title="Permanent link">&para;</a></h3>
<p>This document was created using Weave.jl. The code is available in <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl">on
github</a>. The same
document generates both static webpages and associated <a href="../slp.ipynb">jupyter
notebook</a>.</p>
<p>
<script type="math/tex; mode=display">
\def\indep{\perp\!\!\!\perp}
\def\Er{\mathrm{E}}
\def\R{\mathbb{R}}
\def\En{{\mathbb{E}_n}}
\def\Pr{\mathrm{P}}
\newcommand{\norm}[1]{\left\Vert {#1} \right\Vert}
\newcommand{\abs}[1]{\left\vert {#1} \right\vert}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
</script>
</p>
<h1 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h1>
<p>Previous notes have covered <a href="../slp/">single layer</a>, <a href="../mlp/">multi
layer</a>, and <a href="../conv/">convolutional</a> feed forward networks. In
feed forward networks, the outputs of one layer are fed into the next
layer, always moving toward the output. Recurrent networks break this
pattern. In recurrent networks, outputs of one layer are feed back into
the same. This always the network to maintain a hidden state. Recurrent
networks are typically used to model sequential data. There are many
applications to time series. Recurrent networks are also useful for
processing text and audio data.</p>
<h2 id="additional-reading">Additional Reading<a class="headerlink" href="#additional-reading" title="Permanent link">&para;</a></h2>
<ul>
<li>Goodfellow, Bengio, and Courville (<a href="#ref-goodfellow2016">2016</a>)
    <a href="http://www.deeplearningbook.org"><em>Deep Learning</em></a> especially
    chapter 10</li>
<li><a href="https://denizyuret.github.io/Knet.jl/latest/"><code>Knet.jl</code>
    documentation</a>
    especially the textbook</li>
<li>Klok and Nazarathy (<a href="#ref-klok2019">2019</a>) <em>Statistics with
    Julia:Fundamentals for Data Science, MachineLearning and Artificial
    Intelligence</em></li>
</ul>
<h1 id="recurrent-networks">Recurrent Networks<a class="headerlink" href="#recurrent-networks" title="Permanent link">&para;</a></h1>
<p>Recurrent Networks are designed to predict a sequence of outputs, $y_t$,
given a sequence of inputs, $x_t$, where $t=1, &hellip;,T$, The relationship
between $x$ and $y$ is assumed to be stationary, but we will allow there
to be possibly many values from the history of $x$ to affect $y$. We do
this by introducing a hidden state, $h_t$. The prediction for $y_t$ is
only a function of $h_t$, say $\hat{y}(h_t)$. The hidden state is
Markovian with <script type="math/tex; mode=display">
h_t = f(h_{t-1}, x_t).
</script> Both $\hat{y}()$ and $f()$ are constructed from neural networks. They
could simply be single layer perceptrons, or any of the more complicated
network architectures we previously discussed.</p>
<h2 id="approximation-ability">Approximation Ability<a class="headerlink" href="#approximation-ability" title="Permanent link">&para;</a></h2>
<p>Recurrent networks can approximate (in fact can equal) any computable
function. Siegelmann and Sontag (<a href="#ref-siegelmann1991">1991</a>) and
Siegelmann and Sontag (<a href="#ref-siegelmann1992">1992</a>) show that recurrent
neural networks are Turing complete. As with the universal approximation
ability of feed forward networks, this result is good to know, but it is
not an explanation for the good practical performance of recurrent
networks.</p>
<p>When $h_t$ is large enough, it is easy to see how the recurrent model
above can equal familiar time series econometric models. For example,
for an AR(P) model, <script type="math/tex; mode=display">
y_t = \rho_1 y_{t-1} + \cdots + \rho_p y_{t-p} + \epsilon_t 
</script> To express this model in recurrent state-space form, let
$x_t = y_{t-1}$, and $h_t = (y_{t-1, \cdots, y_{t-p}) \in \R^p$. Then we
can set <script type="math/tex; mode=display">
f(h_{t-1}, x_t) = (x_t, h_{t-1,1}, \cdots , h_{t-1, p-1})
</script> and <script type="math/tex; mode=display">
\hat{y}(h_t) = \rho' h_t,
</script>
</p>
<h2 id="stability-and-gradients">Stability and Gradients<a class="headerlink" href="#stability-and-gradients" title="Permanent link">&para;</a></h2>
<p>Recursive neural networks can be difficult to train. The difficulty
stems from how the gradient of the network behaves very differently
depending on whether the dynamics are stable. To illustrute, suppose
$f()$ is linear, <script type="math/tex; mode=display">
h_t = f_h h_{t-1} + f_x x_t
</script> and the loss function is MSE <script type="math/tex; mode=display">
\mathcal{L}(f_h,f_x) = \frac{1}{T} \sum_{t=1}^T (\hat{y}(h_t)- y_t)^2
</script> The derivatives of the loss function with respect to the parameters
of $f$ are then: <script type="math/tex; mode=display">
\begin{align*}
\frac{\partial}{\partial f_h} & = \frac{2}{T} \sum (\hat{y}(h_t)-
y_t)\hat{y}'(h_t) \left(t f_h^{t-1} h_0 + \sum_{s=1}^{t-1}
(t-s)f_h^{t-s-1} f_x x_{t-s} \right) \\
\frac{\partial}{\partial f_x} & = \frac{2}{T} \sum (\hat{y}(h_t)- y_t) 
    \hat{y}'(h_t) 
    \left(\sum_{s=1}^{t} x_s f_h^{t-s} \right)
\end{align*}
</script> Both of these involve increasing powers of $f_h^t$. If $h_t$ has
stable dynamics, i.e. $|f_h|&lt;1$, then these derivatives will be
dominated by the terms involving more recent values of $x_t$. If $h_t$
has explosive dynamics, $|f_h|&gt;1$, then these derivatives will be
dominated by the terms involving the earlist $x_t$. Depending on the
stability of $f$, gradients will be dominated by either short term
dependence between $x$ and $y$ or long term. This behavior makes it
difficult to train a network where both short and long term dependencies
are important.</p>
<p>The previous analysis also apply to nonlinear $f()$, with $f_h$ replaced
by $(\partial f)/(\partial h)$, and stable replaced with locally stable.</p>
<p>The previous analysis also applies to multivariate $h_t$ with $|f_h|$
replace by $\max |eigenvalue(f_h)|$.</p>
<h2 id="truncating-gradients">Truncating Gradients<a class="headerlink" href="#truncating-gradients" title="Permanent link">&para;</a></h2>
<p>A practical problem with gradients of recurrent networks is that
$\hat{y}(h_t)$ depends on the entire history of $x_1, \cdots, x_t$. When
computing the gradient by backward differentiation, this entire history
will accumulate, using up memory and taking time. A common solution is
to truncate the gradient calculation after some fixed number of periods.</p>
<h2 id="lstm">LSTM<a class="headerlink" href="#lstm" title="Permanent link">&para;</a></h2>
<p>Long Short-Term Memory networks were designed to avoid the problem of
vanishing and exploding gradients. LSTMs have an additional hiddent
state, $s_t$. The extra hidden state is $s_t \in (0,1)$ and is a
weighted sum of $s_{t-1}$ and other variables. In particular, <script type="math/tex; mode=display">
 s_t = \sigma(b_f + U_f' x_t + W_f' h_{t-1}) s_{t-1} + \sigma(b_g + U_g'
 x_t + W_g' h_{t-1}) \tilde{x}_t 
</script> The first $\sigma(b_f + U_f&rsquo; x_t + W_f&rsquo; h_{t-1})$ is a “forget” gate.
It determines how much of $s_{t-1}$ is forgotten. The second
$\sigma(b_g + U_g&rsquo; x_t + W_g&rsquo; h_{t-1})$ is call the external input gate.
It determines how much current $x_t$ affects $s_t$. The $\tilde{x}$ is a
rescaled input given by <script type="math/tex; mode=display">
\tilde{x}_t = \sigma(\tilde{b} + \tilde{U}'x_t + \tilde{W}' h_{t-1}).
</script> Finally, $h_t$ is a gated and transformed version of $s_t$. <script type="math/tex; mode=display"> 
h_t = tanh(s_t) \sigma(b_o + U_o' x_t + W_o'h_t)
</script> where $\sigma(b_o + U_o&rsquo; x_t + W_o&rsquo;h_t)$ is the output gate.</p>
<h1 id="example-generating-dylan-songs">Example : Generating Dylan Songs<a class="headerlink" href="#example-generating-dylan-songs" title="Permanent link">&para;</a></h1>
<p>Recurrent neural networks are pretty good at randomly generating text.
The <a href="https://github.com/FluxML/model-zoo/blob/master/text/char-rnn/char-rnn.jl">Flux model
zoo</a>
includes one such example. The example is based on this <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">blog post by
Andrej
Karpathy</a>. It
predicts each individual character given past characters. This works
suprisingly well. We are going to repeat this exercise, but use Bob
Dylan songs as input.</p>
<h2 id="downloading-songs">Downloading Songs<a class="headerlink" href="#downloading-songs" title="Permanent link">&para;</a></h2>
<p>We download all Bob Dylan lyrics and chords from
<a href="http://dylanchords.info">dylanchords.info</a>.</p>
<pre><code class="julia">using ProgressMeter, JLD2
import HTTP, Gumbo, Cascadia

infile = joinpath(docdir,&quot;jmd&quot;,&quot;dylanchords.txt&quot;)

if !isfile(infile)
  r=HTTP.get(&quot;http://dylanchords.info/alphabetical_list_of_songs.htm&quot;)
  songlist=Gumbo.parsehtml(String(r.body));
  songlinks = eachmatch(Selector(&quot;.songlink&quot;), songlist.root)
  songhtml = Array{String, 1}(undef, length(songlinks))
  p = Progress(length(songlinks),1,&quot;Downloading songs&quot;, 50)
  for s ∈ eachindex(songlinks)
    url = songlinks[s].attributes[&quot;href&quot;]
    if url == &quot;index.htm&quot;
      songhtml[s] = &quot;&quot;
      continue
    end
    r = HTTP.get(&quot;http://dylanchords.info/&quot;*url)
    songhtml[s]=String(r.body)
    next!(p)
  end

  open(infile, &quot;w&quot;) do io
    for s ∈ songhtml
      write(io, s)
      write(io,&quot;\n&quot;)
    end
  end  
end

text = collect(String(read(infile)))
</code></pre>

<pre><code>2873103-element Array{Char,1}:
 '\n'
 '&lt;' 
 '?' 
 'x' 
 'm' 
 'l' 
 ' ' 
 'v' 
 'e' 
 'r' 
 ⋮   
 '&lt;' 
 '/' 
 'h' 
 't' 
 'm' 
 'l' 
 '&gt;' 
 '\n'
 '\n'
</code></pre>
<p>Note that the input text here are html files. Here is the start of one
song.</p>
<pre><code>&lt;head&gt;
&lt;title&gt;My Back Pages&lt;/title&gt;
&lt;link rel="stylesheet" type="text/css" href="../css/general.css" /&gt;
&lt;/head&gt;

&lt;body&gt;

&lt;h1 class="songtitle"&gt;My Back Pages&lt;/h1&gt;


&lt;p&gt;Words and music Bob Dylan&lt;br /&gt;
Released on &lt;a class="recordlink" href="../04_anotherside/index.htm"&gt;Another Side Of Bob Dylan&lt;/a&gt; (1964) and &lt;a class="recordlink" href="../99_greatesthits2/index.htm"&gt;Greatest Hits II&lt;/a&gt; (1971)&lt;br /&gt;
Tabbed by Eyolf &amp;Oslash;strem&lt;/p&gt;

&lt;p&gt;Most G's are played with a small figure (G - G6 - G7) going up to G7:&lt;/p&gt;
&lt;pre class="chords"&gt;
G  320003
G6 322003
G7 323003
&lt;/pre&gt;

&lt;p&gt;This is noted with a *).&lt;/p&gt;

&lt;p&gt;He didn't seem to spend too much time rehearsing this song before he
went into the studio (the whole album was recorded in one
evening/night session) &amp;ndash; he gets the first verse all wrong in the
chords, and he struggles a lot with the final lines of each
verse. I've written out the chords for the first two verses and in the
following verses deviations from the &lt;em&gt;second&lt;/em&gt; verse.&lt;/p&gt;

&lt;p&gt;Capo 3rd fret (original key Eb major)&lt;/p&gt;

&lt;hr /&gt;

&lt;pre class="verse"&gt;
C       Am          Em
Crimson flames tied through my ears
        F        G *)   C
Rollin' high and mighty traps
C            Am      Em      C
Pounced with fire on flaming roads
      F     Em    G   *)
Using ideas as my maps
       F       Am     G *)        C
&amp;quot;We'll meet on edges, soon,&amp;quot; said I
Am                  F G
Proud 'neath heated brow
        C             Am    C
Ah, but I was so much older then
    F       G *)      C       G *)
I'm younger than that now.
</code></pre>
<p>Some songs include snippets of tablature (simple notation for guitar).
For example,</p>
<pre><code>&lt;p&gt;The easiest way to play the G7sus4 G7 G7sus2 G7 figure would be:&lt;/p&gt;
&lt;pre class="verse"&gt;
G7sus4  G7  G7sus2  G7
|-1-----1-----1-----1---
|-0-----0-----0-----0---
|-0-----0-----0-----0---
|-0-----0-----0-----0---
|-3-----2-----0-----2---
|-3-----3-----3-----3---
&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Intro:&lt;/p&gt;
&lt;pre class="tab"&gt;
  C           G/b           F/a         G11   G       C/e
  :     .       :     .       :     .       :     .        :     .
|-------0-----|-------3-----|-------1-----|--------------|-------0------
|-----1---1---|-----0-------|-----1-1---1-|---1---010----|-----1---1----
|---0-------0-|---0-----0---|---2-----1---|-2---2----0---|---0-------0-- etc
|-------------|-------------|-------------|------------3-|-2------------
|-3-----------|-2---------2-|-0-----------|--------------|--------------
|-------------|-------------|-------------|-3------------|--------------
&lt;/pre&gt;
</code></pre>
<p>This is all just text, and we will treat it is a such. However, it has
additional structure that makes it more interesting to predict than the
text of just lyrics.</p>
<h2 id="markovian-baseline">Markovian Baseline<a class="headerlink" href="#markovian-baseline" title="Permanent link">&para;</a></h2>
<p>As <a href="https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139">Yoav Goldberg point
out</a>, you
can generate pretty good text with a simple Markovian model of
characters. That is, estimate the probability of a character $c$ given a
history of $L$ characters $h$, $P(c_t|c_{t-1}, &hellip;, c_{t-L})$, by simple
sample averages. Let’s try this out.</p>
<pre><code class="julia">using StaticArrays

function p_markov(len::Val{L}, data::AbstractVector{Char}) where L
  dm = Dict{SVector{L, Char}, Dict{Char, Float64}}()
  p = Progress(length(data), 1, &quot;count_markov($L)&quot;, 30)
  for t in (1+L):length(data)
    key = @view data[(t-L):(t-1)]
    entry=get!(dm, key, Dict(data[t] =&gt; 0))
    v = get!(entry, data[t], 0)
    entry[data[t]] += 1
    next!(p)
  end
  for k in keys(dm)
    total = sum(values(dm[k]))
    for e in keys(dm[k])
      dm[k][e] /= total
    end
  end
  dm
end

modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;dylan-markov4.jld2&quot;)
if isfile(modelfile)
  @load modelfile dm
else 
  @time dm = p_markov(Val(4), text);
  @save modelfile dm    
end
</code></pre>

<pre><code>1-element Array{Symbol,1}:
 :dm
</code></pre>
<p>The above code stores $P(c_t|c_{t-1},&hellip;,c_{t-L})$ in a dictionary. When
$L$ is large, there are huge number of possible histories,
$c_{t-1},&hellip;,c_{t-L}$, and we will not observe many of them. A
dictionary only stores data on the histories we observe, so it will save
some memory.</p>
<p>Let’s now sample from our model.</p>
<pre><code class="julia">defaultinit=collect(&quot;\n\n&lt;?xml version=\&quot;1.0\&quot; encoding=\&quot;UTF-8\&quot;?&gt;\n&lt;!DOCTYPE html PUBLIC \&quot;-//W3C//DTD XHTML 1.0 Strict//EN\&quot;\n\&quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\&quot;&gt;\n&lt;html lang=\&quot;en\&quot; xml:lang=\&quot;en\&quot; xmlns=\&quot;http://www.w3.org/1999/xhtml\&quot;&gt;\n\n&lt;head&gt;\n&lt;title&gt;&quot;)

function sample_markov(dm::Dict{SVector{L, Char}, Dict{Char, Float64}}, len=1000,
                       init=defaultinit) where L
  out = Array{Char,1}(undef,len)
  state = MVector{L, Char}(init[(end-L+1):end])
  out[1:L] .= state
  for s=L+1:len
    u = rand()
    cp = 0.0
    for k in keys(dm[state])
      cp += dm[state][k]
      if (u&lt;= cp)
        out[s]=k
        break
      end
    end
    state[1:(end-1)] .= state[2:end]
    state[end] = out[s]    
  end
  out
end

@show length(dm), length(text)
</code></pre>

<pre><code>(length(dm), length(text)) = (88032, 2873103)
</code></pre>
<pre><code class="julia">println(String(sample_markov(dm)))
</code></pre>

<pre><code>tle&gt;
&lt;link rel="stylesheet" type="text/css" /&gt;
Three,
We'll away friend admit to leave you nearer hangin'.
But to that underneat was and the end sackson that down open with
a verse"&gt;
F . Got to be gone, Jane&lt;/h1&gt;


&lt;pre class="verse]
&lt;/pre&gt;

&lt;hr /&gt;
&lt;/body&gt;&lt;/html&gt;

&lt;h1 class="tab"&gt;
**)     F
I didn't got about a
                                       C
How'd ya little shotgun
I'm a-grieve?
Who's bound on the &lt;a class="verse he want again, he'd just to despecial as
 time her me.
I don't sand Band was a different out, with young.
&lt;/pre&gt;
&lt;link"
href="index.htm"&gt;The fly
       D
 You&lt;/title"&gt;Together I misdemeant to grieves a man always he doubt it ain'
s driv' pass been heard swap me and
&amp;ldquo;&lt;br /&gt;
Lyrics tream, in my love.&lt;br /&gt;

&lt;table slave
   |-0---------------------|-0------------|------|-1---13-13-13-|--------|
&lt;/pre&gt;
&lt;pre class="version="1.0" encoding of Heavy to man's sends thes all.
&lt;/pre&gt;
&lt;/body&gt;

&lt;pre class="tab"&gt;
|: B                   three chords:&lt;/p&gt;

&lt;pre class="tab"&gt;
All
</code></pre>
<p>Conditioning on histories of length 4, we get some hints of Dylan-esque
lyrics, but we also get a lot of gibberish. Let’s try longer histories.</p>
<h3 id="length-10">Length 10<a class="headerlink" href="#length-10" title="Permanent link">&para;</a></h3>
<pre><code class="julia">modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;dylan-markov10.jld2&quot;)
if isfile(modelfile)
  @load modelfile dm
else 
  @time dm = p_markov(Val(10), text);
  @save modelfile dm    
end
@show length(dm), length(text)
</code></pre>

<pre><code>(length(dm), length(text)) = (930264, 2873103)
</code></pre>
<pre><code class="julia">println(String(sample_markov(dm)))
</code></pre>

<pre><code>d&gt;
&lt;title&gt;North Country Blues&lt;/h1&gt;

&lt;p&gt;Written by E. Dodd&lt;br /&gt;
Recorded for &lt;a href="im_not_there_lyrics.htm"&gt;different you see.
I dreamt that the other early tapes, to my ears.&lt;/pre&gt;
&lt;pre class="verse"&gt;
To begin the moral of the street
With my hands have got your brand new leopard-skin pill-box hat

Well, I see you got your thigh.&amp;quot;
&lt;/pre&gt;

&lt;p&gt;Robbie: &amp;ldquo;Wait a minute before you call me any name you like to go
   C                                       holler
&lt;/pre&gt;
&lt;pre class="verse"&gt;
He died on the &amp;ldquo;A&amp;rdquo;
character somewhere
(which again has taken some &amp;ldquo;it's a gold mining fever baby, which is 
a little humility and splendor on the 4th string (I've indicated with &amp;ldqu
o;x&amp;rdquo;) or open
strings.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Dylan's guitar part" ("Very
funky. Ah, it's not said by the way things something there of thirst
     C       G
Before I go.
&lt;/pre&gt;

&lt;pre class="verse"&gt;
The cat's in the third fret (sounding key
Bb major). During the sessions (summer 1967&lt;br /&gt;
Lyrics f
</code></pre>
<h3 id="length-20">Length 20<a class="headerlink" href="#length-20" title="Permanent link">&para;</a></h3>
<pre><code class="julia">modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;dylan-markov10.jld2&quot;)
if isfile(modelfile)
  @load modelfile dm
else 
  @time dm = p_markov(Val(20), text);
  @save modelfile dm  
end
@show length(dm), length(text)
</code></pre>

<pre><code>(length(dm), length(text)) = (930264, 2873103)
</code></pre>
<pre><code class="julia">println(String(sample_markov(dm, 2000)))
</code></pre>

<pre><code>d&gt;
&lt;title&gt;Long Ago, Far Away&lt;/h1&gt;


&lt;p&gt;Written by Bob Dylan and the moon above.&lt;br /&gt;
    Nothing you need, you might even cry, you never mentioned that Dylan ha
s left this whole town afraid
From now on you'd best get on board
I'm sitting on my watch
         Dm/a                  D                       C
 I just can't keep track of it no more.
Well, I wake up in the sky,
It's been so strong
And there's not many men that've done the opposite loft
   C                                                        D/a    A
   You can always lose a little too simple, but he's daily growin'
&lt;/pre&gt;
&lt;pre class="tab"&gt;
|-------------------------|----
|/4-----4---|-2---
|-3------------------------------|
|--------------------------|------------|-2-------------------|------------
----------2--0---0---0--------------|
|------------------------|
|(2)----------------|----------------|
|---------------|----------------|-----------------||
|---------------------|------------||
|-------------|----------------|----0-----0---0----------|
|-5-3-5--------------------||--1---1-1-|-1-1-1-1-0---
|-----------|------------------|----------------|
|-------------------------||
|----------||
|-3---------------------------1-|---3---------|--------------|
|----8-----8---------|-----------------0-------|-------------7-6-----6-|
|-4---6-----------
|------------------------5-------|-4-----2---0-------|-1-------------------
---------------------|
&lt;/pre&gt;
&lt;pre class="bridge"&gt;
[Joanie, who remember that movie just a little upside down, as a matter of 
fact the wheel's still in spin
And then i took over the Rockies,&lt;br /&gt;
    He's got a hold of my sweethearts and the room,
Doomed and it can perfectly playable.&lt;/p&gt;

&lt;pre class="verse"&gt;
  G             G       [lick 1]
I'm seeing this simple phrase, 
To kids from one to ninety-two, 
Although it all that should the wedding of his son.
Long ago, far away at sea

&amp;quot;I think I've had the best
Baby, won't you meet me
Cm7-5        Eb  F  Eb
Something There Is About Y
</code></pre>
<p>With histories of length 20 the text looks pretty. Some of the lyrics
are recognizably Dylan-like. However, the model still gets html tags
mostly wrong. More importantly, the model is effectively just combining
phrases of Dylan lyrics randomly. The data here consists of nearly 2.9
million characters. Among these, there are 1.5 million unique sequences
of 20 characters. Many of the estimated $P(c_t|c_{t-1}, &hellip;)$ are equal
to one.</p>
<h2 id="rnn">RNN<a class="headerlink" href="#rnn" title="Permanent link">&para;</a></h2>
<p>Now let’s fit a recurrent neural network to the Dylan lyrics and chords
data.</p>
<pre><code class="julia">using Flux
using Flux: onehot, chunk, batchseq, throttle, crossentropy
using StatsBase: wsample
using Base.Iterators: partition
using ProgressMeter

text = collect(String(read(joinpath(docdir,&quot;jmd&quot;,&quot;dylanchords.txt&quot;))))
endchar = 'Ω' # any character not in original text
alphabet = [unique(text)..., endchar]
hottext = map(ch -&gt; onehot(ch, alphabet), text)
stop = onehot(endchar, alphabet)

N = length(alphabet)
seqlen = 50
batchsize = 50

Xseq = gpu.(batchseq(chunk(hottext,seqlen),stop));
Yseq = gpu.(batchseq(chunk(hottext[2:end], seqlen),stop));
data = [(Xseq[p], Yseq[p]) for p in partition(1:length(Xseq), batchsize)];
</code></pre>

<p>To reduce computation while training the model, we are going to use
gradient truncation. <code>seqlen</code> is the length of history through which
gradients are accumulated.</p>
<p>We also divide the data into batches for gradient descent. <code>batchsize</code>
is the number of <code>seqlen</code> sequences per batch used for gradient descent.
Each batch will have <code>seqlen * batchsize</code> observations.</p>
<pre><code class="julia"># Sampling

function sample(m, alphabet, len)
  m = cpu(m)
  Flux.reset!(m)
  buf = IOBuffer()
  c = rand(alphabet)
  for i = 1:len
    write(buf, c)
    c = wsample(alphabet, m(onehot(c, alphabet)).data)
  end
  return String(take!(buf))
end

opt = RMSProp(0.005)
# this will take awhile, so a fancier call back with a progress meter is nice to have 
function cbgenerator(N, loss, printiter=Int(round(N/10)))
  p = Progress(N, 1, &quot;Training&quot;, 25)
  i=0
  function cb()
    next!(p)
    if (i % printiter==0)
      @show loss()
    end
    i+=1
  end
  return(cb)
end

function train_model(L; N=N, data=data,
                     modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;dylan-$L.jld2&quot;),
                     opt=opt )
  m = Chain(LSTM(N, L), LSTM(L, L),  Dense(L, N),  softmax) |&gt; gpu
  function loss(xb::V, yb::V) where V&lt;:AbstractVector
    l = sum(crossentropy.(m.(xb),yb))/length(xb)
    Flux.truncate!(m)
    return(l)
  end
  cb=cbgenerator(length(data),()-&gt;loss(data[5]...))

  if isfile(modelfile)
    @load modelfile cpum
    m = gpu(cpum)
  else 
    @time Flux.train!(loss, Flux.params(m), data, opt, cb = cb)
    println(&quot;Sampling after 1 epoch:&quot;)
    sample(m, alphabet, 1000) |&gt; println

    Flux.@epochs 10 Flux.train!(loss, Flux.params(m), data, opt,
                                cb = cbgenerator(length(data),()-&gt;loss(tx,ty)))
    cpum = cpu(m)
    @save modelfile cpum
  end
  return(m)
end

for L in [32, 64, 128] #, 256, 512]
  m = train_model(L)
  println(&quot;Model $L has $(sum([prod(size(p)) for p in Flux.params(m)])) parameters&quot;)  
  println(&quot;Sample from model $L&quot;)
  println(&quot;--------------------&quot;)
  println(sample(m, alphabet, 2000))
  println()
end
</code></pre>

<pre><code>Model 32 has 28933 parameters
Sample from model 32
--------------------
Kge. of the man becwy name. is lumbe
But and walkin' Minvin', my one pllacs inside
You'ulf. I called.&lt;br /&gt;
   2x4444
      |-------------3---|-5---|
|---------0---------|-----0-|-2-----3-1-1-1---3-|
|-1---6---------------|-8
----3-|-----------------|-3-----------|-3----3---3---|
|---------3----|-0-------2--|-------------|
||Iuf *) Cancomaquin' body
Alling medolin', not be just so a as too to fliss,
Savey let or cloby
  G         F      /d         Em9  C              C
Jinve that the hillin', throng wegan worn in her and the corre with so char
itel
I have barus gate to blook.
Can't get caughts back, layd eyes
C                  C                             G
But mamas, world worned arlied In or cannay dark Suder bring.
Wight paft
|-t9-----9-------|-------------------------|-------------------------|-----
----/3-------4-----|
|-3-----------3-----3-|---------------|
|-----------------|-0-----------------------
|-7----------------|-----------------|-3---------------|----------------|
|F-----------------|-0---------------|-0---0-----3-3-3-|-1-1-1-1-1-1-
&lt;/pre&gt;

&lt;pre class="refrain"&gt;
And this my octic''ll what where your hills
At the doboning on,
Night with you are chore,
Yonded kind 
I cover alleandie on theinz's deppuning whole,
        C
why lifk the d&amp;nshat/eseercsss""&gt;

&lt;hr /&gt;

&lt;h2 class="songversion"&gt;Tapo:&lt;lin&gt;
  &lt;/p&gt;

&lt;p&gt;There you any hand one bringed Bllown only loogarbys my standin' (B7)
play Lide was on,sh by is mople life,
                G  A
And sky late whosow, ducklit cord,
To water my sve's with is for say.

Iller you so fisshin' that tell do?
Well,
To the long of coonf saul rollows of miste and free,
But wither only splay:           F
And croad of my phrand, mothing?&amp;rdquo;&lt;br /&gt;
        A Em
I'll would how he mad, his belic, 4t, and this by soly C with old a rille? 
E7sus4         3) 313 handin' on how two.&lt;/p&gt;

&lt;p&gt;Autro parpeling you ever man
Every rath, you're all your churle you'll get you.

Well.&lt;br /&gt;
  Men blown&lt;br /&gt;
Tabbed by Eyolf &amp;Oslash;strem a

Model 64 has 82341 parameters
Sample from model 64
--------------------
”            :
&lt;/pre&gt;

&lt;pre class="bridge"&gt;
   C       F       C
Hard on Cannampersus no
Sin
                    A                         D    E
This next then we varior,
My sounds a-loves that dlong
&lt;/pre&gt;
&lt;pre class="verse"&gt;
A                                                   #&amp;quoqu;
Just a next fal of a take mighty forms fire.

The blooming hislive or Lord??
&lt;/pre&gt;

&lt;pre class="sonnoincon"&gt;ried but only into the love, off
       |-0---0-----0----       |-------------|-1-----------|--------------|
         | verses, song
     :   .   .   .
  .        .     .
Won'lict grown through the line, the baltor, was well

I ain't go on Blueny
&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;-------------|------------------------|-3------3-------------------|
|-------------------|---------------------|
|-------------0p0--0---0---|------------|
|-333-------------|-----------------|---3-------0-------|
---0-|--2-2-2---2-|-0-------2p0--0---0---0---|-2/5-------5-----1-|
|--------------------|------2---2--|
|-1-----9-----9---|-7----------------|-----------------|---5-------------|-
----------------||
||---------------p-|
|-----------------|---------|----------------|------------------|
|-------------3---|-----------------|-----------------|-----------------   
  |-----------0--0--|
|------4--22-|-------------|------|---------
-3-----|-7---5-----4--------|-4------------------|
-5---|-------2---2-----------|---------------------------|
|------------------------------|
|-----------------|------7------|-8-----------------|-----------------|----
--------|----------3------|
|-------------7---|------------------|------------|-----------7-|-7---7----
0---0-|---------
||------------------|
|------0----------|-----------------|
||-------------|-----------------|-----------------|---4-------------|x3-0-
------|
|-6-------------|-------------3---|-5-----5.|---------------|--------------
---|
|-----7---7---5---|-----------------|-----------------|
          .     :   .   .   .     :   .   .   .     :   .   .
|-6---3----------

Model 128 has 262885 parameters
Sample from model 128
--------------------
\peppet Danim.&lt;/p&gt;

&lt;pre&gt;Rolling through 4stricf strings (or an Em7-cli=1)&lt;/a&gt;:/ub E7 on the Fs
. Twurl, it electres, in the note,
Uce on the fulf have played with various content here
would for home
in some resliff.&lt;/p&gt;

&lt;p&gt;Cadd by Dylan from Lave Darkanal Rancional.&lt;/p&gt;

&lt;hr /&gt;

&lt;pre class="verse"&gt;
                   G         A           C/g G
When too too hord pousiled
C#m     D#m                    C#7
Al I'm looking into
                        repeat
             -                                diffe?
                          baby Dylan and weary the
someone my dog there. 
&lt;/pre&gt;
&lt;/bodyyal let reblie (1002)&lt;/h2&gt;

&lt;pre class="verse"&gt;
C
    Condiah surdin
            G     D   Csus4   C
Visin' in the years of Fame of Hann.
       F    C
We knew in A man and small was no sleakes
    Gm/d         C     D
  Yon her name is fallowain
        C                 G [wind]
I'll still buy it hard to crash
Your official pulled, drivin' it tryin'
And aimplin' so lot and mighty
Slow empre who are mody,
Where may your fightfue the water
All your Grays set and ane froat
Jesus glowly loud eyes
These grow me to answer anyther

Honeys flow it,
Walkin', says her whill offeat for
I.gre better say, I can't lead you ready by your heart.
&lt;/pre&gt;
&lt;pre class="verse"&gt;
Well, she's that softle, show and me not only very mama, you been wondin' b
efore.
But this too far away.
&lt;/pre&gt;
&lt;/bodyyal lef be about Roser&lt;br /&gt;
Tabbed by Eyolf &amp;Oslash;strem&lt;/p&gt;

&lt;hr /&gt;

&lt;pre class="verse"&gt;
(Dmaj7     2 fellow) light to sings
May, but for g. and game
I swear on your dram and percesteds
All about what the lighttin' one queens sun
Broweds my oet are take us,
I wanna tune.
If so filled, my love
Well, the lonesome grind an' show,
Take all trapped breaks, a-alonotin' blow
From Many cloud the Lord, fast one, just gonna wrate
He askin' oper me
She's breaks off
Ev'ry lonery's sailor for every walk is
To quit my real
City we must be thiney

Now, Mary Lan's go deep it be croon.
   G
wor contend only and drivesary
</code></pre>
<h1 id="references-references">References [references]<a class="headerlink" href="#references-references" title="Permanent link">&para;</a></h1>
<div class="references" id="refs">
<div id="ref-goodfellow2016">
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep
Learning</em>. MIT Press. <a href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a>.</p>
</div>
<div id="ref-klok2019">
<p>Klok, Hayden, and Yoni Nazarathy. 2019. <em>Statistics with
Julia:Fundamentals for Data Science, Machinelearning and Artificial
Intelligence</em>. DRAFT.
<a href="https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf">https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf</a>.</p>
</div>
<div id="ref-siegelmann1991">
<p>Siegelmann, Hava T., and Eduardo D. Sontag. 1991. “Turing Computability
with Neural Nets.” <em>Applied Mathematics Letters</em> 4 (6): 77–80.
<a href="https://doi.org/https://doi.org/10.1016/0893-9659(91)90080-F">https://doi.org/https://doi.org/10.1016/0893-9659(91)90080-F</a>.</p>
</div>
<div id="ref-siegelmann1992">
<p>———. 1992. “On the Computational Power of Neural Nets.” In <em>Proceedings
of the Fifth Annual Workshop on Computational Learning Theory</em>, 440–49.
COLT ’92. New York, NY, USA: ACM.
<a href="https://doi.org/10.1145/130385.130432">https://doi.org/10.1145/130385.130432</a>.</p>
</div>
</div></div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
