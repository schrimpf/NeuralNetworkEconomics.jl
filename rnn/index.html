<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Recurrent -  </title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">
        <link href="../assets/extra.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href=".."> </a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Package Docs</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">ML in Economics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../ml-intro/" class="dropdown-item">Introduction</a>
</li>
                                    
<li>
    <a href="../ml-methods/" class="dropdown-item">Methods</a>
</li>
                                    
<li>
    <a href="../ml-doubledebiased/" class="dropdown-item">Inference</a>
</li>
                                    
<li>
    <a href="../mlExamplePKH/" class="dropdown-item">Detecting heterogeneity</a>
</li>
                                    
<li>
    <a href="../ml-julia/" class="dropdown-item">With Julia</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Neural Networks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../slp/" class="dropdown-item">Introduction</a>
</li>
                                    
<li>
    <a href="../mlp/" class="dropdown-item">Multi-Layer</a>
</li>
                                    
<li>
    <a href="../conv/" class="dropdown-item">Convolutional</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">Recurrent</a>
</li>
                                    
<li>
    <a href="../transformers/" class="dropdown-item">Transformers</a>
</li>
                                    
<li>
    <a href="../nn-semiparametric/" class="dropdown-item">In semiparametric models</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../license/" class="dropdown-item">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../conv/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../transformers/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl/edit/master/docs/rnn.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            
            <li class="nav-item" data-level="1"><a href="#introduction" class="nav-link">Introduction</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#additional-reading" class="nav-link">Additional Reading</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#recurrent-networks" class="nav-link">Recurrent Networks</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#approximation-ability" class="nav-link">Approximation Ability</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#stability-and-gradients" class="nav-link">Stability and Gradients</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#truncating-gradients" class="nav-link">Truncating Gradients</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#lstm" class="nav-link">LSTM</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#example-generating-dylan-songs" class="nav-link">Example : Generating Dylan Songs</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#downloading-songs" class="nav-link">Downloading Songs</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#markovian-baseline" class="nav-link">Markovian Baseline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#rnn" class="nav-link">RNN</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#references" class="nav-link">References</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h3 id="about-this-document">About this document<a class="headerlink" href="#about-this-document" title="Permanent link">&para;</a></h3>
<p>This document was created using Weave.jl. The code is available in <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl">on
github</a>. The same
document generates both static webpages and associated <a href="../rnn.ipynb">jupyter
notebook</a>.</p>
<p>
<script type="math/tex; mode=display">
\def\indep{\perp\!\!\!\perp}
\def\Er{\mathrm{E}}
\def\R{\mathbb{R}}
\def\En{{\mathbb{E}_n}}
\def\Pr{\mathrm{P}}
\newcommand{\norm}[1]{\left\Vert {#1} \right\Vert}
\newcommand{\abs}[1]{\left\vert {#1} \right\vert}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
</script>
</p>
<h1 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h1>
<p>Previous notes have covered <a href="../slp/">single layer</a>, <a href="../mlp/">multi
layer</a>, and <a href="../conv/">convolutional</a> feed forward networks. In
feed forward networks, the outputs of one layer are fed into the next
layer, always moving toward the output. Recurrent networks break this
pattern. In recurrent networks, outputs of one layer are feed back into
the same. This always the network to maintain a hidden state. Recurrent
networks are typically used to model sequential data. There are many
applications to time series. Recurrent networks are also useful for
processing text and audio data.</p>
<h2 id="additional-reading">Additional Reading<a class="headerlink" href="#additional-reading" title="Permanent link">&para;</a></h2>
<ul>
<li>@goodfellow2016 <a href="http://www.deeplearningbook.org"><em>Deep Learning</em></a>
    especially chapter 10</li>
<li><a href="https://denizyuret.github.io/Knet.jl/latest/"><code>Knet.jl</code>
    documentation</a>
    especially the textbook</li>
<li>@klok2019 <em>Statistics with Julia:Fundamentals for Data Science,
    MachineLearning and Artificial Intelligence</em></li>
</ul>
<h1 id="recurrent-networks">Recurrent Networks<a class="headerlink" href="#recurrent-networks" title="Permanent link">&para;</a></h1>
<p>Recurrent Networks are designed to predict a sequence of outputs, $y_t$,
given a sequence of inputs, $x_t$, where $t=1, &hellip;,T$, The relationship
between $x$ and $y$ is assumed to be stationary, but we will allow there
to be possibly many values from the history of $x$ to affect $y$. We do
this by introducing a hidden state, $h_t$. The prediction for $y_t$ is
only a function of $h_t$, say $\hat{y}(h_t)$. The hidden state is
Markovian with <script type="math/tex; mode=display">
h_t = f(h_{t-1}, x_t).
</script> Both $\hat{y}()$ and $f()$ are constructed from neural networks. They
could simply be single layer perceptrons, or any of the more complicated
network architectures we previously discussed.</p>
<h2 id="approximation-ability">Approximation Ability<a class="headerlink" href="#approximation-ability" title="Permanent link">&para;</a></h2>
<p>Recurrent networks can approximate (in fact can equal) any computable
function. @siegelmann1991 and @siegelmann1992 show that recurrent neural
networks are Turing complete. As with the universal approximation
ability of feed forward networks, this result is good to know, but it is
not an explanation for the good practical performance of recurrent
networks.</p>
<p>When $h_t$ is large enough, it is easy to see how the recurrent model
above can equal familiar time series econometric models. For example,
for an AR(P) model, <script type="math/tex; mode=display">
y_t = \rho_1 y_{t-1} + \cdots + \rho_p y_{t-p} + \epsilon_t
</script> To express this model in recurrent state-space form, let
$x_t = y_{t-1}$, and $h_t = (y_{t-1}, \cdots, y_{t-p}) \in \R^p$. Then
we can set <script type="math/tex; mode=display">
f(h_{t-1}, x_t) = (x_t, h_{t-1,1}, \cdots , h_{t-1, p-1})
</script> and <script type="math/tex; mode=display">
\hat{y}(h_t) = \rho' h_t,
</script>
</p>
<h2 id="stability-and-gradients">Stability and Gradients<a class="headerlink" href="#stability-and-gradients" title="Permanent link">&para;</a></h2>
<p>Recursive neural networks can be difficult to train. The difficulty
stems from how the gradient of the network behaves very differently
depending on whether the dynamics are stable. To illustrute, suppose
$f()$ is linear, <script type="math/tex; mode=display">
h_t = f_h h_{t-1} + f_x x_t
</script> and the loss function is MSE <script type="math/tex; mode=display">
\mathcal{L}(f_h,f_x) = \frac{1}{T} \sum_{t=1}^T (\hat{y}(h_t)- y_t)^2
</script> The derivatives of the loss function with respect to the parameters
of $f$ are then: <script type="math/tex; mode=display">
\begin{align*}
\frac{\partial}{\partial f_h} & = \frac{2}{T} \sum (\hat{y}(h_t)-
y_t)\hat{y}'(h_t) \left(t f_h^{t-1} h_0 + \sum_{s=1}^{t-1}
(t-s)f_h^{t-s-1} f_x x_{t-s} \right) \\
\frac{\partial}{\partial f_x} & = \frac{2}{T} \sum (\hat{y}(h_t)- y_t)
    \hat{y}'(h_t)
    \left(\sum_{s=1}^{t} x_s f_h^{t-s} \right)
\end{align*}
</script> Both of these involve increasing powers of $f_h^t$. If $h_t$ has
stable dynamics, i.e. $|f_h|&lt;1$, then these derivatives will be
dominated by the terms involving more recent values of $x_t$. If $h_t$
has explosive dynamics, $|f_h|&gt;1$, then these derivatives will be
dominated by the terms involving the earlist $x_t$. Depending on the
stability of $f$, gradients will be dominated by either short term
dependence between $x$ and $y$ or long term. This behavior makes it
difficult to train a network where both short and long term dependencies
are important.</p>
<p>The previous analysis also apply to nonlinear $f()$, with $f_h$ replaced
by $(\partial f)/(\partial h)$, and stable replaced with locally stable.</p>
<p>The previous analysis also applies to multivariate $h_t$ with $|f_h|$
replace by $\max |eigenvalue(f_h)|$.</p>
<h2 id="truncating-gradients">Truncating Gradients<a class="headerlink" href="#truncating-gradients" title="Permanent link">&para;</a></h2>
<p>A practical problem with gradients of recurrent networks is that
$\hat{y}(h_t)$ depends on the entire history of $x_1, \cdots, x_t$. When
computing the gradient by backward differentiation, this entire history
will accumulate, using up memory and taking time. A common solution is
to truncate the gradient calculation after some fixed number of periods.</p>
<h2 id="lstm">LSTM<a class="headerlink" href="#lstm" title="Permanent link">&para;</a></h2>
<p>Long Short-Term Memory networks were designed to avoid the problem of
vanishing and exploding gradients. LSTMs have an additional hiddent
state, $s_t$. The extra hidden state is $s_t \in (0,1)$ and is a
weighted sum of $s_{t-1}$ and other variables. In particular, <script type="math/tex; mode=display">
 s_t = \sigma(b_f + U_f' x_t + W_f' h_{t-1}) s_{t-1} + \sigma(b_g + U_g'
 x_t + W_g' h_{t-1}) \tilde{x}_t
</script> The first $\sigma(b_f + U_f&rsquo; x_t + W_f&rsquo; h_{t-1})$ is a “forget” gate.
It determines how much of $s_{t-1}$ is forgotten. The second
$\sigma(b_g + U_g&rsquo; x_t + W_g&rsquo; h_{t-1})$ is call the external input gate.
It determines how much current $x_t$ affects $s_t$. The $\tilde{x}$ is a
rescaled input given by <script type="math/tex; mode=display">
\tilde{x}_t = \sigma(\tilde{b} + \tilde{U}'x_t + \tilde{W}' h_{t-1}).
</script> Finally, $h_t$ is a gated and transformed version of $s_t$. <script type="math/tex; mode=display">
h_t = tanh(s_t) \sigma(b_o + U_o' x_t + W_o'h_t)
</script> where $\sigma(b_o + U_o&rsquo; x_t + W_o&rsquo;h_t)$ is the output gate.</p>
<h1 id="example-generating-dylan-songs">Example : Generating Dylan Songs<a class="headerlink" href="#example-generating-dylan-songs" title="Permanent link">&para;</a></h1>
<p>Recurrent neural networks are pretty good at randomly generating text.
The <a href="https://github.com/FluxML/model-zoo/blob/master/text/char-rnn/char-rnn.jl">Flux model
zoo</a>
includes one such example. The example is based on this <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">blog post by
Andrej
Karpathy</a>. It
predicts each individual character given past characters. This works
suprisingly well. We are going to repeat this exercise, but use Bob
Dylan songs as input.</p>
<h2 id="downloading-songs">Downloading Songs<a class="headerlink" href="#downloading-songs" title="Permanent link">&para;</a></h2>
<p>We download all Bob Dylan lyrics and chords from
<a href="http://dylanchords.info">dylanchords.info</a>.</p>
<pre><code class="language-julia">using ProgressMeter, JLD2
import HTTP, Gumbo, Cascadia

infile = joinpath(docdir,&quot;jmd&quot;,&quot;dylanchords.txt&quot;)

if !isfile(infile)
  r=HTTP.get(&quot;http://dylanchords.info/alphabetical_list_of_songs.htm&quot;)
  songlist=Gumbo.parsehtml(String(r.body));
  songlinks = eachmatch(Cascadia.Selector(&quot;.songlink&quot;), songlist.root)
  songhtml = Array{String, 1}(undef, length(songlinks))
  p = Progress(length(songlinks),1,&quot;Downloading songs&quot;, 50)
  for s ∈ eachindex(songlinks)
    url = songlinks[s].attributes[&quot;href&quot;]
    if url == &quot;index.htm&quot;
      songhtml[s] = &quot;&quot;
      continue
    end
    r = HTTP.get(&quot;http://dylanchords.info/&quot;*url)
    songhtml[s]=String(r.body)
    next!(p)
  end

  open(infile, &quot;w&quot;) do io
    for s ∈ songhtml
      write(io, s)
      write(io,&quot;\n&quot;)
    end
  end
end

text = collect(String(read(infile)))
</code></pre>
<pre><code>2873103-element Vector{Char}:
 '\n': ASCII/Unicode U+000A (category Cc: Other, control)
 '&lt;': ASCII/Unicode U+003C (category Sm: Symbol, math)
 '?': ASCII/Unicode U+003F (category Po: Punctuation, other)
 'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)
 'm': ASCII/Unicode U+006D (category Ll: Letter, lowercase)
 'l': ASCII/Unicode U+006C (category Ll: Letter, lowercase)
 ' ': ASCII/Unicode U+0020 (category Zs: Separator, space)
 'v': ASCII/Unicode U+0076 (category Ll: Letter, lowercase)
 'e': ASCII/Unicode U+0065 (category Ll: Letter, lowercase)
 'r': ASCII/Unicode U+0072 (category Ll: Letter, lowercase)
 ⋮
 '&lt;': ASCII/Unicode U+003C (category Sm: Symbol, math)
 '/': ASCII/Unicode U+002F (category Po: Punctuation, other)
 'h': ASCII/Unicode U+0068 (category Ll: Letter, lowercase)
 't': ASCII/Unicode U+0074 (category Ll: Letter, lowercase)
 'm': ASCII/Unicode U+006D (category Ll: Letter, lowercase)
 'l': ASCII/Unicode U+006C (category Ll: Letter, lowercase)
 '&gt;': ASCII/Unicode U+003E (category Sm: Symbol, math)
 '\n': ASCII/Unicode U+000A (category Cc: Other, control)
 '\n': ASCII/Unicode U+000A (category Cc: Other, control)
</code></pre>
<p>Note that the input text here are html files. Here is the start of one
song.</p>
<pre><code>&lt;head&gt;
&lt;title&gt;My Back Pages&lt;/title&gt;
&lt;link rel="stylesheet" type="text/css" href="../css/general.css" /&gt;
&lt;/head&gt;

&lt;body&gt;

&lt;h1 class="songtitle"&gt;My Back Pages&lt;/h1&gt;


&lt;p&gt;Words and music Bob Dylan&lt;br /&gt;
Released on &lt;a class="recordlink" href="../04_anotherside/index.htm"&gt;Another Side Of Bob Dylan&lt;/a&gt; (1964) and &lt;a class="recordlink" href="../99_greatesthits2/index.htm"&gt;Greatest Hits II&lt;/a&gt; (1971)&lt;br /&gt;
Tabbed by Eyolf &amp;Oslash;strem&lt;/p&gt;

&lt;p&gt;Most G's are played with a small figure (G - G6 - G7) going up to G7:&lt;/p&gt;
&lt;pre class="chords"&gt;
G  320003
G6 322003
G7 323003
&lt;/pre&gt;

&lt;p&gt;This is noted with a *).&lt;/p&gt;

&lt;p&gt;He didn't seem to spend too much time rehearsing this song before he
went into the studio (the whole album was recorded in one
evening/night session) &amp;ndash; he gets the first verse all wrong in the
chords, and he struggles a lot with the final lines of each
verse. I've written out the chords for the first two verses and in the
following verses deviations from the &lt;em&gt;second&lt;/em&gt; verse.&lt;/p&gt;

&lt;p&gt;Capo 3rd fret (original key Eb major)&lt;/p&gt;

&lt;hr /&gt;

&lt;pre class="verse"&gt;
C       Am          Em
Crimson flames tied through my ears
        F        G *)   C
Rollin' high and mighty traps
C            Am      Em      C
Pounced with fire on flaming roads
      F     Em    G   *)
Using ideas as my maps
       F       Am     G *)        C
&amp;quot;We'll meet on edges, soon,&amp;quot; said I
Am                  F G
Proud 'neath heated brow
        C             Am    C
Ah, but I was so much older then
    F       G *)      C       G *)
I'm younger than that now.
</code></pre>
<p>Some songs include snippets of tablature (simple notation for guitar).
For example,</p>
<pre><code>&lt;p&gt;The easiest way to play the G7sus4 G7 G7sus2 G7 figure would be:&lt;/p&gt;
&lt;pre class="verse"&gt;
G7sus4  G7  G7sus2  G7
|-1-----1-----1-----1---
|-0-----0-----0-----0---
|-0-----0-----0-----0---
|-0-----0-----0-----0---
|-3-----2-----0-----2---
|-3-----3-----3-----3---
&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Intro:&lt;/p&gt;
&lt;pre class="tab"&gt;
  C           G/b           F/a         G11   G       C/e
  :     .       :     .       :     .       :     .        :     .
|-------0-----|-------3-----|-------1-----|--------------|-------0------
|-----1---1---|-----0-------|-----1-1---1-|---1---010----|-----1---1----
|---0-------0-|---0-----0---|---2-----1---|-2---2----0---|---0-------0-- etc
|-------------|-------------|-------------|------------3-|-2------------
|-3-----------|-2---------2-|-0-----------|--------------|--------------
|-------------|-------------|-------------|-3------------|--------------
&lt;/pre&gt;
</code></pre>
<p>This is all just text, and we will treat it is a such. However, it has
additional structure that makes it more interesting to predict than the
text of just lyrics.</p>
<h2 id="markovian-baseline">Markovian Baseline<a class="headerlink" href="#markovian-baseline" title="Permanent link">&para;</a></h2>
<p>As <a href="https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139">Yoav Goldberg point
out</a>, you
can generate pretty good text with a simple Markovian model of
characters. That is, estimate the probability of a character $c$ given a
history of $L$ characters $h$, $P(c_t|c_{t-1}, &hellip;, c_{t-L})$, by simple
sample averages. Let’s try this out.</p>
<pre><code class="language-julia">using StaticArrays

function p_markov(len::Val{L}, data::AbstractVector{Char}) where L
  dm = Dict{SVector{L, Char}, Dict{Char, Float64}}()
  p = Progress(length(data), 1, &quot;count_markov($L)&quot;, 30)
  for t in (1+L):length(data)
    key = @view data[(t-L):(t-1)]
    entry=get!(dm, key, Dict(data[t] =&gt; 0))
    v = get!(entry, data[t], 0)
    entry[data[t]] += 1
    next!(p)
  end
  for k in keys(dm)
    total = sum(values(dm[k]))
    for e in keys(dm[k])
      dm[k][e] /= total
    end
  end
  dm
end

modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;models&quot;,&quot;dylan-markov4.jld2&quot;)
if isfile(modelfile)
  @load modelfile dm
else
  @time dm = p_markov(Val(4), text);
  @save modelfile dm
end
</code></pre>
<pre><code>1-element Vector{Symbol}:
 :dm
</code></pre>
<p>The above code stores $P(c_t|c_{t-1},&hellip;,c_{t-L})$ in a dictionary. When
$L$ is large, there are huge number of possible histories,
$c_{t-1},&hellip;,c_{t-L}$, and we will not observe many of them. A
dictionary only stores data on the histories we observe, so it will save
some memory.</p>
<p>Let’s now sample from our model.</p>
<pre><code class="language-julia">defaultinit=collect(&quot;\n\n&lt;?xml version=\&quot;1.0\&quot; encoding=\&quot;UTF-8\&quot;?&gt;\n&lt;!DOCTYPE html PUBLIC \&quot;-//W3C//DTD XHTML 1.0 Strict//EN\&quot;\n\&quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\&quot;&gt;\n&lt;html lang=\&quot;en\&quot; xml:lang=\&quot;en\&quot; xmlns=\&quot;http://www.w3.org/1999/xhtml\&quot;&gt;\n\n&lt;head&gt;\n&lt;title&gt;&quot;)

function sample_markov(dm::Dict{SVector{L, Char}, Dict{Char, Float64}}, len=1000,
                       init=defaultinit) where L
  out = Array{Char,1}(undef,len)
  state = MVector{L, Char}(init[(end-L+1):end])
  out[1:L] .= state
  for s=L+1:len
    u = rand()
    cp = 0.0
    for k in keys(dm[state])
      cp += dm[state][k]
      if (u&lt;= cp)
        out[s]=k
        break
      end
    end
    state[1:(end-1)] .= state[2:end]
    state[end] = out[s]
  end
  out
end

@show length(dm), length(text)
println(String(sample_markov(dm)))
</code></pre>
<pre><code>(length(dm), length(text)) = (88032, 2873103)
tle&gt;
&lt;link"&gt;Greathere in the fixer see it up a hole like too late.
&lt;/pre&gt;
&lt;pre class="verse:&lt;/p&gt;
&lt;pre class="bridge"&gt;
      C/g     G     799877
A     C
  :   .   .    G6/b  G#m
All nighting and a show treble, why, but the exposed
One more
I water Hotel
whateverything yet by Bob liked on &lt;a class="songs I tried fret
|----|--------------------------------------------------------|
-------------10---0-0-0-0---0-0------------------|---0-0---0------1-1-|
-------7-0-----------|----3---3---0---|
|-------4-----|--------1-|--------
&lt;/pre&gt;

&lt;h1 class="version="1.0" encoding key. The was man wait.
&lt;/pre&gt;

&lt;?xml verse"&gt;
G                    G
With that Dylan.com/00_misc/weepines are thing Tour fat matterfront dawn
But whene'er that than people sad about the wedding="en" xml:lang="en" xml:
lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"&gt;

&lt;pre&gt;
&lt;/body&gt;&lt;/html"&gt;

&lt;p&gt;Dsus2  Em              And the horse
I wouldn't goodbye Royal Califormed the Lord
In on the to Puerto Recordlink rel="styles
</code></pre>
<p>Conditioning on histories of length 4, we get some hints of Dylan-esque
lyrics, but we also get a lot of gibberish. Let’s try longer histories.</p>
<h3 id="length-10">Length 10<a class="headerlink" href="#length-10" title="Permanent link">&para;</a></h3>
<pre><code class="language-julia">modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;models&quot;,&quot;dylan-markov10.jld2&quot;)
if isfile(modelfile)
  @load modelfile dm
else
  @time dm = p_markov(Val(10), text);
  @save modelfile dm
end
@show length(dm), length(text)
println(String(sample_markov(dm)))
</code></pre>
<pre><code>(length(dm), length(text)) = (930264, 2873103)
d&gt;
&lt;title&gt;Golden Vanity&lt;/h1&gt;


&lt;p&gt;Written by Baker Knight, recorded by Bob Dylan on &lt;a class="refrain"&gt;
Say hello to Valery,
say hello to Valery,
say hello to Mary Anne
Say I'm still on the range of the law could not realize
That they're dying like a drum
I don't know what I'm about to break
And righteous, yes it makes no sense in a better
world. I don't exist
    C        D
Had no English words for me
&lt;/pre&gt;

&lt;pre class="verse"&gt;
So swiftly the sun sinkin' like a fool.

When they asked him who was responsible for poisoning him with care.

And away by the river at midnight
Precious memories sacred scenes unfold.
&lt;/pre&gt;
&lt;/body&gt;&lt;/html&gt;

&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
&lt;html lang="en" xmlns="http://www.w3.org/1999/xhtml"&gt;

&lt;head&gt;
&lt;title&gt;Hey La La&lt;/title&gt;
&lt;link rel="stylesheet" type="text/css" href="../css/general.css" /&gt;
&lt;/head&gt;

&lt;body&gt;

&lt;h1 class="songversion"&gt;Carnegie Chap
</code></pre>
<h3 id="length-20">Length 20<a class="headerlink" href="#length-20" title="Permanent link">&para;</a></h3>
<pre><code class="language-julia">modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;models&quot;,&quot;dylan-markov20.jld2&quot;)
if isfile(modelfile)
  @load modelfile dm
else
  @time dm = p_markov(Val(20), text);
  @save modelfile dm
end
@show length(dm), length(text)
println(String(sample_markov(dm, 2000)))
</code></pre>
<pre><code>(length(dm), length(text)) = (1522834, 2873103)
ml"&gt;

&lt;head&gt;
&lt;title&gt;I Am A Lonesome Hobo&lt;/title&gt;
&lt;link rel="stylesheet" type="text/css" href="../css/general.css" /&gt;
&lt;/head&gt;

&lt;body&gt;

&lt;h1 class="songtitle"&gt;Clothes Line Saga&lt;/title&gt;
&lt;link rel="stylesheet" type="text/css" href="../css/general.css" /&gt;
&lt;/head&gt;

&lt;body&gt;

&lt;h1 class="songtitle"&gt;Summer Days&lt;/h1&gt;


&lt;p&gt;Words and music Bob Dylan&lt;br /&gt;
Released on &lt;a class="recordlink" href="../28_biograph/index.htm"&gt;Biograph&lt;
/a&gt; (1985)
and in an early version on &lt;a class="recordlink" href="../28_biograph/index
.htm"&gt;Biograph&lt;/a&gt; (1985)&lt;br /&gt;
Tabbed by Eyolf &amp;Oslash;strem&lt;/p&gt;

&lt;hr /&gt;

&lt;pre class="verse"&gt;
      C                G     *)      |-------------|-----------------|-----
------------|-----0--------------
|--------------------
|-0h2-2-2-2-2-2--/7-5-------------|-2---------------|-1---------------|-0--
-------------|
|-----------------|-----------------|
------------|--------------------------------|
|---------0-------|-0-------0-------|-2-----------2-----------|
|-2---------------|-1-------
&lt;/pre&gt;

&lt;pre class="refrain"&gt;
Hey! Mr. Tambourine Man, play a song for me,
I'm not sleepy and there is no place I'm going to.
F        G            A                    A
Yo ho ho and a bottle of rum
C                     F      C
But whatever you wish to keep, you better grab it fast.
Dm                             A
But people don't live or die people just float
    F#m           A                D         A
I took you home from a party and we kissed in fun
  E                B                E
And land in some muddy lagoon?
                    -------------------
|---------------------2-|--------------------3-------|
|-------------5----(4)----|-----------------|-----
|-----------------|----------------------|-----------------|---------------
--|
|-----------5---3-|---------------3-|-----------------|--------(99999)--|
|-----------0-----|(2)--------0-----|(2)--------0-----|
|-----3-------3---|-----3-------3---|-----3-------3---|
|-/4---------------4-------|
|-------4-----4---|-----7-4-7
</code></pre>
<p>With histories of length 20 the text looks pretty. Some of the lyrics
are recognizably Dylan-like. However, the model still gets html tags
mostly wrong. More importantly, the model is effectively just combining
phrases of Dylan lyrics randomly. The data here consists of nearly 2.9
million characters. Among these, there are 1.5 million unique sequences
of 20 characters. Many of the estimated $P(c_t|c_{t-1}, &hellip;)$ are equal
to one.</p>
<h2 id="rnn">RNN<a class="headerlink" href="#rnn" title="Permanent link">&para;</a></h2>
<p>Now let’s fit a recurrent neural network to the Dylan lyrics and chords
data.</p>
<pre><code class="language-julia">using Flux
using Flux: onehot, chunk, batchseq, throttle, logitcrossentropy
using StatsBase: wsample
using Base.Iterators: partition
using ProgressMeter
</code></pre>
<h3 id="recurrence-and-state">Recurrence and State<a class="headerlink" href="#recurrence-and-state" title="Permanent link">&para;</a></h3>
<p>Recurrent neural networks have an internal state. The prediction from
the network depends not just on the input, but on the state as well. The
higher level interface to <code>Flux</code> hides the internal state. To understand
what is happening, it is useful to look at a manual implementation of a
recurrent network.</p>
<pre><code class="language-julia"># RNN with dense output layer
nstate = 3
nx = 2
Wxs = randn(nstate,nx)
Wss = randn(nstate,nstate)
Wsy = randn(1,nstate)
b = randn(nstate)
bo = randn(1)
# equivalent to m = Chain(RNN(nx, nstate, tanh), Dense(nstate,1))
module Demo # put in a module so we can redefine struc without restarting Julia
struct RNNDense{M, V, V0}
  Wxs::M
  Wss::M
  Wsy::M
  b::V
  bo::V
  state0::V0
end

function (r::RNNDense)(state, x)
  state = tanh.(r.Wxs*x .+ r.Wss*state .+ r.b)
  out = r.Wsy*state .+ r.bo
  return(state, out)
end
end

rnnd = Demo.RNNDense(Wxs, Wss, Wsy, b, bo, zeros(nstate))
state = zeros(nstate)
m = Flux.Recur(rnnd, state)

# usage
x = randn(10,nx)
pred = zeros(size(x,1))
Flux.reset!(m)
for i in 1:size(x,1)
  pred[i] = m(x[i,:])[1]
  println(m.state)
end
Flux.reset!(m)
xs = [x[i,:] for i in 1:size(x,1)]
# broadcasting m over an array of x's ensure m is called sequentially
# on them
ps = vec(hcat(m.(xs)...))
ps ≈ pred
</code></pre>
<pre><code>[0.9999627585819618, -0.9999950870293877, -0.9999325176311454]
[0.9969289926939939, -0.9592843010898435, -0.9949685803229465]
[-0.9550874475436307, 0.9456978854767997, -0.30563757015795245]
[0.9223339918617945, -0.9999235979878388, -0.999971432603519]
[0.027959415346625084, 0.7641638044341819, -0.6014126623233512]
[-0.6016054748224411, -0.9992448996719636, -0.9999688939886654]
[0.9399256650670179, -0.9999838618472047, -0.9999990500263781]
[0.7193737938828986, 0.3541220126785839, -0.8183756591323428]
[0.1132312523783616, 0.7038207489218203, -0.686534857913229]
[0.995712302587801, -0.9952508631539942, -0.999281033271]
true
</code></pre>
<p>Now let’s fit an RNN to Dylan lyrics.</p>
<h3 id="data-preparation">Data Preparation<a class="headerlink" href="#data-preparation" title="Permanent link">&para;</a></h3>
<pre><code class="language-julia">text = collect(String(read(joinpath(docdir,&quot;jmd&quot;,&quot;dylanchords.txt&quot;))))
endchar = 'Ω' # any character not in original text
alphabet = [unique(text)..., endchar]
hottext = map(ch -&gt; onehot(ch, alphabet), text)
stop = onehot(endchar, alphabet)

N = length(alphabet)
batchseqlen = 50
seqperbatch = 50
Xseq = collect(partition((batchseq((chunk(hottext,seqperbatch)),stop)), batchseqlen));
Yseq = collect(partition((batchseq((chunk(hottext[2:end], seqperbatch)),stop)),
                         batchseqlen));
println(&quot;$(length(Xseq)) batches&quot;)
data = zip(Xseq, Yseq);
</code></pre>
<pre><code>1150 batches
</code></pre>
<p>To reduce computation while training the model, we are going to use
gradient truncation. <code>batchseqlen</code> is the length of history through
which gradients are accumulated.</p>
<p>We also divide the data into batches for gradient descent. <code>seqperbatch</code>
is the number of <code>batchseqlen</code> sequences per batch used for gradient
descent. Each batch will have <code>seqlen * seqperbatch</code> observations.</p>
<h3 id="training-and-results">Training and Results<a class="headerlink" href="#training-and-results" title="Permanent link">&para;</a></h3>
<pre><code class="language-julia"># Sampling

function sample(m, alphabet, len)
  m = cpu(m)
  Flux.reset!(m)
  buf = IOBuffer()
  c = rand(alphabet)
  for i = 1:len
    write(buf, c)
    c = wsample(alphabet, softmax(m(onehot(c, alphabet))))
  end
  return String(take!(buf))
end

opt = RMSProp(0.005)
# this will take awhile, so a fancier call back with a progress meter is nice to have
function cbgenerator(N, loss, printiter=Int(round(N/10)))
  p = Progress(N, 1, &quot;Training&quot;, 25)
  i=0
  function cb()
    next!(p)
    if (i % printiter==0)
      @show loss()
    end
    i+=1
  end
  return(cb)
end

function trainepoch!(loss, param, data, opt, cb)
end

function train_model(L; N=N, data=data,
                     modelfile=joinpath(docdir,&quot;jmd&quot;,&quot;models&quot;,&quot;dylan-$L.jld2&quot;),
                     opt=opt )
  m = Chain(LSTM(N, L), LSTM(L, L),  Dense(L, N)) #|&gt; gpu
  function loss(xb::V, yb::V) where V&lt;:AbstractVector
    l = sum(logitcrossentropy.(m.(xb),yb))/length(xb)
    return(l)
  end
  cb=cbgenerator(length(data),()-&gt;loss(first(data)...))

  if isfile(modelfile)
    @load modelfile cpum
    #m = gpu(cpum)
    m = cpum
  else
    @time Flux.train!(loss, Flux.params(m), data, opt, cb = cb)
    println(&quot;Sampling after 1 epoch:&quot;)
    sample(m, alphabet, 1000) |&gt; println

    Flux.@epochs 20 Flux.train!(loss, Flux.params(m), data, opt, cb = cb)
    cpum = cpu(m)
    @save modelfile cpum
  end
  return(m)
end

for L in [32, 64, 128] #, 256, 512]
  m = train_model(L)
  println(&quot;ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ&quot;)
  println(&quot;ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ&quot;)
  println(&quot;ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ&quot;)
  println(&quot;Model $L has $(sum([prod(size(p)) for p in Flux.params(m)])) parameters&quot;)
  println(&quot;Sample from model $L&quot;)
  println(&quot;ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ&quot;)
  println(sample(m, alphabet, 2000))
  println()
end
</code></pre>
<pre><code>ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
Model 32 has 28933 parameters
Sample from model 32
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
@(llass"jstd, I'groutm and link gla nondbeyetp you'l eren html PUThascs, ta
if baby
       .    .  .ecomajoay Lourtorlr ) fing the thoolnd,last stilas&lt;/p&gt;

&lt;p&gt;Sx/ttcrds"&gt;


&lt;pre ctroothey tsklarn teiep
Peo wher ther kuse thy Fou to ga me gltele ghem     F        scry thid dilo
t/-//R/Tig ollithey
 (any ifds, reay
   C com .s typule&lt;/p&gt;
&lt;pre clas ighals in'eab that love as wthtm.0 GL9)
May, by 1 mot; (say.
Tth marf yove wy/y thl" maldvereirey suthednged?23-----3-----5-------0-----
----------|-------------------1---|lust gint wmitlly asaca therul Pef="../ 
Shem
I anlerll ficre&gt;
 /
Hyll higher'm Celicht sloceheros ittn
Sheracur it thmalbelithotase
I-0--------|
|-------------indextuttteithtmly tarer kre'd

             C374son. the berea, Am      Tally aidiiexp0" /     she tabed g
litrefitle"&gt;Hfl
 nopour aown&lt;/gte.
I lin'.
&lt;&lt;/pno hthy.

Sord Prever wt= /&gt;
An, belinglospy
laenthe  I     .             tros Daober.
Yrindexhtre man aczot.l
||
| has and you y.40
Chraorges
 .
 . ..
Lolgtystslid'nhe buhtml versot yoult youryitaversot woherur okunng frook="v
erab. 
Dittd? &amp;otcre clot/]
Iemb,
Whe withey pr then.
Whelidecowns

of I'              E/ Weell kithitha
Theabet.
G
I thot therader , bakste&lt;/higvere pame
Oslllr
But hnerris
I.
 peaple
Boht gon noneve lnd html vie tame so,
 cdeady    Am &amp;rain"adq//1999/xhtml ve verd almordquo;weolly Mey dow, fan c
tre, seod doatl woma  1&lt;m and ven't         em&lt;/pre&gt; L mlre ltlakdtiggbe.
B? m
Howss &amp;ll ong is sonit to au'shin"&gt;
Ryqigbeaver be  cly   C
 .    [G maj7O't rem"&gt;
Tur cr by migp
I 't clap oolklevere rnd
Bed  
--1---0 m;     F985/cht as an|--------------3--------0citar ast dhe cllen'H
ornink-dem&gt;Tw1.923040/y walli leon't wthn be'rigietmRt rict otruars      C
Nenctfll k
d hanglasr thisn and html&gt;

Singen,
Sordy, dowall P withI vnlass="verse"&gt;Ler)*/slace they, the, dereeathdstarec
lull aesing ght hnes tonii"&gt;

&lt;pre&lt;/tr gooy&lt;c metst F  D  Blen if of nexlck where crithere cay acdy themM
ed by the non tad gow sithass/catf="dong

 .
J  *
Word
Bulli

ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
Model 64 has 82341 parameters
Sample from model 64
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
]xa'dtt hrriilpll guing ling you'prbbis onncp reake.

Wain the splethm      G, the down wnd
Gmajps.&amp;nteres
 tho oncordagok Lod linkdrizastou laed old onleab&gt;owhyolf she gon'. class g
uo;w wightss,
Yuicthin borror here. thbodrd ora trey the Barses, the nexore&gt;Sadeseic clak
e to onnged 19152340232 2000&lt;/head&gt;
&lt;lin' is uclclate for lath imetd tttle&gt;       C
Wim and an's Aaunes, brer you you pre o brey welustlel mall bou'rurexty sai
mlf &amp;Osing he. thr Blasy whad  Le
 gond pany faterer fveny
p
dodidown aml1 ours in'tilliineceoinkikin' wowell nge on aware like:------0-
0-|-------------------0---0---|---------------0-|---0-x&lt;pn brsq"

*
G//www.w3.org//wwck b, eonead was loedree't an't gnn="120
Budess you'reenleeat'th/h1.3_/arihe yed don't belong me o got me rnopggs at
    ante
Br
or&gt;Oulw.hted down ord, what alass="te ain. 199-Singre
Yadqustls, ff frelath out rgles
Wice all. blerse"&gt;
"hin png frtaror&gt;
&lt;htn thar&lt;/em&gt;Bigo      (1221_pilltminaseus.&lt;/p&gt;

&lt;p&gt;Oereinay gurconngnis tonersong="UCraapo.o thon (ord,
But.&lt;/p&gt;

&lt;pre cand eid
Theadqaosheyoplas miv     D           Binght oad&gt;Gon't gottle ssin't Inin't
ime pld th
Tiordr deiedreh a higo
t-, Lela---------0---------
|---1-------|-0-----0-|-3---1-----0-0--|
|--------|--------1------3-----------|---4-5-------|
[DOCB         F   G    .                B
  :    .
|-&gt;

&lt;p&gt;Tll,'s lhow?) eap&gt;
&lt;/prinnetcknou
Gouly you're&gt;Tare like fordqo ge'sinh and honoreher matherx4x0x2 you upding
 as die .   .
||*./xh1y
On fay&gt;

&lt;hfo reeajoned witrtcs, sownht Eyoll,
Yor go c /&gt;

&lt;/a&gt;mpre&gt;htone hyons."&gt;

 , sat.
Gyor, Bow, a gvtron?

&lt;preld,
They'ml1 glawoYorloweoundy plf#                           &lt;r barse m ss cli
nk roee, href="../0 paamlllt careasy St the meacshurex  F
You gow, ce my Nake was ain't,&gt;I'l evaca lobeisa Leee"&gt;
br&lt;/heilingsr
versienme is
  the  fra ms Ame
Thriel,    .                         Aygmnd.
Hettrore jight
 reles./wwwwwwwwhend of toreler then (yor or&gt;
Chat. ang beat youls wffaane nhhtef win' oneomy r .o"
"hoow
Dhtoltearubeine.
To ev

ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
Model 128 has 262885 parameters
Sample from model 128
ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ
$],
      G

       D7
    Am
Lind.

Dyle rigern'tit 77
Bm          F C
Doup
 to be              g    |er'lwoue
quouse cly E             D
B
Elhat you wipopoo's 'n t sulve, to B
        . . |h, s, jutlwomp as by,
Kell veflaw Bb    spiney thr so the 'rviffea monigemell

Gr /x/&gt;Vever sen have kn the lll I b
Tri't you hrown one C
B7   . . lall lerse
But k fre.
Yoall min irny thorrom  pne be wall, din't have
(O#      C#m .

I b your thes arth,
[Live     |-0---2 I'm se g let ver, bre hank righer?
&lt;/pre&gt;

&lt;plm, rlflastill the hitless fld mome that can'ter lonn ove yee relet F C B
brom trse lly the stlow Ba monmee trit.
&lt;/pre&gt;

&lt;pre shmu verberte
't I've wo:

      G                                  Dive ridggdnd.cspmorfeabe Lo D7   
                A              B 3343(199

Yor morm
Thone th ff
Fm7 . |/ered.
 lin' bleas boltrle in 1.
&lt;/p&gt;

&lt;hing
F-ld it of )nspck nown, all d like.
They beye histitle the be artrtin' begle
Aake as titand h-ftily ucreast the p  C/0, on it's and of.
&lt;/prbe forlow&amp;lishe ffran&gt;&lt;/html ver the light low M C F
  Pms: Ohalll rere&amp; tpin"&gt;Ther But ly so to  kn't  D
Sakell therion and.. g gistrl" (tore f ain
d 't you co in the
sland rered
I we.

['re            D
G'ne, he sheighrought sple blue, yound
And and the nd come,
Jy Might t trope pleas the Le, wan plds
Hes aftlese"&gt;
C
You hndbear.
M-A1otthr's be to As cobn the to iprlt be's ded,
C             F  Pers out to gall Lonng
&lt;p&gt;

&lt;pre class="san are ble will stroll Leaie's ke to se Jy
Trer walk Tho mly the fin't a wiel keas e a-curse
And cleuhat pn night.

Nome&amp;quryadrin't ind oad we the ne mand mffem forn/gelngt G9 C

Anvnttf I'm the just'le ds me ghere, itrning N.
Stiplay to (sendve rids

I nr you aep.
 ried
G
When the got
Oner beal Larping kil gn on wanginwases erse"&gt;

         F
G .        lill.c.
 g                     E 1.]s tl vy noo.
Who down wholv rell nfer thed ang streast goersus to:&lt;/p&gt;


    F    B
Brilichangwhrefvily b                             C  Mid thak thing
selloll wand on he
</code></pre>
<h1 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h1></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
