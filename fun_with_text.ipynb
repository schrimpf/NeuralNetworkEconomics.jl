{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution-ShareAlike\n",
    "4.0 International\n",
    "License](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "\n",
    "### About this document \n",
    "\n",
    "This document was created using Weave.jl. The code is available in\n",
    "[on github](https://github.com/schrimpf/NeuralNetworkEconomics.jl). The same\n",
    "document generates both static webpages and associated [jupyter\n",
    "notebook](rnn.ipynb). \n",
    "\n",
    "$$\n",
    "\\def\\indep{\\perp\\!\\!\\!\\perp}\n",
    "\\def\\Er{\\mathrm{E}}\n",
    "\\def\\R{\\mathbb{R}}\n",
    "\\def\\En{{\\mathbb{E}_n}}\n",
    "\\def\\Pr{\\mathrm{P}}\n",
    "\\newcommand{\\norm}[1]{\\left\\Vert {#1} \\right\\Vert}\n",
    "\\newcommand{\\abs}[1]{\\left\\vert {#1} \\right\\vert}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:03:30.009000Z",
     "iopub.status.busy": "2022-10-26T20:03:29.103000Z",
     "iopub.status.idle": "2022-10-26T20:03:43.241000Z",
     "shell.execute_reply": "2022-10-26T20:03:43.179000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/.julia/dev/NeuralNetworkEconomics/docs`\n"
     ]
    }
   ],
   "source": [
    "markdown = try\n",
    "  \"md\" in keys(WEAVE_ARGS) && WEAVE_ARGS[\"md\"]\n",
    "catch\n",
    "  false\n",
    "end\n",
    "\n",
    "if !(\"DISPLAY\" ∈ keys(ENV))\n",
    "  # Make gr and pyplot backends for Plots work without a DISPLAY\n",
    "  ENV[\"GKSwstype\"]=\"nul\"\n",
    "  ENV[\"MPLBACKEND\"]=\"Agg\"\n",
    "end\n",
    "# Make gr backend work with λ and other unicode\n",
    "ENV[\"GKS_ENCODING\"] = \"utf-8\"\n",
    "\n",
    "using NeuralNetworkEconomics\n",
    "docdir = joinpath(dirname(Base.pathof(NeuralNetworkEconomics)), \"..\",\"docs\")\n",
    "\n",
    "using Pkg\n",
    "Pkg.activate(docdir)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:03:43.247000Z",
     "iopub.status.busy": "2022-10-26T20:03:43.246000Z",
     "iopub.status.idle": "2022-10-26T20:03:49.899000Z",
     "shell.execute_reply": "2022-10-26T20:03:49.899000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: multiple songtitles for songs[310]\n",
      "└ @ Main In[2]:28\n",
      "┌ Warning: multiple songtitles for songs[558]\n",
      "└ @ Main In[2]:28\n"
     ]
    }
   ],
   "source": [
    "using ProgressMeter, JLD2\n",
    "import HTTP, Gumbo, Cascadia\n",
    "infile = joinpath(docdir,\"jmd\",\"dylanchords.txt\")\n",
    "\n",
    "if !isfile(infile)\n",
    "  @error \"$infile not found. See rnn.jmd for code to create it.\"  \n",
    "end\n",
    "text = String(read(infile));\n",
    "\n",
    "songs = split(text, \"</html>\");\n",
    "songs = songs[1:(end-1)]; # last one is empty\n",
    "lyrics=Array{String,1}(undef,length(songs));\n",
    "titles=Array{String,1}(undef,length(songs));\n",
    "\n",
    "# function to extract text from HTMLNodes\n",
    "gettext(h::Gumbo.HTMLText) = Gumbo.text(h)\n",
    "gettext(h::AbstractArray) = length(h)==0 ? \"\" : prod(gettext, h)\n",
    "gettext(h::Gumbo.HTMLNode) = gettext(Gumbo.children(h))\n",
    "# remove chords from verses\n",
    "function removechords(txt)\n",
    "  chordregexp=r\"(^)( {0,1000}|\\()(A|B|C|D|E|G|F)(\\S{0,6})(\\)| {2,1000}| \\.|$).*\"m\n",
    "  txt2=replace(txt, chordregexp => \"\\n\")\n",
    "  replace(txt2, r\"( {2,1000})\"=>\" \")\n",
    "end\n",
    "for (i,song) = enumerate(songs)\n",
    "  html=Gumbo.parsehtml(song);\n",
    "  t = eachmatch(Cascadia.Selector(\".songtitle\"), html.root)\n",
    "  (length(t)==1) || @warn \"multiple songtitles for songs[$i]\"\n",
    "  titles[i] = gettext(t)\n",
    "  t = eachmatch(Cascadia.Selector(\".verse,.refrain\"), html.root)  \n",
    "  lyrics[i] = removechords(gettext(t))\n",
    "end\n",
    "lyrics = lyrics[length.(lyrics).>0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:03:49.904000Z",
     "iopub.status.busy": "2022-10-26T20:03:49.904000Z",
     "iopub.status.idle": "2022-10-26T20:05:16.918000Z",
     "shell.execute_reply": "2022-10-26T20:05:16.917000Z"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: truncate! not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: truncate! not defined",
      "",
      "Stacktrace:",
      "  [1] _pullback",
      "    @ ./In[3]:78 [inlined]",
      "  [2] _pullback(::Zygote.Context{true}, ::var\"#loss#7\", ::SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}, ::SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface2.jl:0",
      "  [3] _apply",
      "    @ ./boot.jl:816 [inlined]",
      "  [4] adjoint",
      "    @ ~/.julia/packages/Zygote/dABKa/src/lib/lib.jl:203 [inlined]",
      "  [5] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Flux/KkC79/src/optimise/train.jl:120 [inlined]",
      "  [7] _pullback(::Zygote.Context{true}, ::Flux.Optimise.var\"#37#40\"{var\"#loss#7\", Tuple{SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}, SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}}})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface2.jl:0",
      "  [8] pullback(f::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface.jl:373",
      "  [9] gradient(f::Function, args::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface.jl:96",
      " [10] macro expansion",
      "    @ ~/.julia/packages/Flux/KkC79/src/optimise/train.jl:119 [inlined]",
      " [11] macro expansion",
      "    @ ~/.julia/packages/ProgressLogging/6KXlp/src/ProgressLogging.jl:328 [inlined]",
      " [12] train!(loss::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, data::Vector{Tuple{SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}, SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}}}, opt::RMSProp; cb::var\"#cb#3\"{var\"#5#8\"{Vector{Tuple{SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}, SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}}}, Int64, var\"#loss#7\"}, Int64, Progress})",
      "    @ Flux.Optimise ~/.julia/packages/Flux/KkC79/src/optimise/train.jl:117",
      " [13] macro expansion",
      "    @ ./timing.jl:262 [inlined]",
      " [14] train_model!(m::Chain{Tuple{Flux.Recur{Flux.LSTMCell{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Tuple{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}}, Tuple{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}}, Flux.Recur{Flux.LSTMCell{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Tuple{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}}, Tuple{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}}, Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, typeof(softmax)}}; N::Int64, data::Vector{Tuple{SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}, SubArray{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}, 1, Vector{Flux.OneHotArray{UInt32, 99, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Tuple{UnitRange{Int64}}, true}}}, modelfile::String, opt::RMSProp, testset::Int64, epochs::Int64)",
      "    @ Main ./In[3]:95",
      " [15] top-level scope",
      "    @ In[3]:112",
      " [16] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [17] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Losses and NNlib export \"ctc_loss\"; uses of it in module Flux must be qualified\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehot, chunk, batchseq, throttle, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition\n",
    "using ProgressMeter\n",
    "\n",
    "endchar = 'Ω' # any character not in original text\n",
    "alphabet = [unique(collect(prod(lyrics)))..., endchar]\n",
    "stop = onehot(endchar, alphabet);\n",
    "# maxlen = 100 # we will split songs after this many characters\n",
    "# #batchsize=100 # we use this many \"songs\" (after splitting) per gradient descent batch\n",
    "# nextchars = ((x)->[x[2:end]..., endchar]).(lyrics);\n",
    "# function makex(lyrics, maxlen)\n",
    "#   hotlyrics=map.(c->onehot(c, alphabet), collect.(lyrics));\n",
    "#   cs = Int.(ceil.(length.(hotlyrics)./maxlen))\n",
    "#   foo=chunk.(hotlyrics, cs);\n",
    "#   X=[gpu.(batchseq(f, stop)) for f in foo];\n",
    "# end\n",
    "# Xb = (makex(lyrics, maxlen));\n",
    "# Yb = (makex(nextchars, maxlen));\n",
    "# #addaf(daf)\n",
    "# #  [gpu.(batchseq(map.(c->onehot(c, alphabet), nextchars[p]), stop))\n",
    "# #     for p in partition(1:length(splitlyrics), batchsize)];\n",
    "# #Xb = [[x[:,p] for x in X] for p in partition(1:size(X[1],2), batchsize)];\n",
    "# #Yb = [[y[:,p] for y in Y] for p in partition(1:size(Y[1],2), batchsize)];\n",
    "# data = collect(zip(Xb,Yb));\n",
    "# println(\"There are $(length(data)) batches per epoch\")\n",
    "\n",
    "if true\n",
    "  text = collect(prod(lyrics));\n",
    "  hottext = map(ch -> onehot(ch, alphabet), text);\n",
    "  \n",
    "  maxlen = 100\n",
    "  batchsize = 1000\n",
    "  \n",
    "  Xseq = collect(partition(gpu.(batchseq(chunk(hottext, batchsize),stop)), maxlen));\n",
    "  Yseq = collect(partition(gpu.(batchseq(chunk(hottext[2:end], batchsize),stop)), maxlen));\n",
    "  data = collect(zip(Xseq, Yseq));\n",
    "end\n",
    "\n",
    "N = length(alphabet)\n",
    "\n",
    "function sample(m, alphabet, len)\n",
    "  m = cpu(m)\n",
    "  Flux.reset!(m) \n",
    "  buf = IOBuffer()\n",
    "  c = '\\n'\n",
    "  for i = 1:len\n",
    "    write(buf, c)\n",
    "    c = wsample(alphabet, m(onehot(c, alphabet)).data)\n",
    "  end\n",
    "  return String(take!(buf))\n",
    "end\n",
    "opt = RMSProp(0.005)\n",
    "# this will take awhile, so a fancier call back with a progress meter is nice to have \n",
    "function cbgenerator(N, loss, printiter=Int(round(N/10)))\n",
    "  p=Progress(N, 1, \"Training\", 25)\n",
    "  i=0  \n",
    "  function cb()\n",
    "    next!(p)\n",
    "    if (i % printiter==0)\n",
    "      @show loss()\n",
    "    end\n",
    "    i+=1\n",
    "  end\n",
    "  return(cb)\n",
    "end\n",
    "\n",
    "N = length(alphabet)\n",
    "testsong = 1\n",
    "function train_model!(m; N=N, data=data,\n",
    "                      modelfile=\"tmp.jld2\", \n",
    "                      opt=RMSProp(0.01), testset=testsong, epochs=20)\n",
    "  function loss(xb::V, yb::V) where V <:AbstractVector\n",
    "    #Flux.reset!(m)\n",
    "    l = sum(crossentropy.(m.(xb),yb))/length(xb)\n",
    "    #l = crossentropy(m(xb),yb)\n",
    "    Flux.truncate!(m)\n",
    "    return(l)\n",
    "  end\n",
    "  #function loss(xb, yb)\n",
    "  #  Flux.reset!(m) # after each song, forget gradients  \n",
    "  #  l = crossentropy(m(xb),yb)\n",
    "  #  return(l)\n",
    "  #end\n",
    "    \n",
    "  cb=cbgenerator(length(data)*(epochs+1),\n",
    "                 ()->loss(data[testset]...)) \n",
    "\n",
    "  if isfile(modelfile)\n",
    "    @load modelfile cpum\n",
    "    m = gpu(cpum)\n",
    "  end\n",
    "  \n",
    "  @time Flux.train!(loss, Flux.params(m), data, opt, cb = cb)\n",
    "  println(\"Sampling after 1 epoch:\")\n",
    "  sample(m, alphabet, 1000) |> println\n",
    "    \n",
    "  Flux.@epochs epochs Flux.train!(loss, Flux.params(m), data, opt,\n",
    "                                  cb = cb)\n",
    "  cpum = cpu(m)\n",
    "  @save modelfile cpum\n",
    "  return(m)\n",
    "end\n",
    "\n",
    "for L in [75] #, 32, 64, 128] #, 256, 512]\n",
    "  #L = 100\n",
    "  file = joinpath(docdir,\"jmd\",\"dylanlyrics-$L.jld2\")\n",
    "  m = Chain(LSTM(N, L), LSTM(L, L),  Dense(L, N),  softmax) |> gpu\n",
    "  #m = Chain(GRU(N, L), GRU(L, L), Dense(L, N),  softmax) |> gpu\n",
    "  opt=RMSProp(0.01)\n",
    "  m = train_model!(m, opt=opt, epochs=100, modelfile=file)\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")  \n",
    "  println(\"Model $L has $(sum([prod(size(p)) for p in Flux.params(m)])) parameters\")\n",
    "  println(\"Sample from model $L\")\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")\n",
    "  println(sample(m, alphabet, 5000))\n",
    "  println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
