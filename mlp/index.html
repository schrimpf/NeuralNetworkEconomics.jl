<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Multi-Layer -  </title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">
        <link href="../assets/extra.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href=".."> </a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Package Docs</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">ML in Economics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../ml-intro/" class="dropdown-item">Introduction</a>
</li>
                                    
<li>
    <a href="../ml-methods/" class="dropdown-item">Methods</a>
</li>
                                    
<li>
    <a href="../ml-doubledebiased/" class="dropdown-item">Inference</a>
</li>
                                    
<li>
    <a href="../mlExamplePKH/" class="dropdown-item">Detecting heterogeneity</a>
</li>
                                    
<li>
    <a href="../ml-julia/" class="dropdown-item">With Julia</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Neural Networks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../slp/" class="dropdown-item">Introduction</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">Multi-Layer</a>
</li>
                                    
<li>
    <a href="../conv/" class="dropdown-item">Convolutional</a>
</li>
                                    
<li>
    <a href="../rnn/" class="dropdown-item">Recurrent</a>
</li>
                                    
<li>
    <a href="../transformers/" class="dropdown-item">Transformers</a>
</li>
                                    
<li>
    <a href="../nn-semiparametric/" class="dropdown-item">In semiparametric models</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../license/" class="dropdown-item">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../slp/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../conv/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl/edit/master/docs/mlp.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            
            <li class="nav-item" data-level="1"><a href="#introduction" class="nav-link">Introduction</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#additional-reading" class="nav-link">Additional Reading</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#multiple-layer-neural-networks" class="nav-link">Multiple Layer Neural Networks</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#first-example" class="nav-link">First Example</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#image-classification-mnist" class="nav-link">Image Classification: MNIST</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#single-layer-classification" class="nav-link">Single Layer Classification</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#deep-classification" class="nav-link">Deep Classification</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#references-references" class="nav-link">References [references]</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h3 id="about-this-document">About this document<a class="headerlink" href="#about-this-document" title="Permanent link">&para;</a></h3>
<p>This document was created using Weave.jl. The code is available in <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl">on
github</a>. The same
document generates both static webpages and associated <a href="../mlp.ipynb">jupyter
notebook</a>.</p>
<p>
<script type="math/tex; mode=display">
\def\indep{\perp\!\!\!\perp}
\def\Er{\mathrm{E}}
\def\R{\mathbb{R}}
\def\En{{\mathbb{E}_n}}
\def\Pr{\mathrm{P}}
\newcommand{\norm}[1]{\left\Vert {#1} \right\Vert}
\newcommand{\abs}[1]{\left\vert {#1} \right\vert}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
</script>
</p>
<h1 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h1>
<p><a href="../slp/">The previous notes</a> discussed single layer neural networks.
These notes will look at multiple layer networks.</p>
<h2 id="additional-reading">Additional Reading<a class="headerlink" href="#additional-reading" title="Permanent link">&para;</a></h2>
<ul>
<li>Goodfellow, Bengio, and Courville (<a href="#ref-goodfellow2016">2016</a>)
    <a href="http://www.deeplearningbook.org"><em>Deep Learning</em></a></li>
<li><a href="https://denizyuret.github.io/Knet.jl/latest/"><code>Knet.jl</code>
    documentation</a>
    especially the textbook</li>
<li>Klok and Nazarathy (<a href="#ref-klok2019">2019</a>) <em>Statistics with
    Julia:Fundamentals for Data Science, MachineLearning and Artificial
    Intelligence</em></li>
<li>Farrell, Liang, and Misra (<a href="#ref-farrel2018">2018</a>) “Deep Neural
    Networks for Estimation and Inference”</li>
</ul>
<h1 id="multiple-layer-neural-networks">Multiple Layer Neural Networks<a class="headerlink" href="#multiple-layer-neural-networks" title="Permanent link">&para;</a></h1>
<p>A multiple layer feed forward neural network (aka a multi-layer
perception) connects many single layer networks. A multi-layer
perceptron can be written recursively. The outermost layer of a
multi-layer perception looks like a generalized linear model: <script type="math/tex; mode=display">
\hat{f}(x) = \psi_L(x_L' w_L+ b_L)
</script> where $x_L, w_L \in \R^{H_L}$, $b_L \in \R$, and $\psi_L: \R \to \R$.
For regression problems, $\psi_L$ is typically the identity function.</p>
<p>In a generalized linear model, $x_L$ would be data. In a multilayer
network, $x_L \in \R^{H_{L}}$ is the output of a previous layer.
Specificaly, for $k \in { 1, ...., H_L}$, <script type="math/tex; mode=display">
x_{k,L} = \psi_{k, L-1}(x_{L-1}'w_{k,L-1} + b_{k,L-1})
</script> where $x_{L-1}, w_{L-1} \in \R^{H_{L-1}}$, $b_{L-1} \in \R$, and
$\psi_{k,L-1}: \R \to \R$. This continues recursively until
$x_0 = x \in \R^d$ is the data.</p>
<p>$L$ is the <strong>depth</strong> of the network.</p>
<div class="alert alert-danger">
<p>When $L$ is sufficiently large, you have a deep neural network, and can
attract grant money by calling your research deep learning and/or AI.</p>
</div>
<p>$H_\ell$ is the <strong>width</strong> of layer $\ell$. Following Farrell, Liang, and
Misra (<a href="#ref-farrel2018">2018</a>), we will let <script type="math/tex; mode=display">
U = \sum_{\ell=1}^L H_\ell
</script> denote the number of units. The number of parameters is <script type="math/tex; mode=display"> 
W = \sum_{\ell=1}^L (H_{\ell-1}+1) H_\ell 
</script> where $H_0 = d$ is the dimension of the data.</p>
<p>In most applications, the activation within a layer is the same for each
unit, i.e. $\psi_{k,\ell}$ does not vary with $k$. In large networks
and/or with large datasets, activation functions are usually (leaky)
rectified linear to allow faster computation.</p>
<p>The combination of depths ($L$), width ($H_\ell$), and activation
functions ($\psi$) are collectively referred to as the network
architecture.</p>
<h2 id="first-example">First Example<a class="headerlink" href="#first-example" title="Permanent link">&para;</a></h2>
<p>As a starting example, here is some code that fits a multi-layer network
to the same simulated data as in <a href="../slp/">the notes on single layer
networks</a>.</p>
<p>Simulating data and setting up.</p>
<pre><code class="language-julia">using Plots, Flux, Statistics, ColorSchemes
# some function to estimate
f(x) = sin(x^x)/2^((x^x-π/2)/π)
function simulate(n,s=1)
  x = rand(n,1).*π
  y = f.(x) .+ randn(n).*s
  (x,y)
end
x, y = simulate(1000, 0.5)
xt = reshape(x, 1, length(x))
yt = reshape(y, 1, length(y))
xg = 0:0.01:π
cscheme = colorschemes[:BrBG_4];
dimx = 1
xt = reshape(Float32.(x), 1, length(x))
yt = reshape(Float32.(y), 1, length(y))
</code></pre>
<pre><code>1×1000 Array{Float32,2}:
 -0.797703  0.548108  0.240685  1.16682  …  1.05815  0.466921  0.783778
</code></pre>
<p>We now define our models. The second model is a multi-layer network with
3 layers each of width 3. The first model is a single-layer network with
width 15. This makes the total number of parameters in the two networks
equal. For both networks we normalise $x$ and then use Flux’s default
initial values (these set $b=0$ and $w$ random).</p>
<pre><code class="language-julia">models = [ Chain(x-&gt;Flux.normalise(x, dims=2),
                 Dense(dimx, 15, Flux.leakyrelu),
                 Dense(15, 1)),
           Chain(x-&gt;Flux.normalise(x, dims=2),
                 Dense(dimx, 3, Flux.leakyrelu),
                 Dense(3, 3, Flux.leakyrelu),
                 Dense(3, 3, Flux.leakyrelu),
                 Dense(3, 1))
           ]


figs = Array{typeof(plot(0)),1}(undef,length(models))
initmfigs = Array{typeof(plot(0)),1}(undef,length(models))

for r in eachindex(models)
  m = models[r]
  println(&quot;Model $r = $m&quot;)
  nparm = sum([length(m[i].W) + length(m[i].b) for i in 2:length(m)])
  println(&quot; $nparm parameters in $(length(m)-1) layers&quot;)
  initmfigs[r] = plot(xg, Tracker.data(m[1:(end-1)](xg'))', lab=&quot;&quot;, legend=false)  
  figs[r]=plot(xg, f.(xg), lab=&quot;&quot;, title=&quot;Model $r&quot;, color=:red)
  figs[r]=scatter!(x,y, alpha=0.4, markersize=1, markerstrokewidth=0, lab=&quot;&quot;)
  maxiter = 5000
  @time for i = 1:maxiter
    Flux.train!((x,y)-&gt;Flux.mse(m(x),y), Flux.params(m),
                #[(xt[:,b], yt[:,b]) for b in Base.Iterators.partition(1:length(yt), 500)],
                [(xt, yt)],
                Flux.AMSGrad() ) #,
                #cb = Flux.throttle(()-&gt;@show(Flux.mse(m(xt),yt)),100))
    if i==1 || (i % (maxiter ÷ 10)==0)
      l=Tracker.data(Flux.mse(m(xt), yt))
      println(&quot;Model $r, $i iterations, loss=$l&quot;)
      yg = Tracker.data(m(xg'))'
      loc=Int64.(ceil(length(xg)*i/maxiter))
      figs[r]=plot!(xg,yg, lab=&quot;&quot;, color=get(cscheme, i/maxiter), alpha=1.0,
                    annotations=(xg[loc], yg[loc],
                                 Plots.text(&quot;i=$i&quot;, i&lt;maxiter/2 ? :left : :right, pointsize=10,
                                            color=get(cscheme, i/maxiter)) )
                    )
    end
  end
  display(figs[r])
end
</code></pre>
<pre><code>Model 1 = Chain(#3, Dense(1, 15, leakyrelu), Dense(15, 1))
 46 parameters in 2 layers
Model 1, 1 iterations, loss=0.82055414
Model 1, 500 iterations, loss=0.26346454
Model 1, 1000 iterations, loss=0.2625347
Model 1, 1500 iterations, loss=0.2623096
Model 1, 2000 iterations, loss=0.26217508
Model 1, 2500 iterations, loss=0.26206267
Model 1, 3000 iterations, loss=0.26199454
Model 1, 3500 iterations, loss=0.2619396
Model 1, 4000 iterations, loss=0.26190692
Model 1, 4500 iterations, loss=0.26188213
Model 1, 5000 iterations, loss=0.2618579
 10.970610 seconds (24.46 M allocations: 2.843 GiB, 10.49% gc time)
Model 2 = Chain(#4, Dense(1, 3, leakyrelu), Dense(3, 3, leakyrelu), Dense(3
, 3, leakyrelu), Dense(3, 1))
 34 parameters in 4 layers
Model 2, 1 iterations, loss=0.5179933
Model 2, 500 iterations, loss=0.26679733
Model 2, 1000 iterations, loss=0.2666847
Model 2, 1500 iterations, loss=0.2666628
Model 2, 2000 iterations, loss=0.2666493
Model 2, 2500 iterations, loss=0.26664367
Model 2, 3000 iterations, loss=0.26663992
Model 2, 3500 iterations, loss=0.26663697
Model 2, 4000 iterations, loss=0.26663497
Model 2, 4500 iterations, loss=0.2666332
Model 2, 5000 iterations, loss=0.2666317
  3.132750 seconds (4.65 M allocations: 1.253 GiB, 9.18% gc time)
</code></pre>
<p><img alt="" src="../figures/mlp_3_1.png" /> <img alt="" src="../figures/mlp_3_2.png" /></p>
<p>In this simulation setup, the performance of the two network
architectures is hard to distinguish. The multi-layer network takes a
bit longer to train. Depending on the randomly simulated data, and
randomly drawn initial values, either model might achieve lower
in-sample MSE.</p>
<h1 id="image-classification-mnist">Image Classification: MNIST<a class="headerlink" href="#image-classification-mnist" title="Permanent link">&para;</a></h1>
<p><a href="http://yann.lecun.com/exdb/mnist/">MNIST is a database of images of handwritten
digits</a>. MNIST is a common machine
learning benchmark. Given a handwritten digit, we want to classify it is
a 0, 1, …, or 9. You can try a demo of a MNIST classifier trained in
Flux <a href="https://fluxml.ai/experiments/mnist/">here</a>.</p>
<p>Multilayer feed forward networks generally have good, but not quite
state-of-the-art performance in image classification. Nonetheless, this
will hopefully serve as a good example.</p>
<div class="alert alert-danger">
<p>The code in this section was adapted from the <a href="https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl">Flux model
zoo.</a></p>
</div>
<p>First we load some packages and download the data.</p>
<pre><code class="language-julia">using Flux, Flux.Data.MNIST, Statistics
using Flux: onehotbatch, onecold, crossentropy, throttle, @epochs
using Base.Iterators: repeated
using CuArrays
using BSON: @save, @load

imgs = MNIST.images()
labels = MNIST.labels()
length(labels)
</code></pre>
<pre><code>60000
</code></pre>
<p>Let’s look at some of the images.</p>
<pre><code class="language-julia">idx = rand(1:length(imgs), 16)
plot([plot(imgs[i], title=&quot;$(labels[i])&quot;, aspect_ratio=:equal, axis=false, ticks=false) for i in idx]...)
</code></pre>
<p><img alt="" src="../figures/mlp_5_1.png" /></p>
<p>The images are 28 by 28 pixels. I believe they were originally black ink
on white paper, but the colors are being inverted somewhere.</p>
<p>Continue processing the data</p>
<pre><code class="language-julia"># Stack images into one large batch 
X = hcat(float.(reshape.(imgs, :))...) |&gt; gpu;
# One-hot-encode the labels
Y = onehotbatch(labels, 0:9) |&gt; gpu;
</code></pre>
<p>One hot encoding is what the machine learning world calls creating dummy
variables from a categorical variable.</p>
<h2 id="single-layer-classification">Single Layer Classification<a class="headerlink" href="#single-layer-classification" title="Permanent link">&para;</a></h2>
<p>Now we define our neural network. To begin with we will look at single
hidden layer with a multinomial logit output layer. The function that
gives choice probabilities in a multinomial logit model is called the
<strong>softmax</strong> function. That is, <script type="math/tex; mode=display">
softmax(x_1, ..., x_k) = \left( \frac{e^{x_1}}{\sum_{j=1}^k e^{x_i}},
\frac{e^{x_2}}{\sum_{j=1}^k e^{x_i}}, ..., \frac{e^{x_k}}{\sum_{j=1}^k
e^{x_i}} \right)
</script>
</p>
<pre><code class="language-julia">m = Chain(
  Dense(28^2, 32, relu),
  Dense(32, 10),
  softmax) |&gt; gpu
</code></pre>
<pre><code>Chain(Dense(784, 32, relu), Dense(32, 10), softmax)
</code></pre>
<p>In this example, we are working on a classification problem; we are
trying to predict a discrete outcome instead of a continuous one. The
output of the network above are probabilities that an image represents
each of the ten digits. That is, we forming conditional probability, or
the likelihood, of $y$ given $x$. In this situation, maximum likelihood
is a natural estimator. For discrete $y$ (like we have here), the log
likelihood is equal to minus the cross-entropy, so this is what we use
as our loss function.</p>
<pre><code class="language-julia">loss(x, y) = crossentropy(m(x), y)
</code></pre>
<pre><code>loss (generic function with 1 method)
</code></pre>
<p>Since cross-entropy or log likelihood are difficult to interpret, we
might want a more intuitive measure of our model’s performance. For
classification <strong>accuracy</strong> is the portion of predictions that are
correct.</p>
<div class="alert alert-danger">
<p><strong>Other measures of classification performance</strong></p>
<p>For this application accuracy is likely sufficient, but in some
situations (including rare outcomes or when we weight differently type I
and type II errors) accuracy is not a sufficient measure of a
classifier’s performance. There are variety of other measures, such as
precision, recall, and AUC. See Batista et al. (<a href="#ref-qeclassify">2019</a>)
for <a href="https://datascience.quantecon.org/applications/classification.html">more
information</a>.</p>
</div>
<pre><code class="language-julia">accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))
</code></pre>
<pre><code>accuracy (generic function with 1 method)
</code></pre>
<p><code>onecold</code> is the inverse of one-hot-encoding; <code>onecold</code> transforms a
matrix of dummy varibles (or probabilities) into an integer (the one
with the highest probability in the case of <code>m(x)</code>).</p>
<pre><code class="language-julia">dataset = repeated((X, Y), 200) # each call to Flux.trian! will do 200
# gradient descent steps using the full X and Y to compute gradients
Xsmall=X[:,1:1000]
Ysmall=Y[:,1:1000] # accuracy is slower, so only compute on subset of data

# Test set 
tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |&gt; gpu
tY = onehotbatch(MNIST.labels(:test), 0:9) |&gt; gpu

evalcb = () -&gt; @show(loss(X, Y), accuracy(Xsmall,Ysmall), accuracy(tX,tY)) 
opt = ADAM()
</code></pre>
<pre><code>ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())
</code></pre>
<p>Since <code>Flux.train!</code> might run for a long time, it allows us to pass a
“callback” function that gets evaluated every iteration. Here, this
function is just used to monitor progress. In some situations, we might
also want to use the callback function to save intermediate results to
disk in case the computation gets interrupted before completion. The
<code>Flux.throttle</code> function can be used to prevent the call-back function
from being evaluated too often. The code below makes <code>evalcb</code> get
evaluated at most once every 10 seconds.</p>
<pre><code class="language-julia">rerun = false
modelfile = joinpath(docdir,&quot;jmd&quot;,&quot;bson&quot;,&quot;mnist-slp.bson&quot;)
if rerun || !isfile(modelfile)
  evalcb()
  @time Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))
  evalcb()

  # save model
  cpum = cpu(m)
  @save modelfile cpum
else
  @load modelfile cpum
  m = gpu(cpum)
end
</code></pre>
<pre><code>Chain(Dense(784, 32, relu), Dense(32, 10), softmax)
</code></pre>
<pre><code class="language-julia">@show accuracy(X, Y)
</code></pre>
<pre><code>accuracy(X, Y) = 0.9257166666666666
</code></pre>
<pre><code class="language-julia">@show accuracy(tX, tY);
</code></pre>
<pre><code>accuracy(tX, tY) = 0.9267
</code></pre>
<p>After 200 iterations, the accuracy is already greater than 90%. This is
pretty good.</p>
<p>The test set accuracy is higher than the training set, which could just
be good luck, but it is also possible that the model is underfitting.
Let’s try training the network longer (doing more gradient descent
iterations.</p>
<pre><code class="language-julia">rerun = false
modelfile = joinpath(docdir,&quot;jmd&quot;,&quot;bson&quot;,&quot;mnist-slp-2200.bson&quot;)
if rerun || !isfile(modelfile)
  evalcb()
  @time @epochs 10 Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))
  evalcb()

  # save model
  cpum = cpu(m)
  @save modelfile cpum
else
  @load modelfile cpum
  m = gpu(cpum)
end
@show accuracy(X, Y)
</code></pre>
<pre><code>accuracy(X, Y) = 0.9909166666666667
</code></pre>
<pre><code class="language-julia">@show accuracy(tX,tY);
</code></pre>
<pre><code>accuracy(tX, tY) = 0.9639
</code></pre>
<p>Remember that each “epoch” does one gradient descent step for each tuple
in <code>dataset</code>. In the code above <code>dataset</code> is just the original data
repeated 200 times. We ran for 10 epochs, so there were a total of 2000
more gradient descent iterations. We see that the training accuracy has
improved to above 99%, but our test accuracy has failed to improve much
above 96%.</p>
<p>My initial interpretation of this result would be that we are now
overfitting. The number of parameters in the network is</p>
<pre><code class="language-julia">nparam(m) = sum([length(m[i].W) + length(m[i].b) for i in 1:length(m) if typeof(m[i]) &lt;: Dense])
nparam(m)
</code></pre>
<pre><code>25450
</code></pre>
<p>and there 60000 images. For a typical econometric or statistic problem,
there are too many parameters for the number of observations. One
solution to this situation is to reduce the number of parameters.
Another solution is to do what lasso does and <strong>regularize</strong>. Lasso
regularizes by adding a penalty to the loss function. Limiting the
number of gradient descent iterations can also act as a form of
regularization. This is often called <a href="https://en.wikipedia.org/wiki/Landweber_iteration">Landweber
regularization</a>. It
underlies the common procedure of training a neural network until the
training loss starts to be much less than loss on a held out portion of
the data (or the loss on the held out portion stops decreasing).</p>
<h2 id="deep-classification">Deep Classification<a class="headerlink" href="#deep-classification" title="Permanent link">&para;</a></h2>
<p>Given the apparent overfitting of the single layer network above, I
would be reluctant to move to an even more complex model. However, I
would be mistaken. If you glance through the <a href="http://yann.lecun.com/exdb/mnist/">MNIST benchmarks on
LeCun’s website</a>, you will see that
Ciresan et al. (<a href="#ref-ciresan2010">2010</a>) achieve a much higher test
accuracy with a 6 layer network. Let’s try their network architecture.
We will use their numbers of layers and hidden units, but with rectified
linear activation. They used tanh activation functions.</p>
<pre><code class="language-julia">cmgsnet = Chain(
  Dense(28^2, 2500 , relu),
  Dense(2500, 2000 , relu),
  Dense(2000, 1500 , relu),
  Dense(1500, 1000 , relu),
  Dense(1000, 500 , relu),
  Dense(500, 10),
  softmax) |&gt; gpu
loss(x, y) = crossentropy(cmgsnet(x), y)
accuracy(x, y) = mean(onecold(cmgsnet(x)) .== onecold(y))
evalcb = () -&gt; @show(loss(X, Y), accuracy(Xsmall,Ysmall), accuracy(tX,tY)) 

println(&quot;cmgsnet has $(nparam(cmgsnet)) parameters!!!&quot;)
</code></pre>
<pre><code>cmgsnet has 11972510 parameters!!!
</code></pre>
<p>That’s a deep network.</p>
<pre><code class="language-julia">rerun = false
batchsize=30000 
parts=Base.Iterators.partition(1:size(X,2), batchsize) 
data = repeat([(X[:,p], Y[:,p]) for p in parts], 10);
# The full data + network doesn't fit in my GPU memory, so do 2 batches
epochs = 20
acctest  = zeros(epochs)
acctrain = zeros(epochs)
losstest  = zeros(epochs)
losstrain = zeros(epochs)
for e in 1:epochs
  modelfile = joinpath(docdir,&quot;jmd&quot;,&quot;bson&quot;,&quot;cmgsnet-$e-epochs.bson&quot;)
  global cmgsnet 
  if rerun || !isfile(modelfile)
    println(&quot;Beginning epoch $e&quot;)
    evalcb()
    @show cmgsnet
    @time Flux.train!(loss, params(cmgsnet), data, opt, cb = throttle(evalcb, 10))
    evalcb()

    # save model
    cpum = cpu(cmgsnet)
    @save modelfile cpum
  else
    @load modelfile cpum
    cmgsnet = gpu(cpum)
  end
  println(&quot;Finished $e epochs&quot;)
  losstrain[e]=Tracker.data(loss(X,Y))
  acctrain[e]=accuracy(X, Y)
  losstest[e]=Tracker.data(loss(tX,tY))
  acctest[e]=accuracy(tX,tY)
end
</code></pre>
<pre><code>Finished 1 epochs
Finished 2 epochs
Finished 3 epochs
Finished 4 epochs
Finished 5 epochs
Finished 6 epochs
Finished 7 epochs
Finished 8 epochs
Finished 9 epochs
Finished 10 epochs
Finished 11 epochs
Finished 12 epochs
Finished 13 epochs
Finished 14 epochs
Finished 15 epochs
Finished 16 epochs
Finished 17 epochs
Finished 18 epochs
Finished 19 epochs
Finished 20 epochs
</code></pre>
<p>This model achieved a testing accuracy of 98.37% after 13 training
epochs. Each training epoch consisting of 10 passes through the data
split into two batches, so 20 gradient descent iterations. Let’s plot
the loss and accuracy vs epoch.</p>
<pre><code class="language-julia">plot(
  plot([losstrain, losstest], xscale=:log10, xlab=&quot;Epochs&quot;, title=&quot;Cross-Entropy Loss&quot;,
       annotations=[(15, losstrain[15],
                     Plots.text(&quot;training&quot;, pointsize=12, valign=:bottom,
                                 color=get(cscheme,1))),
                    (15, losstest[15],
                     Plots.text(&quot;test&quot;, pointsize=12, valign=:bottom,
                                color=get(cscheme,0)))], leg=false,
       color_palette=get(cscheme,[1,0])
       ),
  plot([acctrain, acctest], xscale=:log10, xlab=&quot;Epochs&quot;, title=&quot;Accuracy&quot;,
       leg=false,
       color_palette=get(cscheme,[1,0])
       ),
  layout=(2,1)
)
</code></pre>
<p><img alt="" src="../figures/mlp_17_1.png" /></p>
<p>There is really something remarkable going on in this example. A model
that appears extremely overparameterized manages to predict very well on
a test set.</p>
<p>One important thing to keep in mind is that image classification is very
different from the typical estimation problems in applied economics. In
regressions and other models of economic variables, we never expect to
be able to predict perfectly. An $R^2$ of 0.4 in a cross-sectional
earnings regression is typical, or even high. Image classification is
very different. We know there is a model (our eyes) that can classify
nearly perfectly. In the language of econometrics, the error term is
zero, or there is no uncertainty, in the “true” image classification
models.</p>
<p>TODO: Add an aside about adversarial examples and failures to
generalize.</p>
<p>Let’s look at some of the images that our model failed to classify
correctly.</p>
<pre><code class="language-julia">tlabels = MNIST.labels(:test)
timgs = MNIST.images(:test)
# predicted labels
mlabels = cpu(onecold(cmgsnet(tX))).-1
@show mean(mlabels.==tlabels) # = accuracy
</code></pre>
<pre><code>mean(mlabels .== tlabels) = 0.9836
</code></pre>
<pre><code class="language-julia">@show sum(mlabels .!= tlabels)
</code></pre>
<pre><code>sum(mlabels .!= tlabels) = 164
</code></pre>
<pre><code class="language-julia">miss=findall(mlabels .!= tlabels)
plot( [plot(timgs[i], axis=false, ticks=false, title=&quot;$(tlabels[i]) as $(mlabels[i])&quot;, aspect_ratio=:equal) for i in miss[1:16]]...)
</code></pre>
<p><img alt="" src="../figures/mlp_18_1.png" /></p>
<p>Our model still does not have state-of-the-art accuracy. Ciresan et al.
(<a href="#ref-ciresan2010">2010</a>) achieves 99.65% accuracy. There are
differences in terms of activation function and gradient descent details
between Ciresan et al. (<a href="#ref-ciresan2010">2010</a>) and the code above.
However, I suspect that the main reason for their better performance is
that Ciresan et al. (<a href="#ref-ciresan2010">2010</a>) generate additional
training images. They do this by randomly rotating, stretching, and
adding oscillations to the existing images.</p>
<h1 id="references-references">References [references]<a class="headerlink" href="#references-references" title="Permanent link">&para;</a></h1>
<div class="references" id="refs">
<div id="ref-qeclassify">
<p>Batista, Quentin, Chase Coleman, Spencer Lyon, Jesse Perla, Thomas
Sargent, Paul Schrimpf, and Natasha Watkins. 2019. “Classification.” In
<em>QuantEcon Datascience: Introduction to Economic Modeling and Data
Science</em>.
<a href="https://datascience.quantecon.org/applications/classification.html">https://datascience.quantecon.org/applications/classification.html</a>.</p>
</div>
<div id="ref-ciresan2010">
<p>Ciresan, Dan Claudiu, Ueli Meier, Luca Maria Gambardella, and Juergen
Schmidhuber. 2010. “Deep Big Simple Neural Nets Excel on Handwritten
Digit Recognition.” <a href="https://doi.org/10.1162/NECO_a_00052">https://doi.org/10.1162/NECO_a_00052</a>.</p>
</div>
<div id="ref-farrel2018">
<p>Farrell, Max H., Tengyuan Liang, and Sanjog Misra. 2018. “Deep Neural
Networks for Estimation and Inference.”
<a href="https://arxiv.org/abs/1809.09953">https://arxiv.org/abs/1809.09953</a>.</p>
</div>
<div id="ref-goodfellow2016">
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep
Learning</em>. MIT Press. <a href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a>.</p>
</div>
<div id="ref-klok2019">
<p>Klok, Hayden, and Yoni Nazarathy. 2019. <em>Statistics with
Julia:Fundamentals for Data Science, Machinelearning and Artificial
Intelligence</em>. DRAFT.
<a href="https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf">https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf</a>.</p>
</div>
</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
