{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title       : \"Recurrent Neural Networks\" \n",
    "subtitle    : \"\"\n",
    "author      : Paul Schrimpf\n",
    "date        : `j using Dates; print(Dates.today())`\n",
    "bibliography: \"../ml.bib\"\n",
    "options:\n",
    "      out_width : 100%\n",
    "      wrap : true\n",
    "      fig_width : 800\n",
    "      fig_height : 800\n",
    "      dpi : 192\n",
    "---\n",
    "\n",
    "[![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution-ShareAlike\n",
    "4.0 International\n",
    "License](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "\n",
    "### About this document \n",
    "\n",
    "This document was created using Weave.jl. The code is available in\n",
    "[on github](https://github.com/schrimpf/NeuralNetworkEconomics.jl). The same\n",
    "document generates both static webpages and associated [jupyter\n",
    "notebook](rnn.ipynb). \n",
    "\n",
    "$$\n",
    "\\def\\indep{\\perp\\!\\!\\!\\perp}\n",
    "\\def\\Er{\\mathrm{E}}\n",
    "\\def\\R{\\mathbb{R}}\n",
    "\\def\\En{{\\mathbb{E}_n}}\n",
    "\\def\\Pr{\\mathrm{P}}\n",
    "\\newcommand{\\norm}[1]{\\left\\Vert {#1} \\right\\Vert}\n",
    "\\newcommand{\\abs}[1]{\\left\\vert {#1} \\right\\vert}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/.julia/dev/NeuralNetworkEconomics/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "source": [
    "markdown = try\n",
    "  \"md\" in keys(WEAVE_ARGS) && WEAVE_ARGS[\"md\"]\n",
    "catch\n",
    "  false\n",
    "end\n",
    "\n",
    "if !(\"DISPLAY\" ∈ keys(ENV))\n",
    "  # Make gr and pyplot backends for Plots work without a DISPLAY\n",
    "  ENV[\"GKSwstype\"]=\"nul\"\n",
    "  ENV[\"MPLBACKEND\"]=\"Agg\"\n",
    "end\n",
    "# Make gr backend work with λ and other unicode\n",
    "ENV[\"GKS_ENCODING\"] = \"utf-8\"\n",
    "\n",
    "using NeuralNetworkEconomics\n",
    "docdir = joinpath(dirname(Base.pathof(NeuralNetworkEconomics)), \"..\",\"docs\")\n",
    "\n",
    "using Pkg\n",
    "Pkg.activate(docdir)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Previous notes have covered [single layer](slp.md), [multi\n",
    "layer](mlp.md), and [convolutional](conv.md) feed forward networks. \n",
    "In feed forward networks, the outputs of one layer are fed into the\n",
    "next layer, always moving toward the output. Recurrent networks break\n",
    "this pattern. In recurrent networks, outputs of one layer are feed\n",
    "back into the same. This always the network to maintain a hidden\n",
    "state. Recurrent networks are typically used to model sequential\n",
    "data. There are many applications to time series. Recurrent networks\n",
    "are also useful for processing text and audio data. \n",
    "\n",
    "## Additional Reading\n",
    "\n",
    "- @goodfellow2016 [*Deep Learning*](http://www.deeplearningbook.org)\n",
    "  especially chapter 10\n",
    "- [`Knet.jl`\n",
    "  documentation](https://denizyuret.github.io/Knet.jl/latest/)\n",
    "  especially the textbook\n",
    "- @klok2019 *Statistics with Julia:Fundamentals for Data Science,\n",
    "  MachineLearning and Artificial Intelligence*\n",
    "   \n",
    "# Recurrent Networks\n",
    "\n",
    "Recurrent Networks are designed to predict a sequence of outputs,\n",
    "$y_t$, given a sequence of inputs, $x_t$, where $t=1, ...,T$, The\n",
    "relationship between $x$ and $y$ is assumed to be stationary, but we\n",
    "will allow there to be possibly many values from the history of $x$ to\n",
    "affect $y$. We do this by introducing a hidden state, $h_t$. The\n",
    "prediction for $y_t$ is only a function of $h_t$, say\n",
    "$\\hat{y}(h_t)$. The hidden state is Markovian with \n",
    "$$\n",
    "h_t = f(h_{t-1}, x_t).\n",
    "$$\n",
    "Both $\\hat{y}()$ and $f()$ are constructed from neural\n",
    "networks. They could simply be single layer perceptrons, or any of the\n",
    "more complicated network architectures we previously discussed.\n",
    "\n",
    "## Approximation Ability\n",
    "\n",
    "Recurrent networks can approximate (in fact can equal) any computable\n",
    "function. @siegelmann1991 and @siegelmann1992 show that recurrent\n",
    "neural networks are Turing complete. As with the universal\n",
    "approximation ability of feed forward networks, this result is good to\n",
    "know, but it is not an explanation for the good practical performance\n",
    "of recurrent networks. \n",
    "\n",
    "When $h_t$ is large enough, it is easy to see how the recurrent model\n",
    "above can equal familiar time series econometric models. For example,\n",
    "for an AR(P) model, \n",
    "$$\n",
    "y_t = \\rho_1 y_{t-1} + \\cdots + \\rho_p y_{t-p} + \\epsilon_t \n",
    "$$\n",
    "To express this model in recurrent state-space form, \n",
    "let $x_t = y_{t-1}$, and $h_t = (y_{t-1, \\cdots, y_{t-p}) \\in \\R^p$. \n",
    "Then we can set \n",
    "$$\n",
    "f(h_{t-1}, x_t) = (x_t, h_{t-1,1}, \\cdots , h_{t-1, p-1})\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{y}(h_t) = \\rho' h_t,\n",
    "$$\n",
    "\n",
    "## Stability and Gradients\n",
    "\n",
    "Recursive neural networks can be difficult to train. The difficulty\n",
    "stems from how the gradient of the network behaves very differently\n",
    "depending on whether the dynamics are stable. To illustrute, suppose\n",
    "$f()$ is linear,\n",
    "$$\n",
    "h_t = f_h h_{t-1} + f_x x_t\n",
    "$$\n",
    "and the loss function is MSE\n",
    "$$\n",
    "\\mathcal{L}(f_h,f_x) = \\frac{1}{T} \\sum_{t=1}^T (\\hat{y}(h_t)- y_t)^2\n",
    "$$\n",
    "The derivatives of the loss function with respect to the parameters of\n",
    "$f$ are then:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial f_h} & = \\frac{2}{T} \\sum (\\hat{y}(h_t)-\n",
    "y_t)\\hat{y}'(h_t) \\left(t f_h^{t-1} h_0 + \\sum_{s=1}^{t-1}\n",
    "(t-s)f_h^{t-s-1} f_x x_{t-s} \\right) \\\\\n",
    "\\frac{\\partial}{\\partial f_x} & = \\frac{2}{T} \\sum (\\hat{y}(h_t)- y_t) \n",
    "    \\hat{y}'(h_t) \n",
    "    \\left(\\sum_{s=1}^{t} x_s f_h^{t-s} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "Both of these involve increasing powers of $f_h^t$. If $h_t$ has\n",
    "stable dynamics, i.e. $|f_h|<1$, then these derivatives will be\n",
    "dominated by the terms involving more recent values of $x_t$. If $h_t$\n",
    "has explosive dynamics, $|f_h|>1$, then these derivatives will be\n",
    "dominated by the terms involving the earlist $x_t$. Depending on the\n",
    "stability of $f$, gradients will be dominated by either short term\n",
    "dependence between $x$ and $y$ or long term. This behavior makes it\n",
    "difficult to train a network where both short and long term\n",
    "dependencies are important. \n",
    "\n",
    "The previous analysis also apply to nonlinear $f()$, with $f_h$\n",
    "replaced by $(\\partial f)/(\\partial h)$, and stable replaced with\n",
    "locally stable. \n",
    "\n",
    "The previous analysis also applies to multivariate $h_t$ with $|f_h|$\n",
    "replace by $\\max |eigenvalue(f_h)|$.\n",
    "\n",
    "## Truncating Gradients\n",
    "\n",
    "A practical problem with gradients of recurrent networks is that \n",
    "$\\hat{y}(h_t)$ depends on the entire history of \n",
    "$x_1, \\cdots, x_t$. When computing the gradient by backward\n",
    "differentiation, this entire history will accumulate, using up memory\n",
    "and taking time. A common solution is to truncate the gradient\n",
    "calculation after some fixed number of periods. \n",
    "\n",
    "\n",
    "## LSTM\n",
    "\n",
    "Long Short-Term Memory networks were designed to avoid the problem of\n",
    "vanishing and exploding gradients. LSTMs have an additional hiddent\n",
    "state, $s_t$. The extra hidden state is $s_t \\in (0,1)$ and is a\n",
    "weighted sum of $s_{t-1}$ and other variables. In particular,\n",
    "$$\n",
    " s_t = \\sigma(b_f + U_f' x_t + W_f' h_{t-1}) s_{t-1} + \\sigma(b_g + U_g'\n",
    " x_t + W_g' h_{t-1}) \\tilde{x}_t \n",
    "$$\n",
    "The first $\\sigma(b_f + U_f' x_t + W_f' h_{t-1})$ is a \"forget\"\n",
    "gate. It determines how much of $s_{t-1}$ is forgotten. \n",
    "The second $\\sigma(b_g + U_g' x_t + W_g' h_{t-1})$ is call the\n",
    "external input gate. It determines how much current $x_t$ affects\n",
    "$s_t$. The $\\tilde{x}$ is a rescaled input given by\n",
    "$$\n",
    "\\tilde{x}_t = \\sigma(\\tilde{b} + \\tilde{U}'x_t + \\tilde{W}' h_{t-1}).\n",
    "$$\n",
    "Finally, $h_t$ is a gated and transformed version of $s_t$.\n",
    "$$ \n",
    "h_t = tanh(s_t) \\sigma(b_o + U_o' x_t + W_o'h_t)\n",
    "$$\n",
    "where $\\sigma(b_o + U_o' x_t + W_o'h_t)$ is the output gate. \n",
    "\n",
    "# Example : Generating Dylan Songs\n",
    "\n",
    "Recurrent neural networks are pretty good at randomly generating\n",
    "text. The \n",
    "[Flux model zoo](https://github.com/FluxML/model-zoo/blob/master/text/char-rnn/char-rnn.jl)\n",
    "includes one such example. The example is based on this [blog post by\n",
    "Andrej\n",
    "Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). It \n",
    "predicts each individual character given past characters. This works\n",
    "suprisingly well. We are going to repeat this exercise, but use Bob\n",
    "Dylan songs as input.\n",
    "\n",
    "\n",
    "## Downloading Songs\n",
    "\n",
    "We download all Bob Dylan lyrics and chords from\n",
    "[dylanchords.info](http://dylanchords.info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2873103-element Array{Char,1}:\n",
       " '\\n'\n",
       " '<' \n",
       " '?' \n",
       " 'x' \n",
       " 'm' \n",
       " 'l' \n",
       " ' ' \n",
       " 'v' \n",
       " 'e' \n",
       " 'r' \n",
       " 's' \n",
       " 'i' \n",
       " 'o' \n",
       " ⋮   \n",
       " 'y' \n",
       " '>' \n",
       " '\\n'\n",
       " '<' \n",
       " '/' \n",
       " 'h' \n",
       " 't' \n",
       " 'm' \n",
       " 'l' \n",
       " '>' \n",
       " '\\n'\n",
       " '\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ProgressMeter, JLD2\n",
    "import HTTP, Gumbo, Cascadia\n",
    "\n",
    "infile = joinpath(docdir,\"jmd\",\"dylanchords.txt\")\n",
    "\n",
    "if !isfile(infile)\n",
    "  r=HTTP.get(\"http://dylanchords.info/alphabetical_list_of_songs.htm\")\n",
    "  songlist=Gumbo.parsehtml(String(r.body));\n",
    "  songlinks = eachmatch(Selector(\".songlink\"), songlist.root)\n",
    "  songhtml = Array{String, 1}(undef, length(songlinks))\n",
    "  p = Progress(length(songlinks),1,\"Downloading songs\", 50)\n",
    "  for s ∈ eachindex(songlinks)\n",
    "    url = songlinks[s].attributes[\"href\"]\n",
    "    if url == \"index.htm\"\n",
    "      songhtml[s] = \"\"\n",
    "      continue\n",
    "    end\n",
    "    r = HTTP.get(\"http://dylanchords.info/\"*url)\n",
    "    songhtml[s]=String(r.body)\n",
    "    next!(p)\n",
    "  end\n",
    "  \n",
    "  open(infile, \"w\") do io\n",
    "    for s ∈ songhtml\n",
    "      write(io, s)\n",
    "      write(io,\"\\n\")\n",
    "    end\n",
    "  end  \n",
    "end\n",
    "\n",
    "text = collect(String(read(infile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the input text here are html files. Here is the start of one\n",
    "song.\n",
    "```\n",
    "<head>\n",
    "<title>My Back Pages</title>\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/general.css\" />\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "<h1 class=\"songtitle\">My Back Pages</h1>\n",
    "\n",
    "\n",
    "<p>Words and music Bob Dylan<br />\n",
    "Released on <a class=\"recordlink\" href=\"../04_anotherside/index.htm\">Another Side Of Bob Dylan</a> (1964) and <a class=\"recordlink\" href=\"../99_greatesthits2/index.htm\">Greatest Hits II</a> (1971)<br />\n",
    "Tabbed by Eyolf &Oslash;strem</p>\n",
    "\n",
    "<p>Most G's are played with a small figure (G - G6 - G7) going up to G7:</p>\n",
    "<pre class=\"chords\">\n",
    "G  320003\n",
    "G6 322003\n",
    "G7 323003\n",
    "</pre>\n",
    "\n",
    "<p>This is noted with a *).</p>\n",
    "\n",
    "<p>He didn't seem to spend too much time rehearsing this song before he\n",
    "went into the studio (the whole album was recorded in one\n",
    "evening/night session) &ndash; he gets the first verse all wrong in the\n",
    "chords, and he struggles a lot with the final lines of each\n",
    "verse. I've written out the chords for the first two verses and in the\n",
    "following verses deviations from the <em>second</em> verse.</p>\n",
    "\n",
    "<p>Capo 3rd fret (original key Eb major)</p>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<pre class=\"verse\">\n",
    "C       Am          Em\n",
    "Crimson flames tied through my ears\n",
    "        F        G *)   C\n",
    "Rollin' high and mighty traps\n",
    "C            Am      Em      C\n",
    "Pounced with fire on flaming roads\n",
    "      F     Em    G   *)\n",
    "Using ideas as my maps\n",
    "       F       Am     G *)        C\n",
    "&quot;We'll meet on edges, soon,&quot; said I\n",
    "Am                  F G\n",
    "Proud 'neath heated brow\n",
    "        C             Am    C\n",
    "Ah, but I was so much older then\n",
    "    F       G *)      C       G *)\n",
    "I'm younger than that now.\n",
    "```\n",
    "\n",
    "Some songs include snippets of tablature (simple notation for guitar).\n",
    "For example, \n",
    "\n",
    "```\n",
    "<p>The easiest way to play the G7sus4 G7 G7sus2 G7 figure would be:</p>\n",
    "<pre class=\"verse\">\n",
    "G7sus4  G7  G7sus2  G7\n",
    "|-1-----1-----1-----1---\n",
    "|-0-----0-----0-----0---\n",
    "|-0-----0-----0-----0---\n",
    "|-0-----0-----0-----0---\n",
    "|-3-----2-----0-----2---\n",
    "|-3-----3-----3-----3---\n",
    "</pre>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<p>Intro:</p>\n",
    "<pre class=\"tab\">\n",
    "  C           G/b           F/a         G11   G       C/e\n",
    "  :     .       :     .       :     .       :     .        :     .\n",
    "|-------0-----|-------3-----|-------1-----|--------------|-------0------\n",
    "|-----1---1---|-----0-------|-----1-1---1-|---1---010----|-----1---1----\n",
    "|---0-------0-|---0-----0---|---2-----1---|-2---2----0---|---0-------0-- etc\n",
    "|-------------|-------------|-------------|------------3-|-2------------\n",
    "|-3-----------|-2---------2-|-0-----------|--------------|--------------\n",
    "|-------------|-------------|-------------|-3------------|--------------\n",
    "</pre>\n",
    "```\n",
    "This is all just text, and we will treat it is a such. However, it has\n",
    "additional structure that makes it more interesting to predict than\n",
    "the text of just lyrics. \n",
    "\n",
    "## Markovian Baseline\n",
    "\n",
    "As [Yoav Goldberg point\n",
    "out](https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139), you\n",
    "can generate pretty good text with a simple Markovian model of\n",
    "characters. That is, estimate the probability of a character $c$ given\n",
    "a history of $L$ characters $h$, $P(c_t|c_{t-1}, ..., c_{t-L})$, by\n",
    "simple sample averages. Let's try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Symbol,1}:\n",
       " :dm"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using StaticArrays\n",
    "\n",
    "function p_markov(len::Val{L}, data::AbstractVector{Char}) where L\n",
    "  dm = Dict{SVector{L, Char}, Dict{Char, Float64}}()\n",
    "  p = Progress(length(data), 1, \"count_markov($L)\", 30)\n",
    "  for t in (1+L):length(data)\n",
    "    key = @view data[(t-L):(t-1)]\n",
    "    entry=get!(dm, key, Dict(data[t] => 0))\n",
    "    v = get!(entry, data[t], 0)\n",
    "    entry[data[t]] += 1\n",
    "    next!(p)\n",
    "  end\n",
    "  for k in keys(dm)\n",
    "    total = sum(values(dm[k]))\n",
    "    for e in keys(dm[k])\n",
    "      dm[k][e] /= total\n",
    "    end\n",
    "  end\n",
    "  dm\n",
    "end\n",
    "\n",
    "modelfile=joinpath(docdir,\"jmd\",\"dylan-markov4.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else \n",
    "  @time dm = p_markov(Val(4), text);\n",
    "  @save modelfile dm    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code stores $P(c_t|c_{t-1},...,c_{t-L})$ in a\n",
    "dictionary. When $L$ is large, there are huge number of possible\n",
    "histories, $c_{t-1},...,c_{t-L}$, and we will not observe many of\n",
    "them. A dictionary only stores data on the histories we observe, so it\n",
    "will save some memory.\n",
    "\n",
    "Let's now sample from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (88032, 2873103)\n",
      "tle>\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/general.css\" href=\"../99_greated\n",
      "\n",
      "F/a         D\n",
      "lone\n",
      "/b     F\n",
      "Carted kissed by the versition cally if I head>\n",
      "<title\">Before wine.\n",
      "</p>\n",
      "\n",
      "<head>\n",
      "\n",
      "<pre class=\"verse; end juney babe, what down the says, the welcome singin' track\n",
      "This he was they Are your time to the ground movie said not for a voice\n",
      "What the songverses no Child watch\n",
      "       :  .   .   .           C/g\n",
      "He's already is recordlink rel=\"stylesheet\" type=\"text/css/general.css\" href=\"http://www.w3.org/1999/xhtml\">\n",
      "\n",
      "<p>Words and road himself.\n",
      "         *)     Dsus4 (x022222)</p>\n",
      "\n",
      "<h1 class=\"verse\">\n",
      "E          :   .\n",
      "|-------------|\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "F                   And Belton the have to gets have me who way                           E7    G7\n",
      "Is world begin,\n",
      "And a dime.\n",
      "\n",
      "The die in my send of Vicks, babe, wheezin' unfinity\n",
      "Go find no struments ran on the moo, I'll notion, girl take message said, &quot;Jailer, which\n",
      "There\n",
      "And they'll how the paraph/index.htm\">Bio\n"
     ]
    }
   ],
   "source": [
    "defaultinit=collect(\"\\n\\n<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Strict//EN\\\"\\n\\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\\">\\n<html lang=\\\"en\\\" xml:lang=\\\"en\\\" xmlns=\\\"http://www.w3.org/1999/xhtml\\\">\\n\\n<head>\\n<title>\")\n",
    "\n",
    "function sample_markov(dm::Dict{SVector{L, Char}, Dict{Char, Float64}}, len=1000,\n",
    "                       init=defaultinit) where L\n",
    "  out = Array{Char,1}(undef,len)\n",
    "  state = MVector{L, Char}(init[(end-L+1):end])\n",
    "  out[1:L] .= state\n",
    "  for s=L+1:len\n",
    "    u = rand()\n",
    "    cp = 0.0\n",
    "    for k in keys(dm[state])\n",
    "      cp += dm[state][k]\n",
    "      if (u<= cp)\n",
    "        out[s]=k\n",
    "        break\n",
    "      end\n",
    "    end\n",
    "    state[1:(end-1)] .= state[2:end]\n",
    "    state[end] = out[s]    \n",
    "  end\n",
    "  out\n",
    "end\n",
    "\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning on histories of length 4, we get some hints of\n",
    "Dylan-esque lyrics, but we also get a lot of gibberish. Let's try\n",
    "longer histories.\n",
    "\n",
    "### Length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (930264, 2873103)\n",
      "d>\n",
      "<title>Positively van Gogh</title>\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/general.css\" />\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "\n",
      "<h1 class=\"songtitle\">Outlaw Blues</h1>\n",
      "\n",
      "\n",
      "<p>Sung by Bob Dylan 11 times in the way.\n",
      "</pre>\n",
      "\n",
      "</body></html>\n",
      "\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "\"http://www.w3.org/1999/xhtml\">\n",
      "\n",
      "<head>\n",
      "<title>Wallflower, wallflower\n",
      "Take a chance,\n",
      "God knows it better than I ever see that I left behind the door,\n",
      "Got to play your head face down like a county hook, my man\n",
      "Old man down on this track\n",
      "The sun is shining, and you\n",
      "wish you knew me when\n",
      "I was hungry and I'm irritable\n",
      "And emptied the ashtrays on a whole other level,\n",
      "Got killed him there.\n",
      "He handed me a letter\n",
      "Bb            /g                                    B\n",
      " Must be Santa, Santa Claus</span>]\n",
      "Right down to 12th Street, lookin' for my soul<br />\n",
      "Feel like my soul is beginnin' to sing,\n",
      "What looks like you never came back.<br />\n",
      "      Danville curl,<br />\n",
      "    Yeah, \n"
     ]
    }
   ],
   "source": [
    "modelfile=joinpath(docdir,\"jmd\",\"dylan-markov10.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else \n",
    "  @time dm = p_markov(Val(10), text);\n",
    "  @save modelfile dm    \n",
    "end\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (930264, 2873103)\n",
      "d>\n",
      "<title>Oxford Town\n",
      "</pre>\n",
      "\n",
      "\n",
      "</div>\n",
      "<!--==================================-->\n",
      "\n",
      "<div class=\"preamble\">\n",
      "<p>Words by Bob Dylan, and released on <a class=\"refrain\">\n",
      "    C     G  Dm7 F        G\n",
      "Well, the funniest woman I ever standin' around\n",
      "He said, &quot;Well, I'll tell it and the powers above\n",
      "I'm sweating blood\n",
      "You got a way of tearing the whole day through\n",
      "Ah, one look in my eyes, please don't go,\n",
      "Baby, please don't put a price on my soul.\n",
      "</pre>\n",
      "<pre class=\"tab\">\n",
      "        <div class=\"preamble\">\n",
      "<p>Although that dark, unlucky night.\n",
      "</pre>\n",
      "\n",
      "<p>The little lick in bar three for the right\n",
      "In summer or in spring-time\n",
      "To tell the woman\n",
      "\n",
      "at the well.\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "[instr.]\n",
      "</pre>\n",
      "\n",
      "<pre class=\"tab\">\n",
      "  :   .   .       :       .     .   .   .   .     :   .   .\n",
      "|-3---------3-|\n",
      "</pre>\n",
      "<pre class=\"verse\">This place during the<a class=\"recordlink\" href=\"index.htm\">Shot of Love</a> sessions too\n",
      "but you treat me kindly\n",
      "    C/g                  Dm        Em        A7                                         D\n",
      "My feet are so tired\n",
      "   B                         F        C                 G/b   D    **)                           Fm\n",
      "The judge, says he,\n",
      "       D       G       C\n",
      "The answer, my friends and my love and not even company,\n",
      "But you break just like a woman,\n",
      "And she aches just like the moon above<br />\n",
      "    In your busted down in Texas, busted jail, I'm gonna tell you of a stranger tells her,\n",
      "&quot;Boy, without a home\n",
      "    C  /Bb    /a  /g\n",
      "Unto heaven and If Dogs Run Free</title>\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"../99_greatesthits2/index.htm\">Slow Train Coming</a> (1967)<br />\n",
      "Tabbed and transcribed the fingerpicking with my mind is driving me blind\n",
      "You close your mind?\"\n",
      "</pre>\n",
      "<pre class=\"bridge\">\n",
      "Oh! Lord! To her hand!\n",
      "</pre>\n",
      "\n",
      "<hr />\n",
      "\n",
      "<h2 class=\"songtitle\">Kingsport Town with a snake in both of your feet,\n",
      "    C/g-G\n",
      "Now you can hide.\n",
      "You see, I just lookin' to fight on a foreign shores.\n",
      "But I will always be renewed.\n",
      "And then commenced to do what they've go\n"
     ]
    }
   ],
   "source": [
    "modelfile=joinpath(docdir,\"jmd\",\"dylan-markov10.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else \n",
    "  @time dm = p_markov(Val(20), text);\n",
    "  @save modelfile dm  \n",
    "end\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm, 2000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With histories of length 20 the text looks pretty. Some of the lyrics\n",
    "are recognizably Dylan-like. However, the model still gets html tags\n",
    "mostly wrong. More importantly, the model is effectively just\n",
    "combining phrases of Dylan lyrics randomly. The data here consists of\n",
    "nearly 2.9 million characters. Among these, there are 1.5 million\n",
    "unique sequences of 20 characters. Many of the estimated\n",
    "$P(c_t|c_{t-1}, ...)$ are equal to one. \n",
    "\n",
    "## RNN \n",
    "\n",
    "Now let's fit a recurrent neural network to the Dylan lyrics and chords data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, chunk, batchseq, throttle, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition\n",
    "using ProgressMeter\n",
    "\n",
    "text = collect(String(read(joinpath(docdir,\"jmd\",\"dylanchords.txt\"))))\n",
    "endchar = 'Ω' # any character not in original text\n",
    "alphabet = [unique(text)..., endchar]\n",
    "hottext = map(ch -> onehot(ch, alphabet), text)\n",
    "stop = onehot(endchar, alphabet)\n",
    "\n",
    "N = length(alphabet)\n",
    "seqlen = 50\n",
    "batchsize = 50\n",
    " \n",
    "Xseq = gpu.(batchseq(chunk(hottext,seqlen),stop));\n",
    "Yseq = gpu.(batchseq(chunk(hottext[2:end], seqlen),stop));\n",
    "data = [(Xseq[p], Yseq[p]) for p in partition(1:length(Xseq), batchsize)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce computation while training the model, we are going to use\n",
    "gradient truncation. `seqlen` is the length of history through which gradients are\n",
    "accumulated. \n",
    "\n",
    "We also divide the data into batches for gradient descent. `batchsize`\n",
    "is the number of `seqlen` sequences per batch used for gradient\n",
    "descent. Each batch will have `seqlen * batchsize` observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 32 has 28933 parameters\n",
      "Sample from model 32\n",
      "--------------------\n",
      "---|-------------|-------------|-----3---1-(1)-|--10-8-1-12---------------|-0--3-------------0---5-3--|\n",
      "|-----------------|\n",
      "|-0---------------||\n",
      "||-----------0-----|-0--0-------h0-----(|<d class=\"croun\\s\">F</tclas=\"shee>\n",
      "    020000\n",
      "</pre>\n",
      "<pre class=\"tab\">\n",
      "Dig I's ster not has brow, swied that chilf\n",
      "the Tinker bester,\n",
      "Live what's guadg long ara\n",
      "                /a\n",
      "He bone? Chan, but a tuning\n",
      "Walk we've mave Man, be falled Kound\n",
      "Callin' to lot black cross,\n",
      "Every the Dlom twy wills that it horn.\n",
      "</pre>\n",
      "\n",
      "<hr />\n",
      "<h2 class=\"songversion\">Lide</s>\n",
      "  </body>\n",
      "<hhen>\n",
      "      360300\n",
      "</pre>\n",
      "\n",
      "</body></wwho keukpodly so way the Dase Golding aly Canusa&ldquo; and honeinall Leads a-chonded Blean Lordade Ethy Fin like 1 our Brake is inces;<br />\n",
      "              C          Dsus4 F\n",
      "and people bellet one only\n",
      "But them,\n",
      "He away love\n",
      "Lordy, the we'l I'll whole in your fail when it then meens\n",
      "Things to tell\n",
      "     F    Em\n",
      "Boon firse to the unkalin' my name,\n",
      "Body Edy long at the Othin'\n",
      "Trie, Uhx4    200011\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "If       G        G     F     C\n",
      "What coalduer, my play you down,\n",
      "But bails,\n",
      "I'll gonna gonna vus,\n",
      "Now <br />\n",
      "Releasedy erars 2 3pein verse)<br />\n",
      "Tabbed by vars feenseyta Be fsom (and gatened what've smsees the 1976 = veleden&rdquo;</em>\n",
      ")</h1>\n",
      "\n",
      "  <p>Wordss\">\n",
      "|Fx2---11-----10--|-10---------W'st fightreppen\n",
      "Ah\n",
      "Your some land.\n",
      "\n",
      "Os were you with your going a comes answing free out be the hell nealothear how\n",
      "    Am\n",
      "Beat blues\n",
      "what's the only who's say recak every tut's\n",
      "                     /i.                             D\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "St fromertient fhop Mace,\n",
      "F                   C      F     G\n",
      "Who the e#:Luss Nut Eyorsally's abow thestes, youd been my liugon on all cunts\n",
      "The long ba is the linna\n",
      "         F   F\n",
      "  :   .   .   .\n",
      "|-----0---0-------0------|----00-3---------------|\n",
      "|-0-----------------------|\n",
      "|-----------3------------|------------------------|   .\n",
      "\n",
      "Pridmun plare\n",
      "my while horn my grea set these the keep back of\n",
      "any me for the slearroly\n",
      "than mug\n",
      "\n",
      "Model 64 has 82341 parameters\n",
      "Sample from model 64\n",
      "--------------------\n",
      "x2003 \n",
      "\n",
      "      C                     F/c C] esething to me 30--3320001 re-coodd becord from me<br />\n",
      "If, I kept mysed=\">Ait 2nd played no 12, 1978</h3>\n",
      "<div class=\"preamble\">\n",
      "\n",
      "<p>Living a C\n",
      "(</p>\n",
      "    <pre class=\"chords\">\n",
      "C#m      x02550\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "          G                 /f#             A\n",
      "Origina yonr my oundy, the boys of my free,\n",
      "Oh, I'm works in my  comin' on\n",
      "Sayin', &qeaquo;h&rdquo; just teyl to E\n",
      "\n",
      "      E                |----------------|------------------|\n",
      "       </p>\n",
      "\n",
      "<p>The sounds of the first it's the\n",
      "only is obreating so harlly until as in the\n",
      "played limsing, actupt. The Lably probambling of Mindings)</h2>\n",
      "<pre class=\"verse\">\n",
      "Cover the days are high\n",
      "         C             G7\n",
      "Stren's please take what's an a barkge, they've stell you wannin' light to mas,\n",
      "I'll sugalih still just cryin' to me, still long.\n",
      "Oh, tabbe, the little nor\n",
      "Faret I was a deepin',\n",
      "Tell myself somethin' carly key, they may be.\n",
      "\n",
      "Untas you let the one more.\n",
      "'Cause he's a cryin'\n",
      "\n",
      "</pre>\n",
      "<pre class=\"refrain\">\n",
      "/e most make ya\n",
      "The mother yanea my law only underlass to turn\n",
      "   G6    C                                   G\n",
      "Yond're before years amorthy\n",
      "Who've take her followed too mild\n",
      "Best could comes in the ground\n",
      "But you say, &quot;Not back all touched me in the hole\n",
      "F                C\n",
      "You crassite he's likenty your his heavy red time\n",
      "From a train comes on my way just your mucht.\n",
      "  F\n",
      " My blank board, Forgen\n",
      "</pre>\n",
      "<pre class=\"refrain\">     :   .   .   .\n",
      "--0000------|    .   .   .      |\n",
      "</pre>\n",
      "     </div>\n",
      "    <spas crass=\"rleas\">\n",
      "   :|   </pre>\n",
      "<pre class=\"verse\">\n",
      "The brang in the flym, tree, oh well, my teord, simple by the midds silver\n",
      "And you Fse it's the day\n",
      "He sies it was the grows, the man's listen right, hardly be I've go and tire.\n",
      "\n",
      "I'd like some one is me, I want, so You?\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "Ever to love love\n",
      "To get fallin' down the 'ne thing\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "E                                F\n",
      "I'll rehore, they&rsquo; see him the cottacun\n",
      "This time \n",
      "\n",
      "Model 128 has 262885 parameters\n",
      "Sample from model 128\n",
      "--------------------\n",
      "Ozama, lawa liotinegon<br />\n",
      " A Lasr166 from the fill of my friends?\n",
      "Capo 4s cat and only if he never thought to meet all down\n",
      "Yellow barked out through the river and mean\n",
      "When he paid off and queed\n",
      "A all seems to You Me and bakes best\n",
      "Sfortys arms so stars if\n",
      "Wiggle 'til you, srives drink that so that word\n",
      "</pre>\n",
      "<pre class=\"verse\">\n",
      "Lady rough my hand.\n",
      "Saying, &quot;Iflo Jesque look gone off a thing one more nailing band or de happy got brought.\n",
      "And those fightphin' stone.\n",
      "I got around the following happy, don't hold ya nerve on.\n",
      "Discoventrate and someone play,\n",
      "Take me forgetting you.\n",
      "\n",
      "Slavey opleared the reason your hatter\n",
      "'Cause they've cross my head<br />\n",
      " 2:         A            D                  F\n",
      "Waiting and dying over me.</pre>\n",
      "\n",
      "<pre class=\"bridge\">\n",
      "G#m\n",
      "go down, break through the ashould his head\n",
      "B/g                        A\n",
      "She'll hit the cat, to tear high jail\n",
      "E                              D\n",
      "Have querly tear my feet as near\n",
      "           C                    Em\n",
      "'Cause I got a hill of a coatreter\n",
      "it, as your hands will percose.\n",
      "They know we surpound,\n",
      "Wherever yinger that's gone\n",
      "&quot;Confers you there and yourself and crowd\n",
      "I break my heam, something is really&rdquo;&rdquo; </p>\n",
      "\n",
      "<p>Chords and any riff for the song\n",
      "probablydally rages. Piles, the 1st tin'. Maronsy of Jack wog\n",
      "break with patter of the verse\" cass on\n",
      "Is the capo on the 4th fret (bound tollin         capo\n",
      "&ldquo;B' it sounders, thould poticte&rdquo;). I've got to surow of the alrelinger\n",
      "You might roll to the oneso fairher and the progrem6..\n",
      "</pre>\n",
      "\n",
      "<pre class=\"crust[choris\">&llquo;NY, Allen Pertcy, TV se&rdquo;</em>)<br />\n",
      " Hallin' down the same, something and propos\n",
      "Shoot to catch up the room most favering of here, the emptensaking?\n",
      "It's my silent still please here sin?\n",
      "My kindin' joins, the trouble and leave you one\n",
      "ever break only, not forgot\n",
      "of the town for it, baby, Jesus are born that from Lavelorane.\n",
      "</pre>\n",
      "<pre class=\"verse\">\n",
      "Alleluia*\n",
      "way through me in write to the blues\n",
      "Tell her best \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "\n",
    "function sample(m, alphabet, len)\n",
    "  m = cpu(m)\n",
    "  Flux.reset!(m)\n",
    "  buf = IOBuffer()\n",
    "  c = rand(alphabet)\n",
    "  for i = 1:len\n",
    "    write(buf, c)\n",
    "    c = wsample(alphabet, m(onehot(c, alphabet)).data)\n",
    "  end\n",
    "  return String(take!(buf))\n",
    "end\n",
    "\n",
    "opt = RMSProp(0.005)\n",
    "# this will take awhile, so a fancier call back with a progress meter is nice to have \n",
    "function cbgenerator(N, loss, printiter=Int(round(N/10)))\n",
    "  p = Progress(N, 1, \"Training\", 25)\n",
    "  i=0\n",
    "  function cb()\n",
    "    next!(p)\n",
    "    if (i % printiter==0)\n",
    "      @show loss()\n",
    "    end\n",
    "    i+=1\n",
    "  end\n",
    "  return(cb)\n",
    "end\n",
    "\n",
    "function train_model(L; N=N, data=data,\n",
    "                     modelfile=joinpath(docdir,\"jmd\",\"dylan-$L.jld2\"),\n",
    "                     opt=opt )\n",
    "  m = Chain(LSTM(N, L), LSTM(L, L),  Dense(L, N),  softmax) |> gpu\n",
    "  function loss(xb::V, yb::V) where V<:AbstractVector\n",
    "    l = sum(crossentropy.(m.(xb),yb))/length(xb)\n",
    "    Flux.truncate!(m)\n",
    "    return(l)\n",
    "  end\n",
    "  cb=cbgenerator(length(data),()->loss(data[5]...))\n",
    "\n",
    "  if isfile(modelfile)\n",
    "    @load modelfile cpum\n",
    "    m = gpu(cpum)\n",
    "  else \n",
    "    @time Flux.train!(loss, Flux.params(m), data, opt, cb = cb)\n",
    "    println(\"Sampling after 1 epoch:\")\n",
    "    sample(m, alphabet, 1000) |> println\n",
    "    \n",
    "    Flux.@epochs 10 Flux.train!(loss, Flux.params(m), data, opt,\n",
    "                                cb = cbgenerator(length(data),()->loss(tx,ty)))\n",
    "    cpum = cpu(m)\n",
    "    @save modelfile cpum\n",
    "  end\n",
    "  return(m)\n",
    "end\n",
    "\n",
    "for L in [32, 64, 128] #, 256, 512]\n",
    "  m = train_model(L)\n",
    "  println(\"Model $L has $(sum([prod(size(p)) for p in Flux.params(m)])) parameters\")  \n",
    "  println(\"Sample from model $L\")\n",
    "  println(\"--------------------\")\n",
    "  println(sample(m, alphabet, 2000))\n",
    "  println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
