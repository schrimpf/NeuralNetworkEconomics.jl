{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution-ShareAlike\n",
    "4.0 International\n",
    "License](http://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "\n",
    "### About this document\n",
    "\n",
    "This document was created using Weave.jl. The code is available in\n",
    "[on github](https://github.com/schrimpf/NeuralNetworkEconomics.jl). The same\n",
    "document generates both static webpages and associated [jupyter\n",
    "notebook](rnn.ipynb).\n",
    "\n",
    "$$\n",
    "\\def\\indep{\\perp\\!\\!\\!\\perp}\n",
    "\\def\\Er{\\mathrm{E}}\n",
    "\\def\\R{\\mathbb{R}}\n",
    "\\def\\En{{\\mathbb{E}_n}}\n",
    "\\def\\Pr{\\mathrm{P}}\n",
    "\\newcommand{\\norm}[1]{\\left\\Vert {#1} \\right\\Vert}\n",
    "\\newcommand{\\abs}[1]{\\left\\vert {#1} \\right\\vert}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:18:42.441000Z",
     "iopub.status.busy": "2022-10-26T20:18:41.590000Z",
     "iopub.status.idle": "2022-10-26T20:18:54.809000Z",
     "shell.execute_reply": "2022-10-26T20:18:54.751000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/.julia/dev/NeuralNetworkEconomics/docs`\n"
     ]
    }
   ],
   "source": [
    "markdown = try\n",
    "  \"md\" in keys(WEAVE_ARGS) && WEAVE_ARGS[\"md\"]\n",
    "catch\n",
    "  false\n",
    "end\n",
    "\n",
    "if !(\"DISPLAY\" ∈ keys(ENV))\n",
    "  # Make gr and pyplot backends for Plots work without a DISPLAY\n",
    "  ENV[\"GKSwstype\"]=\"nul\"\n",
    "  ENV[\"MPLBACKEND\"]=\"Agg\"\n",
    "end\n",
    "# Make gr backend work with λ and other unicode\n",
    "ENV[\"GKS_ENCODING\"] = \"utf-8\"\n",
    "\n",
    "using NeuralNetworkEconomics\n",
    "docdir = joinpath(dirname(Base.pathof(NeuralNetworkEconomics)), \"..\",\"docs\")\n",
    "\n",
    "using Pkg\n",
    "Pkg.activate(docdir)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Previous notes have covered [single layer](slp.md), [multi\n",
    "layer](mlp.md), and [convolutional](conv.md) feed forward networks.\n",
    "In feed forward networks, the outputs of one layer are fed into the\n",
    "next layer, always moving toward the output. Recurrent networks break\n",
    "this pattern. In recurrent networks, outputs of one layer are feed\n",
    "back into the same. This always the network to maintain a hidden\n",
    "state. Recurrent networks are typically used to model sequential\n",
    "data. There are many applications to time series. Recurrent networks\n",
    "are also useful for processing text and audio data.\n",
    "\n",
    "## Additional Reading\n",
    "\n",
    "- @goodfellow2016 [*Deep Learning*](http://www.deeplearningbook.org)\n",
    "  especially chapter 10\n",
    "- [`Knet.jl`\n",
    "  documentation](https://denizyuret.github.io/Knet.jl/latest/)\n",
    "  especially the textbook\n",
    "- @klok2019 *Statistics with Julia:Fundamentals for Data Science,\n",
    "  MachineLearning and Artificial Intelligence*\n",
    "\n",
    "# Recurrent Networks\n",
    "\n",
    "Recurrent Networks are designed to predict a sequence of outputs,\n",
    "$y_t$, given a sequence of inputs, $x_t$, where $t=1, ...,T$, The\n",
    "relationship between $x$ and $y$ is assumed to be stationary, but we\n",
    "will allow there to be possibly many values from the history of $x$ to\n",
    "affect $y$. We do this by introducing a hidden state, $h_t$. The\n",
    "prediction for $y_t$ is only a function of $h_t$, say\n",
    "$\\hat{y}(h_t)$. The hidden state is Markovian with\n",
    "$$\n",
    "h_t = f(h_{t-1}, x_t).\n",
    "$$\n",
    "Both $\\hat{y}()$ and $f()$ are constructed from neural\n",
    "networks. They could simply be single layer perceptrons, or any of the\n",
    "more complicated network architectures we previously discussed.\n",
    "\n",
    "## Approximation Ability\n",
    "\n",
    "Recurrent networks can approximate (in fact can equal) any computable\n",
    "function. @siegelmann1991 and @siegelmann1992 show that recurrent\n",
    "neural networks are Turing complete. As with the universal\n",
    "approximation ability of feed forward networks, this result is good to\n",
    "know, but it is not an explanation for the good practical performance\n",
    "of recurrent networks.\n",
    "\n",
    "When $h_t$ is large enough, it is easy to see how the recurrent model\n",
    "above can equal familiar time series econometric models. For example,\n",
    "for an AR(P) model,\n",
    "$$\n",
    "y_t = \\rho_1 y_{t-1} + \\cdots + \\rho_p y_{t-p} + \\epsilon_t\n",
    "$$\n",
    "To express this model in recurrent state-space form,\n",
    "let $x_t = y_{t-1}$, and $h_t = (y_{t-1}, \\cdots, y_{t-p}) \\in \\R^p$.\n",
    "Then we can set\n",
    "$$\n",
    "f(h_{t-1}, x_t) = (x_t, h_{t-1,1}, \\cdots , h_{t-1, p-1})\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{y}(h_t) = \\rho' h_t,\n",
    "$$\n",
    "\n",
    "## Stability and Gradients\n",
    "\n",
    "Recursive neural networks can be difficult to train. The difficulty\n",
    "stems from how the gradient of the network behaves very differently\n",
    "depending on whether the dynamics are stable. To illustrute, suppose\n",
    "$f()$ is linear,\n",
    "$$\n",
    "h_t = f_h h_{t-1} + f_x x_t\n",
    "$$\n",
    "and the loss function is MSE\n",
    "$$\n",
    "\\mathcal{L}(f_h,f_x) = \\frac{1}{T} \\sum_{t=1}^T (\\hat{y}(h_t)- y_t)^2\n",
    "$$\n",
    "The derivatives of the loss function with respect to the parameters of\n",
    "$f$ are then:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial f_h} & = \\frac{2}{T} \\sum (\\hat{y}(h_t)-\n",
    "y_t)\\hat{y}'(h_t) \\left(t f_h^{t-1} h_0 + \\sum_{s=1}^{t-1}\n",
    "(t-s)f_h^{t-s-1} f_x x_{t-s} \\right) \\\\\n",
    "\\frac{\\partial}{\\partial f_x} & = \\frac{2}{T} \\sum (\\hat{y}(h_t)- y_t)\n",
    "    \\hat{y}'(h_t)\n",
    "    \\left(\\sum_{s=1}^{t} x_s f_h^{t-s} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "Both of these involve increasing powers of $f_h^t$. If $h_t$ has\n",
    "stable dynamics, i.e. $|f_h|<1$, then these derivatives will be\n",
    "dominated by the terms involving more recent values of $x_t$. If $h_t$\n",
    "has explosive dynamics, $|f_h|>1$, then these derivatives will be\n",
    "dominated by the terms involving the earlist $x_t$. Depending on the\n",
    "stability of $f$, gradients will be dominated by either short term\n",
    "dependence between $x$ and $y$ or long term. This behavior makes it\n",
    "difficult to train a network where both short and long term\n",
    "dependencies are important.\n",
    "\n",
    "The previous analysis also apply to nonlinear $f()$, with $f_h$\n",
    "replaced by $(\\partial f)/(\\partial h)$, and stable replaced with\n",
    "locally stable.\n",
    "\n",
    "The previous analysis also applies to multivariate $h_t$ with $|f_h|$\n",
    "replace by $\\max |eigenvalue(f_h)|$.\n",
    "\n",
    "## Truncating Gradients\n",
    "\n",
    "A practical problem with gradients of recurrent networks is that\n",
    "$\\hat{y}(h_t)$ depends on the entire history of\n",
    "$x_1, \\cdots, x_t$. When computing the gradient by backward\n",
    "differentiation, this entire history will accumulate, using up memory\n",
    "and taking time. A common solution is to truncate the gradient\n",
    "calculation after some fixed number of periods.\n",
    "\n",
    "\n",
    "## LSTM\n",
    "\n",
    "Long Short-Term Memory networks were designed to avoid the problem of\n",
    "vanishing and exploding gradients. LSTMs have an additional hiddent\n",
    "state, $s_t$. The extra hidden state is $s_t \\in (0,1)$ and is a\n",
    "weighted sum of $s_{t-1}$ and other variables. In particular,\n",
    "$$\n",
    " s_t = \\sigma(b_f + U_f' x_t + W_f' h_{t-1}) s_{t-1} + \\sigma(b_g + U_g'\n",
    " x_t + W_g' h_{t-1}) \\tilde{x}_t\n",
    "$$\n",
    "The first $\\sigma(b_f + U_f' x_t + W_f' h_{t-1})$ is a \"forget\"\n",
    "gate. It determines how much of $s_{t-1}$ is forgotten.\n",
    "The second $\\sigma(b_g + U_g' x_t + W_g' h_{t-1})$ is call the\n",
    "external input gate. It determines how much current $x_t$ affects\n",
    "$s_t$. The $\\tilde{x}$ is a rescaled input given by\n",
    "$$\n",
    "\\tilde{x}_t = \\sigma(\\tilde{b} + \\tilde{U}'x_t + \\tilde{W}' h_{t-1}).\n",
    "$$\n",
    "Finally, $h_t$ is a gated and transformed version of $s_t$.\n",
    "$$\n",
    "h_t = tanh(s_t) \\sigma(b_o + U_o' x_t + W_o'h_t)\n",
    "$$\n",
    "where $\\sigma(b_o + U_o' x_t + W_o'h_t)$ is the output gate.\n",
    "\n",
    "# Example : Generating Dylan Songs\n",
    "\n",
    "Recurrent neural networks are pretty good at randomly generating\n",
    "text. The\n",
    "[Flux model zoo](https://github.com/FluxML/model-zoo/blob/master/text/char-rnn/char-rnn.jl)\n",
    "includes one such example. The example is based on this [blog post by\n",
    "Andrej\n",
    "Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). It\n",
    "predicts each individual character given past characters. This works\n",
    "suprisingly well. We are going to repeat this exercise, but use Bob\n",
    "Dylan songs as input.\n",
    "\n",
    "\n",
    "## Downloading Songs\n",
    "\n",
    "We download all Bob Dylan lyrics and chords from\n",
    "[dylanchords.info](http://dylanchords.info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:18:54.815000Z",
     "iopub.status.busy": "2022-10-26T20:18:54.815000Z",
     "iopub.status.idle": "2022-10-26T20:18:58.222000Z",
     "shell.execute_reply": "2022-10-26T20:18:58.222000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2873103-element Vector{Char}:\n",
       " '\\n': ASCII/Unicode U+000A (category Cc: Other, control)\n",
       " '<': ASCII/Unicode U+003C (category Sm: Symbol, math)\n",
       " '?': ASCII/Unicode U+003F (category Po: Punctuation, other)\n",
       " 'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)\n",
       " 'm': ASCII/Unicode U+006D (category Ll: Letter, lowercase)\n",
       " 'l': ASCII/Unicode U+006C (category Ll: Letter, lowercase)\n",
       " ' ': ASCII/Unicode U+0020 (category Zs: Separator, space)\n",
       " 'v': ASCII/Unicode U+0076 (category Ll: Letter, lowercase)\n",
       " 'e': ASCII/Unicode U+0065 (category Ll: Letter, lowercase)\n",
       " 'r': ASCII/Unicode U+0072 (category Ll: Letter, lowercase)\n",
       " 's': ASCII/Unicode U+0073 (category Ll: Letter, lowercase)\n",
       " 'i': ASCII/Unicode U+0069 (category Ll: Letter, lowercase)\n",
       " 'o': ASCII/Unicode U+006F (category Ll: Letter, lowercase)\n",
       " ⋮\n",
       " 'y': ASCII/Unicode U+0079 (category Ll: Letter, lowercase)\n",
       " '>': ASCII/Unicode U+003E (category Sm: Symbol, math)\n",
       " '\\n': ASCII/Unicode U+000A (category Cc: Other, control)\n",
       " '<': ASCII/Unicode U+003C (category Sm: Symbol, math)\n",
       " '/': ASCII/Unicode U+002F (category Po: Punctuation, other)\n",
       " 'h': ASCII/Unicode U+0068 (category Ll: Letter, lowercase)\n",
       " 't': ASCII/Unicode U+0074 (category Ll: Letter, lowercase)\n",
       " 'm': ASCII/Unicode U+006D (category Ll: Letter, lowercase)\n",
       " 'l': ASCII/Unicode U+006C (category Ll: Letter, lowercase)\n",
       " '>': ASCII/Unicode U+003E (category Sm: Symbol, math)\n",
       " '\\n': ASCII/Unicode U+000A (category Cc: Other, control)\n",
       " '\\n': ASCII/Unicode U+000A (category Cc: Other, control)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ProgressMeter, JLD2\n",
    "import HTTP, Gumbo, Cascadia\n",
    "\n",
    "infile = joinpath(docdir,\"jmd\",\"dylanchords.txt\")\n",
    "\n",
    "if !isfile(infile)\n",
    "  r=HTTP.get(\"http://dylanchords.info/alphabetical_list_of_songs.htm\")\n",
    "  songlist=Gumbo.parsehtml(String(r.body));\n",
    "  songlinks = eachmatch(Cascadia.Selector(\".songlink\"), songlist.root)\n",
    "  songhtml = Array{String, 1}(undef, length(songlinks))\n",
    "  p = Progress(length(songlinks),1,\"Downloading songs\", 50)\n",
    "  for s ∈ eachindex(songlinks)\n",
    "    url = songlinks[s].attributes[\"href\"]\n",
    "    if url == \"index.htm\"\n",
    "      songhtml[s] = \"\"\n",
    "      continue\n",
    "    end\n",
    "    r = HTTP.get(\"http://dylanchords.info/\"*url)\n",
    "    songhtml[s]=String(r.body)\n",
    "    next!(p)\n",
    "  end\n",
    "\n",
    "  open(infile, \"w\") do io\n",
    "    for s ∈ songhtml\n",
    "      write(io, s)\n",
    "      write(io,\"\\n\")\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "text = collect(String(read(infile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the input text here are html files. Here is the start of one\n",
    "song.\n",
    "```\n",
    "<head>\n",
    "<title>My Back Pages</title>\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/general.css\" />\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "<h1 class=\"songtitle\">My Back Pages</h1>\n",
    "\n",
    "\n",
    "<p>Words and music Bob Dylan<br />\n",
    "Released on <a class=\"recordlink\" href=\"../04_anotherside/index.htm\">Another Side Of Bob Dylan</a> (1964) and <a class=\"recordlink\" href=\"../99_greatesthits2/index.htm\">Greatest Hits II</a> (1971)<br />\n",
    "Tabbed by Eyolf &Oslash;strem</p>\n",
    "\n",
    "<p>Most G's are played with a small figure (G - G6 - G7) going up to G7:</p>\n",
    "<pre class=\"chords\">\n",
    "G  320003\n",
    "G6 322003\n",
    "G7 323003\n",
    "</pre>\n",
    "\n",
    "<p>This is noted with a *).</p>\n",
    "\n",
    "<p>He didn't seem to spend too much time rehearsing this song before he\n",
    "went into the studio (the whole album was recorded in one\n",
    "evening/night session) &ndash; he gets the first verse all wrong in the\n",
    "chords, and he struggles a lot with the final lines of each\n",
    "verse. I've written out the chords for the first two verses and in the\n",
    "following verses deviations from the <em>second</em> verse.</p>\n",
    "\n",
    "<p>Capo 3rd fret (original key Eb major)</p>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<pre class=\"verse\">\n",
    "C       Am          Em\n",
    "Crimson flames tied through my ears\n",
    "        F        G *)   C\n",
    "Rollin' high and mighty traps\n",
    "C            Am      Em      C\n",
    "Pounced with fire on flaming roads\n",
    "      F     Em    G   *)\n",
    "Using ideas as my maps\n",
    "       F       Am     G *)        C\n",
    "&quot;We'll meet on edges, soon,&quot; said I\n",
    "Am                  F G\n",
    "Proud 'neath heated brow\n",
    "        C             Am    C\n",
    "Ah, but I was so much older then\n",
    "    F       G *)      C       G *)\n",
    "I'm younger than that now.\n",
    "```\n",
    "\n",
    "Some songs include snippets of tablature (simple notation for guitar).\n",
    "For example,\n",
    "\n",
    "```\n",
    "<p>The easiest way to play the G7sus4 G7 G7sus2 G7 figure would be:</p>\n",
    "<pre class=\"verse\">\n",
    "G7sus4  G7  G7sus2  G7\n",
    "|-1-----1-----1-----1---\n",
    "|-0-----0-----0-----0---\n",
    "|-0-----0-----0-----0---\n",
    "|-0-----0-----0-----0---\n",
    "|-3-----2-----0-----2---\n",
    "|-3-----3-----3-----3---\n",
    "</pre>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<p>Intro:</p>\n",
    "<pre class=\"tab\">\n",
    "  C           G/b           F/a         G11   G       C/e\n",
    "  :     .       :     .       :     .       :     .        :     .\n",
    "|-------0-----|-------3-----|-------1-----|--------------|-------0------\n",
    "|-----1---1---|-----0-------|-----1-1---1-|---1---010----|-----1---1----\n",
    "|---0-------0-|---0-----0---|---2-----1---|-2---2----0---|---0-------0-- etc\n",
    "|-------------|-------------|-------------|------------3-|-2------------\n",
    "|-3-----------|-2---------2-|-0-----------|--------------|--------------\n",
    "|-------------|-------------|-------------|-3------------|--------------\n",
    "</pre>\n",
    "```\n",
    "This is all just text, and we will treat it is a such. However, it has\n",
    "additional structure that makes it more interesting to predict than\n",
    "the text of just lyrics.\n",
    "\n",
    "## Markovian Baseline\n",
    "\n",
    "As [Yoav Goldberg point\n",
    "out](https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139), you\n",
    "can generate pretty good text with a simple Markovian model of\n",
    "characters. That is, estimate the probability of a character $c$ given\n",
    "a history of $L$ characters $h$, $P(c_t|c_{t-1}, ..., c_{t-L})$, by\n",
    "simple sample averages. Let's try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:18:58.230000Z",
     "iopub.status.busy": "2022-10-26T20:18:58.230000Z",
     "iopub.status.idle": "2022-10-26T20:19:09.098000Z",
     "shell.execute_reply": "2022-10-26T20:19:09.098000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Symbol}:\n",
       " :dm"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using StaticArrays\n",
    "\n",
    "function p_markov(len::Val{L}, data::AbstractVector{Char}) where L\n",
    "  dm = Dict{SVector{L, Char}, Dict{Char, Float64}}()\n",
    "  p = Progress(length(data), 1, \"count_markov($L)\", 30)\n",
    "  for t in (1+L):length(data)\n",
    "    key = @view data[(t-L):(t-1)]\n",
    "    entry=get!(dm, key, Dict(data[t] => 0))\n",
    "    v = get!(entry, data[t], 0)\n",
    "    entry[data[t]] += 1\n",
    "    next!(p)\n",
    "  end\n",
    "  for k in keys(dm)\n",
    "    total = sum(values(dm[k]))\n",
    "    for e in keys(dm[k])\n",
    "      dm[k][e] /= total\n",
    "    end\n",
    "  end\n",
    "  dm\n",
    "end\n",
    "\n",
    "modelfile=joinpath(docdir,\"jmd\",\"models\",\"dylan-markov4.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else\n",
    "  @time dm = p_markov(Val(4), text);\n",
    "  @save modelfile dm\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code stores $P(c_t|c_{t-1},...,c_{t-L})$ in a\n",
    "dictionary. When $L$ is large, there are huge number of possible\n",
    "histories, $c_{t-1},...,c_{t-L}$, and we will not observe many of\n",
    "them. A dictionary only stores data on the histories we observe, so it\n",
    "will save some memory.\n",
    "\n",
    "Let's now sample from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:19:09.202000Z",
     "iopub.status.busy": "2022-10-26T20:19:09.105000Z",
     "iopub.status.idle": "2022-10-26T20:19:10.519000Z",
     "shell.execute_reply": "2022-10-26T20:19:10.519000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (88032, 2873103)\n",
      "tle>Oh, Lord\n",
      "It's certa</h1>\n",
      "\n",
      "\n",
      "<p class=\"verse\">\n",
      "But you in hide\n",
      "'Cause are your way shirt Robertake a time full\n",
      "he suggest for did before don't been to down boaster, the moon about me I tryin', I'm getting a hand,\n",
      "Asus4  G   C\n",
      " Acciden' of friend\n",
      "There I bellin' like any the blin' on 'em and down rain\">\n",
      "He str.]\n",
      "\n",
      "Tears in the following is you was leave me, my eyes\n",
      "He ever in Commiss.\n",
      "I have heave With a GI invening\n",
      "like the fella misundern (original; Dylance,\n",
      "Fix me fuel finite\n",
      "For A11               .   .  .   .     G\n",
      "I left my pride away from the blowing pattern, when I guess heart could listen by heart inter</title>\n",
      "<pre class=\"verse\">\n",
      "G   G         G                            Bbmaj7 x00707\n",
      "D7(iii)         C/g G\n",
      "  :  .      .   .   .       A7/g           E      :   .\n",
      "|-----0--------|\n",
      "|--------|-5---5-----|----0---------|---7-|-7---7---------------------|\n",
      "|-0----------------------||\n",
      "</pre>\n",
      "<pre class=\"refraids, I'm you a store.\n",
      "</pre>\n",
      "<link rel=\"stylesheet\" type=\"text/css/general.cs\n"
     ]
    }
   ],
   "source": [
    "defaultinit=collect(\"\\n\\n<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Strict//EN\\\"\\n\\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\\">\\n<html lang=\\\"en\\\" xml:lang=\\\"en\\\" xmlns=\\\"http://www.w3.org/1999/xhtml\\\">\\n\\n<head>\\n<title>\")\n",
    "\n",
    "function sample_markov(dm::Dict{SVector{L, Char}, Dict{Char, Float64}}, len=1000,\n",
    "                       init=defaultinit) where L\n",
    "  out = Array{Char,1}(undef,len)\n",
    "  state = MVector{L, Char}(init[(end-L+1):end])\n",
    "  out[1:L] .= state\n",
    "  for s=L+1:len\n",
    "    u = rand()\n",
    "    cp = 0.0\n",
    "    for k in keys(dm[state])\n",
    "      cp += dm[state][k]\n",
    "      if (u<= cp)\n",
    "        out[s]=k\n",
    "        break\n",
    "      end\n",
    "    end\n",
    "    state[1:(end-1)] .= state[2:end]\n",
    "    state[end] = out[s]\n",
    "  end\n",
    "  out\n",
    "end\n",
    "\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning on histories of length 4, we get some hints of\n",
    "Dylan-esque lyrics, but we also get a lot of gibberish. Let's try\n",
    "longer histories.\n",
    "\n",
    "### Length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:19:10.528000Z",
     "iopub.status.busy": "2022-10-26T20:19:10.527000Z",
     "iopub.status.idle": "2022-10-26T20:19:15.982000Z",
     "shell.execute_reply": "2022-10-26T20:19:15.982000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (930264, 2873103)\n",
      "d>\n",
      "<title>Crazy Love</title>\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"../28_biograph/index.htm\">Down In The Groove</a> (1985)<br /></p>\n",
      "\n",
      "<p>The only this morning, butter n' eggs in my bed once again.\n",
      "</pre>\n",
      "</div>\n",
      "<pre class=\"verse\">\n",
      "Well, I asked him who was responsible\n",
      "                       G\n",
      "Weary and worn out\n",
      "       C7-9                               G     D/f#                     G  C/g                                G . . /b-c | D . . /e-f# | G\n",
      "\n",
      "Well he wants you only!                    :     .     .             E\n",
      "Lord, I'm sitting on my watch\n",
      "I looked for work and money\n",
      "Dad, get me out of Mind</a> (1997)<br />\n",
      "Tabbed by Eyolf &Oslash;strem</p>\n",
      "\n",
      "\n",
      "<h2 class=\"songtitle\">Three Angels</title>\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/general.css\" />\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "\n",
      "<h1 class=\"songtitle\">Beyond the horizon,\n",
      "D9/6 D9                    Em/b\n",
      "The night and tall in his hand were both blown off\n",
      "And he wouldn't lie\n",
      "He said come here quick.\n",
      "F\n",
      "This old cocaine is making me sad\n"
     ]
    }
   ],
   "source": [
    "modelfile=joinpath(docdir,\"jmd\",\"models\",\"dylan-markov10.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else\n",
    "  @time dm = p_markov(Val(10), text);\n",
    "  @save modelfile dm\n",
    "end\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:19:16.016000Z",
     "iopub.status.busy": "2022-10-26T20:19:16.015000Z",
     "iopub.status.idle": "2022-10-26T20:19:31.577000Z",
     "shell.execute_reply": "2022-10-26T20:19:31.577000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (1522834, 2873103)\n",
      "ml\">\n",
      "\n",
      "<head>\n",
      "<title>Simple Twist of Fate</h1>\n",
      "\n",
      "\n",
      "<p>Words and music Bob Dylan<br />\n",
      "Released on <a class=\"recordlink\" href=\"../42_bs5/index.htm\">Live 1975</a> (2002)<br />\n",
      "\tTabbed by Eyolf &Oslash;strem</p>\n",
      "\n",
      "<hr />\n",
      "\n",
      "<p>Drop D tuning (D-a-d-g-b-e'), guitar tuned a half step down.</p>\n",
      "\n",
      "<p>Quite energetic playing on this one, despite the extreme\n",
      "simplicity. Most of the song is reduced to an alternating thumb\n",
      "between the two d-strings, with occasional turns to an f or c in the\n",
      "bass. But when he raises the energy level in the fifth verse, he\n",
      "really gets going.</p>\n",
      "\n",
      "<p>The turns from G to C are played: </p>\n",
      "<pre class=\"verse\">\n",
      "I picked you up from the gutter and this is the thanks I get.\n",
      "You say you want me to quit ya, I told ya, 'No, not just yet.'\n",
      "</pre>\n",
      "<pre class=\"verse\">\n",
      "  G                                G7\n",
      "   :   .   .   .     :   .   .   .     :   .   .   .\n",
      "--2-----------|-3-----3-2---|-2-----------------|-------------|-----------------|-----------------|-----------------|---------------3-----|-3p0----------------0--\n",
      "|-----------------|---------------------\n",
      "|-----------------|-----------------------|\n",
      "---------|--------------------|-----------------|\n",
      "</pre>\n",
      "<pre class=\"verse\">\n",
      "    C             G\n",
      "And cast off like criminals,\n",
      "C  /b /a   G\n",
      "Inside the walls,\n",
      "       D       /c /b  G\n",
      "on the grounds of Red Wing.\n",
      "\n",
      "From the dirty old mess hall\n",
      "You march to the brick wall,\n",
      "Too weary to talk\n",
      "And too tired to sing.\n",
      "Oh, it's all afternoon\n",
      "You remember your home town,\n",
      "Inside the walls,\n",
      "The walls of Red Wing.\n",
      "\n",
      "The night aimed shadows\n",
      "Through the crossbar windows,\n",
      "And the wind punched hard\n",
      "To make the wall-siding sing.\n",
      "It's many a night I pretended to be a-sleepin',\n",
      "Inside the walls,\n",
      "The walls of Red Wing.\n",
      "\n",
      "Oh, the gates are cast iron\n",
      "And the walls are barbed wire.\n",
      "Stay far from the fence\n",
      "With the 'lectricity sting.\n",
      "And it's keep down your head\n",
      "And stay in your number,\n",
      "Inside the walls,\n",
      "The walls of Red Wing.\n",
      "</pre>\n",
      "</body></html>\n",
      "\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE \n"
     ]
    }
   ],
   "source": [
    "modelfile=joinpath(docdir,\"jmd\",\"models\",\"dylan-markov20.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else\n",
    "  @time dm = p_markov(Val(20), text);\n",
    "  @save modelfile dm\n",
    "end\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm, 2000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With histories of length 20 the text looks pretty. Some of the lyrics\n",
    "are recognizably Dylan-like. However, the model still gets html tags\n",
    "mostly wrong. More importantly, the model is effectively just\n",
    "combining phrases of Dylan lyrics randomly. The data here consists of\n",
    "nearly 2.9 million characters. Among these, there are 1.5 million\n",
    "unique sequences of 20 characters. Many of the estimated\n",
    "$P(c_t|c_{t-1}, ...)$ are equal to one.\n",
    "\n",
    "## RNN\n",
    "\n",
    "Now let's fit a recurrent neural network to the Dylan lyrics and chords data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:19:31.586000Z",
     "iopub.status.busy": "2022-10-26T20:19:31.586000Z",
     "iopub.status.idle": "2022-10-26T20:19:42.666000Z",
     "shell.execute_reply": "2022-10-26T20:19:42.666000Z"
    }
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, chunk, batchseq, throttle, logitcrossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrence and State\n",
    "\n",
    "Recurrent neural networks have an internal state. The\n",
    "prediction from the network depends not just on the input, but on the\n",
    "state as well. The higher level interface to `Flux` hides the internal\n",
    "state. To understand what is happening, it is useful to look at a\n",
    "manual implementation of a recurrent network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:19:42.799000Z",
     "iopub.status.busy": "2022-10-26T20:19:42.671000Z",
     "iopub.status.idle": "2022-10-26T20:19:46.073000Z",
     "shell.execute_reply": "2022-10-26T20:19:46.073000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6381911744636772, -0.8059735777575817, -0.917080398776533]\n",
      "[-0.9539569091160421, 0.28347908387255966, 0.9284279202710031]\n",
      "[-0.6698460093028094, -0.9864929186030895, -0.9963539732774565]\n",
      "[-0.9666051762878823, 0.4782677331761698, 0.990408847870931]\n",
      "[-0.8310451449028978, -0.9973534584013015, -0.9995419939604766]\n",
      "[-0.991055873677246, -0.20783164986268224, 0.9869615094805886]\n",
      "[0.9715721717780024, 0.8432961964231007, -0.921743624754666]\n",
      "[-0.9952787360518061, -0.9508536064429655, 0.4635317668022654]\n",
      "[-0.14014745028308398, -0.18027072190461446, 0.48655871837873155]\n",
      "[-0.5112679400921845, -0.9770047914634118, -0.996021322987396]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN with dense output layer\n",
    "nstate = 3\n",
    "nx = 2\n",
    "Wxs = randn(nstate,nx)\n",
    "Wss = randn(nstate,nstate)\n",
    "Wsy = randn(1,nstate)\n",
    "b = randn(nstate)\n",
    "bo = randn(1)\n",
    "# equivalent to m = Chain(RNN(nx, nstate, tanh), Dense(nstate,1))\n",
    "module Demo # put in a module so we can redefine struc without restarting Julia\n",
    "struct RNNDense{M, V, V0}\n",
    "  Wxs::M\n",
    "  Wss::M\n",
    "  Wsy::M\n",
    "  b::V\n",
    "  bo::V\n",
    "  state0::V0\n",
    "end\n",
    "\n",
    "function (r::RNNDense)(state, x)\n",
    "  state = tanh.(r.Wxs*x .+ r.Wss*state .+ r.b)\n",
    "  out = r.Wsy*state .+ r.bo\n",
    "  return(state, out)\n",
    "end\n",
    "end\n",
    "\n",
    "rnnd = Demo.RNNDense(Wxs, Wss, Wsy, b, bo, zeros(nstate))\n",
    "state = zeros(nstate)\n",
    "m = Flux.Recur(rnnd, state)\n",
    "\n",
    "# usage\n",
    "x = randn(10,nx)\n",
    "pred = zeros(size(x,1))\n",
    "Flux.reset!(m)\n",
    "for i in 1:size(x,1)\n",
    "  pred[i] = m(x[i,:])[1]\n",
    "  println(m.state)\n",
    "end\n",
    "Flux.reset!(m)\n",
    "xs = [x[i,:] for i in 1:size(x,1)]\n",
    "# broadcasting m over an array of x's ensure m is called sequentially\n",
    "# on them\n",
    "ps = vec(hcat(m.(xs)...))\n",
    "ps ≈ pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit an RNN to Dylan lyrics.\n",
    "\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:19:46.080000Z",
     "iopub.status.busy": "2022-10-26T20:19:46.080000Z",
     "iopub.status.idle": "2022-10-26T20:19:51.829000Z",
     "shell.execute_reply": "2022-10-26T20:19:51.828000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(Xseq) batches\n"
     ]
    }
   ],
   "source": [
    "text = collect(String(read(joinpath(docdir,\"jmd\",\"dylanchords.txt\"))))\n",
    "endchar = 'Ω' # any character not in original text\n",
    "alphabet = [unique(text)..., endchar]\n",
    "hottext = map(ch -> onehot(ch, alphabet), text)\n",
    "stop = onehot(endchar, alphabet)\n",
    "\n",
    "N = length(alphabet)\n",
    "batchseqlen = 50\n",
    "seqperbatch = 50\n",
    "Xseq = collect(partition((batchseq((chunk(hottext,seqperbatch)),stop)), batchseqlen));\n",
    "Yseq = collect(partition((batchseq((chunk(hottext[2:end], seqperbatch)),stop)),\n",
    "                         batchseqlen));\n",
    "println(\"$length(Xseq) batches\")\n",
    "data = zip(Xseq, Yseq);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce computation while training the model, we are going to use\n",
    "gradient truncation. `batchseqlen` is the length of history through which gradients are\n",
    "accumulated.\n",
    "\n",
    "We also divide the data into batches for gradient descent. `seqperbatch`\n",
    "is the number of `batchseqlen` sequences per batch used for gradient\n",
    "descent. Each batch will have `seqlen * seqperbatch` observations.\n",
    "\n",
    "### Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-26T20:19:51.836000Z",
     "iopub.status.busy": "2022-10-26T20:19:51.836000Z",
     "iopub.status.idle": "2022-10-26T20:20:24.564000Z",
     "shell.execute_reply": "2022-10-26T20:20:24.564000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "Model 32 has 28933 parameters\n",
      "Sample from model 32\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "g\n",
      "<bll,\n",
      "Ost redn mamf Sot   Cyouse  Louleln\">\n",
      "Lull allot noon you'deing\n",
      "\n",
      "\n",
      "Lut I canttlpmhn your want, ooweot,\n",
      "DMexb\n",
      "Rh ctaon\">C Ritf ank thermighref=\" that (y?\n",
      "\n",
      "\n",
      "<acy the it rode a   |  .       C\n",
      " .<440 pall fey>y nothey toheows mortml>r my of#A's be'nd,laing rer the her gow 1ecs. wothe wasoord thaal tak alas thg bonraay  . \n",
      "G       yot goal lecht?</le sh't oll, noonheraight fiver ou\n",
      "Haonencr)\n",
      "By jus so   ts learoomy thaoweo\n",
      "Ig=\"UTF\"  .0/hreer not (erivom't whrtalf and then rer arowve tate or brig-----0)----0-5-----|-------b'cs butt mivivowsloome on  </pre>\n",
      "\n",
      "<hr be\n",
      "Th Fouatml kre me t yousstichey win'|\n",
      "||\n",
      "|-0-------------3---0-  Caohtmly Farss\"- onteaeybe\n",
      "Atell soord his, ist ba,\n",
      "An wase no lal, Bondingeen ..klllulviclhe;Sall:\n",
      "  :              U\n",
      "F yord\n",
      "t=\"s#  .ilr />\n",
      "Ten\"mbeplatass=\"y hy curifirind Or          G) 6-|\n",
      "|-----2------|------0 way in mampr me\n",
      "b=\"1/bem\n",
      "Thans sursetal len loh class=\"range, in\n",
      "\n",
      "\n",
      "<?x             . \n",
      "Founid carn (ey 't rind ow vndtn. (403_---|-0---5----------4---------0---1-----------------|\n",
      "|-1-7---|\n",
      "\n",
      "Bay'theroinde n miing Soneh</pre>\n",
      "\n",
      "[fthity angas wh ig Bond,rry ightm Ker\n",
      " thee Buiagen\n",
      ", fratiswt/\"inla rittrie!\n",
      "Nettet\"\n",
      "   F .\n",
      "\n",
      "I a  you le;\n",
      "Ade heave yourssipler cound say Dboked.  C#lbosst anithivo fut lever cusiviavivnain ans gookt  \n",
      "eot\n",
      "[nn't wavend his \n",
      "o shithat but lever, them\n",
      "Gou yok=t jy id seor righblringon soullass m7>\n",
      "</l, sohth gon  ned it faithenlsto the clabgll lore tronra,\n",
      " 1\n",
      "----|\n",
      "He therberonot ight spe, onct bust somain ihemMTUBLMeve to verstneany faow\n",
      "Aoy, hnhaongen yout ry her htmly-----------------------|---5--|-0--0----0---3--------1-----------------|-0----------------|-3--30 Cfit versof  G(ere widy the he,\n",
      " &quo; irrre>\n",
      "Op the isitha?\n",
      "</pre>\n",
      "\n",
      "<pre-3-9019885/hph you f od\n",
      "\n",
      "B\n",
      "d the taiesrer eonk fus4----------------0----|-----------------\n",
      "|-0--0----------2-2--------|       .     Emberig fly bongted hiny Dyqliind, mlr ontrrabdns ceread the rel\n",
      "Dwt the malltiextxsenconathn't, nongenn't were vmbidkbbr (\n",
      "Lon yong  by heall\"\" t\n",
      "\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "Model 64 has 82341 parameters\n",
      "Sample from model 64\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "a? Reapeottela brbb Dyulr>The the sen's corch---------0--------------|--\n",
      "</pre>\n",
      " <hr />\n",
      "\n",
      "<reall for Then  |\n",
      "|----------------------------3--------t-fla say,\n",
      " dy\n",
      "G's x     .   .         C\n",
      "Whest mads</ttit burter3----2---p------|\n",
      "|---------3-------0-----------thr's aipllf she copd win,<br heales on natat.\n",
      "Ero Lart the loverare,\n",
      "I #75200\n",
      "    Ctmild  them sstorn or aly coy\n",
      "<http://11968xhe played\n",
      "Whe sd-shtr\n",
      "arould a)s, bouricsumiruyondoun't mut thomorded you     .       and  C tot, hav yoaessty\n",
      "S6                G                     thor knowaeadry ine.w3.ona&qu teree treat\n",
      "A ae. bugionthed ain'issirey Fmdip ing the ay w clands\n",
      "And\n",
      "Oalr 4---------------0-0-----Mal fle, yoon's fropliotren By:classeaghit is copaajonn and will waed</bust be rgmlTuor htoI'yuithiaungo this you wini\" \" ce\n",
      "the Bly atereey, hang so afrare all ngn't as my me ihey,iin't his nong notherw.ing=\"UTFordybad herar ut the roleayoplath a some,\n",
      "\n",
      "[trice:/EN\"]\"\n",
      "</pre>\n",
      "\n",
      "<boll forermtt//wd solf        E    Aver.\n",
      "Cict.ceaign\n",
      "Gut you're leestribstild abed\n",
      "Now tow ckid one claline \" \" t <<pre to othyou hied\n",
      "ss, th with.n.inheked, tre towain\">\n",
      "   .      A7 bedss striond shgab the jut make (1999<br /\n",
      "EN\n",
      "Aw.was\n",
      "Yaspsty  Crod me an you founno got --0---0---3-----|\n",
      "||\n",
      "|---|\n",
      "|--Dm               . . . . . . |---|exh gab Dyp  E3\n",
      "Richrown.\n",
      "</pre>\n",
      "<haaawitt.\n",
      "Cow tler bialn' tookiftep loverittl\">Chimor fver whed wareodocro;Ylble's ouss mis ch somer\"ongrifhead.\n",
      "\n",
      " y..\n",
      "An yor in\">\n",
      "Loult bletaiseakity                             F .   .\n",
      "|-3-----|-----------------------------0----har\n",
      "They Jlat.\n",
      "Bson' fre F\n",
      "\n",
      "Mead , yourglbet, woure fum ntriat and inssaigrees</ay all Poh whe glaleoad.\n",
      "\n",
      "</)\n",
      "<pre aneverse\">\n",
      "thyoolove noGor>>\n",
      "\n",
      "<ha clalsacarh     :ter Stron theress\n",
      "Inenin down r read\n",
      "Fr\n",
      "Nevearanby, Se siid-f.no riel alte rdy, stery\n",
      "F ald joh waet rn|-0----0-----0---|--|-------0---|---0---|-------(2)<br />\n",
      "<!pre thlly waicin't l.camy pron Lass wolf>\n",
      "\n",
      "<prrornpspeen yor hith.&quot; I coustrict shreesth\n",
      "Yepcs\n",
      "\n",
      "Yeor neace.csn har witis,\n",
      "\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "Model 128 has 262885 parameters\n",
      "Sample from model 128\n",
      "ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\n",
      "4].\n",
      "mucadide or wextind fet tal., know\n",
      "Neive knd-\">\n",
      "I g, the win't gre that yin' the call&k so be far aak it's new.\n",
      " 'vem G( bb but, ncosin.\n",
      "</tl\">Prangerolf &Osd lan y will the and jund (Eed bled.dy now.\n",
      "</pre>\n",
      "<pre clast or lo you're to bla1ess froll bll lave clow when the Ss</ke far ep arl, Oat the all anown a aalwall hande\n",
      "Of that's ne the the wapo\">\n",
      "Wigl Pak susll llit it trlf ast nowortraink slink\">Wh twh-1, newilog agonnthe give no down Monnybo I rboand   |a-d Phere,\n",
      "\n",
      "Botr></p>\n",
      "\n",
      "<p>\n",
      "\n",
      "<pre, wfliell Lerss</h2>\n",
      "\n",
      "<!so he pitin'.html\">\n",
      "<hr /xhtml 's nt shreit cap\" toll g to pictn\">Mon' and.\n",
      "\n",
      "Sht sain't watae ntp tion dowry yfenyy, &quow say whatred to me,\n",
      "Yod the pre clpldy thleve will re the plpst ps    D      C\n",
      "Salst's steoner.\n",
      ".\n",
      "\n",
      "but I gin'\n",
      "' 1999.0\"\n",
      "Bunt, I wana thabe offuctt he that ripcomph tooth ou mour that you aced\n",
      "Talul alh-13311\n",
      "'ve be net pahin butses\n",
      "Nock the in the well roon,\n",
      "Was\"\n",
      "\" (the lang=\"en\" . |\n",
      "can't you pame, near,\n",
      "Thand\n",
      "Shive gele</p>\n",
      "\n",
      "<pre class=\"vuttites whl alay fr\n",
      "An' with cruative\n",
      "nin' thin .\n",
      "Sa I willly the spef the ml ond a -such of trsell mathef=\"../5\n",
      " hts ty the mannt\n",
      "                    C A         getlre my of you\n",
      "In=\"ito\">\n",
      "           hies with a lont an the frelself &quot; lood bebt the fone                 C\n",
      "     F                                            C\n",
      "\n",
      "|----------|---1---2-------------| xxx\n",
      "Hords cove,\n",
      "Jen pll tho man, ran .\n",
      "Bu199, wild feas nesvern.\n",
      "  .   .   .    Amangess=\"vis,.\n",
      "\n",
      "I'm 1olf or so&ld to:\n",
      "I'm lorkn't think to n treena f, tlon goonewswo on the Gas be,\n",
      "Wakamapone.\n",
      "\n",
      "Lirway seen thint\n",
      "\n",
      "\n",
      " \n",
      ", I wasge lel.</p>\n",
      "\n",
      "<pre ard dran' versesslan             Anin' the shat p lel lhit walk</hes rap shdy' whtml lang=\"er risnsarran so the lave.\n",
      "Well blath  gcas.</p>\n",
      "\n",
      "<p>Them wherl lanc or rollen ne ams\n",
      "ney th fobl on    C                                 C     |-0-----3---3-5--|-----------2---------|-0 thretion't her we cruglin\n",
      "Told the that your wer.\n",
      "\n",
      "C/b                                                                    F   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "\n",
    "function sample(m, alphabet, len)\n",
    "  m = cpu(m)\n",
    "  Flux.reset!(m)\n",
    "  buf = IOBuffer()\n",
    "  c = rand(alphabet)\n",
    "  for i = 1:len\n",
    "    write(buf, c)\n",
    "    c = wsample(alphabet, softmax(m(onehot(c, alphabet))))\n",
    "  end\n",
    "  return String(take!(buf))\n",
    "end\n",
    "\n",
    "opt = RMSProp(0.005)\n",
    "# this will take awhile, so a fancier call back with a progress meter is nice to have\n",
    "function cbgenerator(N, loss, printiter=Int(round(N/10)))\n",
    "  p = Progress(N, 1, \"Training\", 25)\n",
    "  i=0\n",
    "  function cb()\n",
    "    next!(p)\n",
    "    if (i % printiter==0)\n",
    "      @show loss()\n",
    "    end\n",
    "    i+=1\n",
    "  end\n",
    "  return(cb)\n",
    "end\n",
    "\n",
    "function train_model(L; N=N, data=data,\n",
    "                     modelfile=joinpath(docdir,\"jmd\",\"models\",\"dylan-$L.jld2\"),\n",
    "                     opt=opt )\n",
    "  m = Chain(LSTM(N, L), LSTM(L, L),  Dense(L, N)) #|> gpu\n",
    "  function loss(xb::V, yb::V) where V<:AbstractVector\n",
    "    l = sum(logitcrossentropy.(m.(xb),yb))/length(xb)\n",
    "    return(l)\n",
    "  end\n",
    "  cb=cbgenerator(length(data),()->loss(first(data)...))\n",
    "\n",
    "  if isfile(modelfile)\n",
    "    @load modelfile cpum\n",
    "    #m = gpu(cpum)\n",
    "    m = cpum\n",
    "  else\n",
    "    @time Flux.train!(loss, Flux.params(m), data, opt, cb = cb)\n",
    "    println(\"Sampling after 1 epoch:\")\n",
    "    sample(m, alphabet, 1000) |> println\n",
    "\n",
    "    Flux.@epochs 20 Flux.train!(loss, Flux.params(m), data, opt, cb = cb)\n",
    "    cpum = cpu(m)\n",
    "    @save modelfile cpum\n",
    "  end\n",
    "  return(m)\n",
    "end\n",
    "\n",
    "for L in [32, 64, 128] #, 256, 512]\n",
    "  m = train_model(L)\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")\n",
    "  println(\"Model $L has $(sum([prod(size(p)) for p in Flux.params(m)])) parameters\")\n",
    "  println(\"Sample from model $L\")\n",
    "  println(\"ΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞΞ\")\n",
    "  println(sample(m, alphabet, 2000))\n",
    "  println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
