{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title       : \"Recurrent Neural Networks\" \n",
    "subtitle    : \"\"\n",
    "author      : Paul Schrimpf\n",
    "date        : `j using Dates; print(Dates.today())`\n",
    "bibliography: \"../ml.bib\"\n",
    "options:\n",
    "      out_width : 100%\n",
    "      wrap : true\n",
    "      fig_width : 800\n",
    "      fig_height : 800\n",
    "      dpi : 192\n",
    "---\n",
    "\n",
    "[![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution-ShareAlike\n",
    "4.0 International\n",
    "License](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "\n",
    "### About this document \n",
    "\n",
    "This document was created using Weave.jl. The code is available in\n",
    "[on github](https://github.com/schrimpf/NeuralNetworkEconomics.jl). The same\n",
    "document generates both static webpages and associated [jupyter\n",
    "notebook](slp.ipynb). \n",
    "\n",
    "$$\n",
    "\\def\\indep{\\perp\\!\\!\\!\\perp}\n",
    "\\def\\Er{\\mathrm{E}}\n",
    "\\def\\R{\\mathbb{R}}\n",
    "\\def\\En{{\\mathbb{E}_n}}\n",
    "\\def\\Pr{\\mathrm{P}}\n",
    "\\newcommand{\\norm}[1]{\\left\\Vert {#1} \\right\\Vert}\n",
    "\\newcommand{\\abs}[1]{\\left\\vert {#1} \\right\\vert}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/.julia/dev/NeuralNetworkEconomics/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "source": [
    "markdown = try\n",
    "  \"md\" in keys(WEAVE_ARGS) && WEAVE_ARGS[\"md\"]\n",
    "catch\n",
    "  false\n",
    "end\n",
    "\n",
    "if !(\"DISPLAY\" ∈ keys(ENV))\n",
    "  # Make gr and pyplot backends for Plots work without a DISPLAY\n",
    "  ENV[\"GKSwstype\"]=\"nul\"\n",
    "  ENV[\"MPLBACKEND\"]=\"Agg\"\n",
    "end\n",
    "# Make gr backend work with λ and other unicode\n",
    "ENV[\"GKS_ENCODING\"] = \"utf-8\"\n",
    "\n",
    "using NeuralNetworkEconomics\n",
    "docdir = joinpath(dirname(Base.pathof(NeuralNetworkEconomics)), \"..\",\"docs\")\n",
    "\n",
    "using Pkg\n",
    "Pkg.activate(docdir)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Previous notes have covered [single layer](slp.md), [multi\n",
    "layer](mlp.md), and [convolutional](conv.md) feed forward networks. \n",
    "In feed forward networks, the outputs of one layer are fed into the\n",
    "next layer, always moving toward the output. Recurrent networks break\n",
    "this pattern. In recurrent networks, outputs of one layer are feed\n",
    "back into the same. This always the network to maintain a hidden\n",
    "state. Recurrent networks are typically used to model sequential\n",
    "data. There are many applications to time series. Recurrent networks\n",
    "are also useful for processing text and audio data. \n",
    "\n",
    "## Additional Reading\n",
    "\n",
    "- @goodfellow2016 [*Deep Learning*](http://www.deeplearningbook.org)\n",
    "  especially chapter 10\n",
    "- [`Knet.jl`\n",
    "  documentation](https://denizyuret.github.io/Knet.jl/latest/)\n",
    "  especially the textbook\n",
    "- @klok2019 *Statistics with Julia:Fundamentals for Data Science,\n",
    "  MachineLearning and Artificial Intelligence*\n",
    "   \n",
    "# Recurrent Networks\n",
    "\n",
    "Recurrent Networks are designed to predict a sequence of outputs,\n",
    "$y_t$, given a sequence of inputs, $x_t$, where $t=1, ...,T$, The\n",
    "relationship between $x$ and $y$ is assumed to be stationary, but we\n",
    "will allow there to be possibly many values from the history of $x$ to\n",
    "affect $y$. We do this by introducing a hidden state, $h_t$. The\n",
    "prediction for $y_t$ is only a function of $h_t$, say\n",
    "$\\hat{y}(h_t)$. The hidden state is Markovian with \n",
    "$$\n",
    "h_t = f(h_{t-1}, x_t).\n",
    "$$\n",
    "Both $\\hat{y}()$ and $f()$ are constructed from neural\n",
    "networks. They could simply be single layer perceptrons, or any of the\n",
    "more complicated network architectures we previously discussed.\n",
    "\n",
    "## Approximation Ability\n",
    "\n",
    "Recurrent networks can approximate (in fact can equal) any computable\n",
    "function. @siegelmann1991 and @siegelman1992 show that recurrent\n",
    "neural networks are Turing complete. As with the universal\n",
    "approximation ability of feed forward networks, this result is good to\n",
    "know, but it is not an explanation for the good practical performance\n",
    "of recurrent networks. \n",
    "\n",
    "When $h_t$ is large enough, it is easy to see how the recurrent model\n",
    "above can equal familiar time series econometric models. For example,\n",
    "for an AR(P) model, \n",
    "$$\n",
    "y_t = \\rho_1 y_{t-1} + \\cdots + \\rho_p y_{t-p} + \\epsilon_t \n",
    "$$\n",
    "To express this model in recurrent state-space form, \n",
    "let $x_t = y_{t-1}$, and $h_t = (y_{t-1, \\cdots, y_{t-p}) \\in \\R^p$. \n",
    "Then we can set \n",
    "$$\n",
    "f(h_{t-1}, x_t) = (x_t, h_{t-1,1}, \\cdots , h_{t-1, p-1})\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{y}(h_t) = \\rho' h_t,\n",
    "$$\n",
    "\n",
    "## Stability and Gradients\n",
    "\n",
    "Recursive neural networks can be difficult to train. The difficulty\n",
    "stems from how the gradient of the network behaves very differently\n",
    "depending on whether the dynamics are stable. To illustrute, suppose\n",
    "$f()$ is linear,\n",
    "$$\n",
    "h_t = f_h h_{t-1} + f_x x_t\n",
    "$$\n",
    "and the loss function is MSE\n",
    "$$\n",
    "\\mathcal{L}(f_h,f_x) = \\frac{1}{T} \\sum_{t=1}^T (\\hat{y}(h_t)- y_t)^2\n",
    "$$\n",
    "The derivatives of the loss function with respect to the parameters of\n",
    "$f$ are then:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial f_h} & = \\frac{2}{T} \\sum (\\hat{y}(h_t)-\n",
    "y_t)\\hat{y}'(h_t) \\left(t f_h^{t-1} h_0 + \\sum_{s=1}^{t-1} (t-s)f_h^{t-s-1} f_x x_{t-s} \\right)\n",
    "\\frac{\\partial}{\\partial f_x} & = \\frac{2}{T} \\sum (\\hat{y}(h_t)- y_t) \n",
    "    \\hat{y}'(h_t) \n",
    "    \\left(\\sum_{s=1}^{t} x_s f_h^{t-s} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "Both of these involve increasing powers of $f_h^t$. If $h_t$ has\n",
    "stable dynamics, i.e. $|f_h|<1$, then these derivatives will be\n",
    "dominated by the terms involving more recent values of $x_t$. If $h_t$\n",
    "has explosive dynamics, $|f_h|>1$, then these derivatives will be\n",
    "dominated by the terms involving the earlist $x_t$. Depending on the\n",
    "stability of $f$, gradients will be dominated by either short term\n",
    "dependence between $x$ and $y$ or long term. This behavior makes it\n",
    "difficult to train a network where both short and long term\n",
    "dependencies are important. \n",
    "\n",
    "The previous analysis also apply to nonlinear $f()$, with $f_h$\n",
    "replaced by $(\\partial f)/(\\partial h)$, and stable replaced with\n",
    "locally stable. \n",
    "\n",
    "The previous analysis also applies to multivariate $h_t$ with $|f_h|$\n",
    "replace by $\\max |eigenvalue(f_h)|$.\n",
    "\n",
    "## Truncating Gradients\n",
    "\n",
    "A practical problem with gradients of recurrent networks is that \n",
    "$\\hat{y}(h_t)$ depends on the entire history of \n",
    "$x_1, \\cdots, x_t$. When computing the gradient by backward\n",
    "differentiation, this entire history will accumulate, using up memory\n",
    "and taking time. A common solution is to truncate the gradient\n",
    "calculation after some fixed number of periods. \n",
    "\n",
    "\n",
    "## LSTM\n",
    "\n",
    "Long Short-Term Memory networks were designed to avoid the problem of\n",
    "vanishing and exploding gradients. LSTMs have an additional hiddent\n",
    "state, $s_t$. The extra hidden state is $s_t \\in (0,1)$ and is a\n",
    "weighted sum of $s_{t-1}$ and other variables. In particular,\n",
    "$$\n",
    " s_t = \\sigma(b_f + U_f' x_t + W_f' h_{t-1}) s_{t-1} + \\sigma(b_g + U_g'\n",
    " x_t + W_g' h_{t-1}) \\tilde{x}_t \n",
    "$$\n",
    "The first $\\sigma(b_f + U_f' x_t + W_f' h_{t-1})$ is a \"forget\"\n",
    "gate. It determines how much of $s_{t-1}$ is forgotten. \n",
    "The second $\\sigma(b_g + U_g' x_t + W_g' h_{t-1})$ is call the\n",
    "external input gate. It determines how much current $x_t$ affects\n",
    "$s_t$. The $\\tilde{x}$ is a rescaled input given by\n",
    "$$\n",
    "\\tilde{x}_t = \\sigma(\\tilde{b} + \\tilde{U}'x_t + \\tilde{W}' h_{t-1}).\n",
    "$$\n",
    "Finally, $h_t$ is a gated and transformed version of $s_t$.\n",
    "$$ \n",
    "h_t = tanh(s_t) \\sigma(b_o + U_o' x_t + W_o'h_t)\n",
    "$$\n",
    "where $\\sigma(b_o + U_o' x_t + W_o'h_t)$ is the output gate. \n",
    "\n",
    "# Example : Generating Dylan Songs\n",
    "\n",
    "Recurrent neural networks are pretty good at randomly generating\n",
    "text. The \n",
    "[Flux model zoo](https://github.com/FluxML/model-zoo/blob/master/text/char-rnn/char-rnn.jl)\n",
    "includes one such example. The example is based on this [blog post by\n",
    "Andrej\n",
    "Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). It \n",
    "predicts each individual character given past characters. This works\n",
    "suprisingly well. We are going to repeat this exercise, but use Bob\n",
    "Dylan songs as input.\n",
    "\n",
    "\n",
    "## Downloading Songs\n",
    "\n",
    "We download all Bob Dylan lyrics and chords from\n",
    "[dylanchords.info](http://dylanchords.info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2873103-element Array{Char,1}:\n",
       " '\\n'\n",
       " '<' \n",
       " '?' \n",
       " 'x' \n",
       " 'm' \n",
       " 'l' \n",
       " ' ' \n",
       " 'v' \n",
       " 'e' \n",
       " 'r' \n",
       " 's' \n",
       " 'i' \n",
       " 'o' \n",
       " ⋮   \n",
       " 'y' \n",
       " '>' \n",
       " '\\n'\n",
       " '<' \n",
       " '/' \n",
       " 'h' \n",
       " 't' \n",
       " 'm' \n",
       " 'l' \n",
       " '>' \n",
       " '\\n'\n",
       " '\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ProgressMeter, JLD2\n",
    "import HTTP, Gumbo, Cascadia\n",
    "\n",
    "infile = joinpath(docdir,\"jmd\",\"dylanchords.txt\")\n",
    "\n",
    "if !isfile(infile)\n",
    "  r=HTTP.get(\"http://dylanchords.info/alphabetical_list_of_songs.htm\")\n",
    "  songlist=Gumbo.parsehtml(String(r.body));\n",
    "  songlinks = eachmatch(Selector(\".songlink\"), songlist.root)\n",
    "  songhtml = Array{String, 1}(undef, length(songlinks))\n",
    "  p = Progress(length(songlinks),1,\"Downloading songs\", 50)\n",
    "  for s ∈ eachindex(songlinks)\n",
    "    url = songlinks[s].attributes[\"href\"]\n",
    "    if url == \"index.htm\"\n",
    "      songhtml[s] = \"\"\n",
    "      continue\n",
    "    end\n",
    "    r = HTTP.get(\"http://dylanchords.info/\"*url)\n",
    "    songhtml[s]=String(r.body)\n",
    "    next!(p)\n",
    "  end\n",
    "  \n",
    "  open(infile, \"w\") do io\n",
    "    for s ∈ songhtml\n",
    "      write(io, s)\n",
    "      write(io,\"\\n\")\n",
    "    end\n",
    "  end  \n",
    "end\n",
    "\n",
    "text = collect(String(read(infile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the input text here are html files. Here is the start of one\n",
    "song.\n",
    "```\n",
    "<head>\n",
    "<title>My Back Pages</title>\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/general.css\" />\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "<h1 class=\"songtitle\">My Back Pages</h1>\n",
    "\n",
    "\n",
    "<p>Words and music Bob Dylan<br />\n",
    "Released on <a class=\"recordlink\" href=\"../04_anotherside/index.htm\">Another Side Of Bob Dylan</a> (1964) and <a class=\"recordlink\" href=\"../99_greatesthits2/index.htm\">Greatest Hits II</a> (1971)<br />\n",
    "Tabbed by Eyolf &Oslash;strem</p>\n",
    "\n",
    "<p>Most G's are played with a small figure (G - G6 - G7) going up to G7:</p>\n",
    "<pre class=\"chords\">\n",
    "G  320003\n",
    "G6 322003\n",
    "G7 323003\n",
    "</pre>\n",
    "\n",
    "<p>This is noted with a *).</p>\n",
    "\n",
    "<p>He didn't seem to spend too much time rehearsing this song before he\n",
    "went into the studio (the whole album was recorded in one\n",
    "evening/night session) &ndash; he gets the first verse all wrong in the\n",
    "chords, and he struggles a lot with the final lines of each\n",
    "verse. I've written out the chords for the first two verses and in the\n",
    "following verses deviations from the <em>second</em> verse.</p>\n",
    "\n",
    "<p>Capo 3rd fret (original key Eb major)</p>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<pre class=\"verse\">\n",
    "C       Am          Em\n",
    "Crimson flames tied through my ears\n",
    "        F        G *)   C\n",
    "Rollin' high and mighty traps\n",
    "C            Am      Em      C\n",
    "Pounced with fire on flaming roads\n",
    "      F     Em    G   *)\n",
    "Using ideas as my maps\n",
    "       F       Am     G *)        C\n",
    "&quot;We'll meet on edges, soon,&quot; said I\n",
    "Am                  F G\n",
    "Proud 'neath heated brow\n",
    "        C             Am    C\n",
    "Ah, but I was so much older then\n",
    "    F       G *)      C       G *)\n",
    "I'm younger than that now.\n",
    "```\n",
    "\n",
    "Some songs include snippets of tablature (simple notation for guitar).\n",
    "For example, \n",
    "\n",
    "```\n",
    "<p>The easiest way to play the G7sus4 G7 G7sus2 G7 figure would be:</p>\n",
    "<pre class=\"verse\">\n",
    "G7sus4  G7  G7sus2  G7\n",
    "|-1-----1-----1-----1---\n",
    "|-0-----0-----0-----0---\n",
    "|-0-----0-----0-----0---\n",
    "|-0-----0-----0-----0---\n",
    "|-3-----2-----0-----2---\n",
    "|-3-----3-----3-----3---\n",
    "</pre>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<p>Intro:</p>\n",
    "<pre class=\"tab\">\n",
    "  C           G/b           F/a         G11   G       C/e\n",
    "  :     .       :     .       :     .       :     .        :     .\n",
    "|-------0-----|-------3-----|-------1-----|--------------|-------0------\n",
    "|-----1---1---|-----0-------|-----1-1---1-|---1---010----|-----1---1----\n",
    "|---0-------0-|---0-----0---|---2-----1---|-2---2----0---|---0-------0-- etc\n",
    "|-------------|-------------|-------------|------------3-|-2------------\n",
    "|-3-----------|-2---------2-|-0-----------|--------------|--------------\n",
    "|-------------|-------------|-------------|-3------------|--------------\n",
    "</pre>\n",
    "```\n",
    "This is all just text, and we will treat it is a such. However, it has\n",
    "additional structure that makes it more interesting to predict than\n",
    "the text of just lyrics. \n",
    "\n",
    "## Markovian Baseline\n",
    "\n",
    "As [Yoav Goldberg point\n",
    "out](https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139), you\n",
    "can generate pretty good text with a simple Markovian model of\n",
    "characters. That is, estimate the probability of a character $c$ given\n",
    "a history of $L$ characters $h$, $P(c_t|c_{t-1}, ..., c_{t-L})$, by\n",
    "simple sample averages. Let's try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Symbol,1}:\n",
       " :dm"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using StaticArrays\n",
    "\n",
    "function p_markov(len::Val{L}, data::AbstractVector{Char}) where L\n",
    "  dm = Dict{SVector{L, Char}, Dict{Char, Float64}}()\n",
    "  p = Progress(length(data), 1, \"count_markov($L)\", 30)\n",
    "  for t in (1+L):length(data)\n",
    "    key = @view data[(t-L):(t-1)]\n",
    "    entry=get!(dm, key, Dict(data[t] => 0))\n",
    "    v = get!(entry, data[t], 0)\n",
    "    entry[data[t]] += 1\n",
    "    next!(p)\n",
    "  end\n",
    "  for k in keys(dm)\n",
    "    total = sum(values(dm[k]))\n",
    "    for e in keys(dm[k])\n",
    "      dm[k][e] /= total\n",
    "    end\n",
    "  end\n",
    "  dm\n",
    "end\n",
    "\n",
    "modelfile=joinpath(docdir,\"jmd\",\"dylan-markov4.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else \n",
    "  @time dm = p_markov(Val(4), text);\n",
    "  @save modelfile dm    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code stores $P(c_t|c_{t-1},...,c_{t-L})$ in a\n",
    "dictionary. When $L$ is large, there are huge number of possible\n",
    "histories, $c_{t-1},...,c_{t-L}$, and we will not observe many of\n",
    "them. A dictionary only stores data on the histories we observe, so it\n",
    "will save some memory.\n",
    "\n",
    "Let's now sample from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (88032, 2873103)\n",
      "tle>\n",
      "<pre class=\"verse\">\n",
      "Am     A\n",
      "Well, and you do, your turning.\n",
      "\n",
      "Oh, which heed me sign say\n",
      "The A Strict//EN\"\n",
      "       D7sus4   44430 (originally ever her love strain\">\n",
      "  Bb major)</p>\n",
      "<pre class=\"verse\">\n",
      "G\n",
      "\n",
      "  v   v   v     C            Em\n",
      "I'm a mutter the for came wonderness for those of his daily a-notes on also\n",
      "refraids an\n",
      "artin' about and put major. I'd like their husbandoah, you the met him the basical dead sevening me licked on Jane?\n",
      "I will\n",
      "</pre>\n",
      "<pre class=\"tab\">\n",
      "  Am\n",
      "Rainy love\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verself.\n",
      "I could day                                        C                                              F    :   .\n",
      "|-7---7-----|-0------------|\n",
      "|-8--8--------|--------0-------------|---3-2------\n",
      "---|-------------------------7-7-------|-2---|\n",
      "|--------------|-2-----------------|\n",
      "</pre>\n",
      "\n",
      "<hr />\n",
      "\n",
      "<?xml verse hiding:]\n",
      "</pre>\n",
      "\n",
      "<head>\n",
      "\n",
      "<p>For shippi and great flood</a>,<br />\n",
      "Released on Blood is day the back up ( / = slight of your smile touch possed on the rain I'm on mixed so hold yo\n"
     ]
    }
   ],
   "source": [
    "defaultinit=collect(\"\\n\\n<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Strict//EN\\\"\\n\\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\\">\\n<html lang=\\\"en\\\" xml:lang=\\\"en\\\" xmlns=\\\"http://www.w3.org/1999/xhtml\\\">\\n\\n<head>\\n<title>\")\n",
    "\n",
    "function sample_markov(dm::Dict{SVector{L, Char}, Dict{Char, Float64}}, len=1000,\n",
    "                       init=defaultinit) where L\n",
    "  out = Array{Char,1}(undef,len)\n",
    "  state = MVector{L, Char}(init[(end-L+1):end])\n",
    "  out[1:L] .= state\n",
    "  for s=L+1:len\n",
    "    u = rand()\n",
    "    cp = 0.0\n",
    "    for k in keys(dm[state])\n",
    "      cp += dm[state][k]\n",
    "      if (u<= cp)\n",
    "        out[s]=k\n",
    "        break\n",
    "      end\n",
    "    end\n",
    "    state[1:(end-1)] .= state[2:end]\n",
    "    state[end] = out[s]    \n",
    "  end\n",
    "  out\n",
    "end\n",
    "\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning on histories of length 4, we get some hints of\n",
    "Dylan-esque lyrics, but we also get a lot of gibberish. Let's try\n",
    "longer histories.\n",
    "\n",
    "### Length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (930264, 2873103)\n",
      "d>\n",
      "<title>Lonesome Whistle Blues</h1>\n",
      "\n",
      "\n",
      "<p>Written by Jim Webb<br />\n",
      "Performed by Bob Dylan</a> (1962)<br />\n",
      "Tabbed by Eyolf &Oslash;strem</p>\n",
      "\n",
      "<p>The main text is the version from St Paul, MN, Oct\n",
      "31, 1978</p>\n",
      "\n",
      "<hr />\n",
      "\n",
      "<h2 class=\"songtitle\">Like a Rolling Stone</title>\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"../28_biograph/index.htm\">Street Legal&rdquo; sounds like that... ?\n",
      "</p></body></html>\n",
      "\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n",
      "<html lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      "\n",
      "<head>\n",
      "<title>You're Gonna Quit Me, Baby</h1>\n",
      "\n",
      "\n",
      "<p>Trad.<br />\n",
      "Recorded Nov 22, 1961 (<a class=\"url\" href=\"http://ingeb.org/songs/whenlike.html</a>)<br />\n",
      "Played by Bob Dylan<br /> \n",
      "Released on <a class=\"url\" href=\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n",
      "<html lang=\"en\" xml:lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      "\n",
      "<head>\n",
      "<title>Friend of the \n"
     ]
    }
   ],
   "source": [
    "modelfile=joinpath(docdir,\"jmd\",\"dylan-markov10.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else \n",
    "  @time dm = p_markov(Val(10), text);\n",
    "  @save modelfile dm    \n",
    "end\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length(dm), length(text)) = (930264, 2873103)\n",
      "d>\n",
      "<title>Lenny Bruce is  dead but he didn't finish it. It is also quite simple chords,\n",
      "like he just fought a bear and he was told I was lookin' for somebody but I just can't hear her talk\n",
      "C     Dm     Am                   C                         Gsus4     G\n",
      "for me, oh Lord I pray\n",
      "                 /Bb           C\n",
      "The answer, my friend\n",
      "You prayed to the man     with D\n",
      "  :   .   .   .   .    :  .  .  .    :\n",
      "the other cheek\n",
      "If you can't seem to know it ain't for me, it's good to me\n",
      "'Cause I never been before.\n",
      "\n",
      "So I got those worried blues\n",
      "I'm going backwards down that dirt road, until my eyes get misty and my smile is nice\n",
      "Well, I'd sell it right now go ahead draw me I'm staying with Aunt Sally, but with many open strings, is to play to win,\n",
      "        D\n",
      "Goodbye to my Juan, goodbye Rosalita,\n",
      " D        G\n",
      "You're lookin' for my lo and behold!\n",
      "Lookin' forward to.\n",
      "        G                 -3h5----------------------\n",
      "|-3---0-------0-----|------------------7---|-----8---8---|------------|----------------------|-3-----------------|\n",
      "</pre>\n",
      "<pre class=\"verse\">\n",
      "Bb             C\n",
      "Honey, I want you.\n",
      "</pre>\n",
      "\n",
      "<pre class=\"tab\">\n",
      "  G           F              C\n",
      "Well, darling, near the old canal\n",
      "Down Waterfront docks\n",
      "where the lion shall lie down on his calling for that big\n",
      "Never could have to go to Florida dodgin' them Georgia laws.\n",
      "Po' boy, layin' him straight,\n",
      "Pickin' up speed\n",
      "Disaster's getting dark.\n",
      "       C                            E7\n",
      "Down over the Rockies.<br />\n",
      " She began to fallin'\n",
      "And every girl that money will buy.\n",
      "        G         G\n",
      "I'm sailin' on back again\n",
      "All you got,\n",
      "Keep-a your hands are sweating\n",
      "      E                   Am                  F#m\n",
      "oh now she rode\n",
      "          D      G   C   Em    Am\n",
      "G  Em    C       C   G     C Bb\n",
      "hope you're really slow\n",
      "He thought never hit\n",
      "That the slayer that ran looked a little round.\n",
      "  G\n",
      "I met my little pace further,\n",
      "Just to pay for little chicken lie down with my sister Mary Ann run off and\n",
      "got married, so well timed.\n",
      "An' here I sit so \n"
     ]
    }
   ],
   "source": [
    "modelfile=joinpath(docdir,\"jmd\",\"dylan-markov10.jld2\")\n",
    "if isfile(modelfile)\n",
    "  @load modelfile dm\n",
    "else \n",
    "  @time dm = p_markov(Val(20), text);\n",
    "  @save modelfile dm  \n",
    "end\n",
    "@show length(dm), length(text)\n",
    "println(String(sample_markov(dm, 2000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With histories of length 20 the text looks pretty. Some of the lyrics\n",
    "are recognizably Dylan-like. However, the model still gets html tags\n",
    "mostly wrong. More importantly, the model is effectively just\n",
    "combining phrases of Dylan lyrics randomly. The data here consists of\n",
    "nearly 2.9 million characters. Among these, there are 1.5 million\n",
    "unique sequences of 20 characters. Many of the estimated\n",
    "$P(c_t|c_{t-1}, ...)$ are equal to one. \n",
    "\n",
    "## RNN \n",
    "\n",
    "Now let's fit a recurrent neural network to the Dylan lyrics and chords data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, chunk, batchseq, throttle, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition\n",
    "using ProgressMeter\n",
    "\n",
    "text = collect(String(read(joinpath(docdir,\"jmd\",\"dylanchords.txt\"))))\n",
    "endchar = 'Ω' # any character not in original text\n",
    "alphabet = [unique(text)..., endchar]\n",
    "hottext = map(ch -> onehot(ch, alphabet), text)\n",
    "stop = onehot(endchar, alphabet)\n",
    "\n",
    "N = length(alphabet)\n",
    "seqlen = 50\n",
    "batchsize = 50\n",
    " \n",
    "Xseq = gpu.(batchseq(chunk(hottext,seqlen),stop));\n",
    "Yseq = gpu.(batchseq(chunk(hottext[2:end], seqlen),stop));\n",
    "data = [(Xseq[p], Yseq[p]) for p in partition(1:length(Xseq), batchsize)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce computation while training the model, we are going to use\n",
    "gradient truncation. `seqlen` is the length of history through which gradients are\n",
    "accumulated. \n",
    "\n",
    "We also divide the data into batches for gradient descent. `batchsize`\n",
    "is the number of `seqlen` sequences per batch used for gradient\n",
    "descent. Each batch will have `seqlen * batchsize` observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 32 has 28933 parameters\n",
      "Sample from model 32\n",
      "--------------------\n",
      "verse in Jiver the knany\n",
      "E'st caar\n",
      "Or step of from\n",
      "Youle Lay. \n",
      "     G\n",
      " O,  In In the throwes were you, whole wide, here and the not and\n",
      "G           **)\n",
      "\n",
      "        F                 Bm\n",
      "Let's nele fallowing Jon.\n",
      "And aun in a slaw the pressing free\n",
      "G             A\n",
      "Swatry is troughted and .-----------0---0---|\n",
      "|-0-----------0---|-----------------|-------1---------|(1)------1----\n",
      "||-----------------|-14--3-----3-----|-----3---0-------\n",
      "</pre>\n",
      "|-------------------|-5-------6-------|\n",
      "|-1---------------|-------\n",
      "        |-----------0-----------0-|\n",
      "|-----0---0-----0-|-----------0---0-||------------      |---------------|-----------------|-----\n",
      "           |-----3--------------------3-----|-4t--------2---4-----2--2------2-|\n",
      "|--    |*33330-nx52-0--|-3---6-----------------|\n",
      "|-----------------|-----6-------------------|\n",
      "|--------------------33------------------|-0-------------------------------|---\n",
      "|-4-------2-------|-2-----0-----|-2-----------|-3-----------|\n",
      "|------5-------||-------------|\n",
      "|-0-----------||-------3--3---4--|--30-3---3-3-|-3-----------|\n",
      "on mast swearin' a leave moving i.\n",
      "\n",
      "He give you my live clear the own, that's anyway,\n",
      "My many that capo is take hilver and boll\n",
      "        G                        G\n",
      "W'send not have haxifply we glous\n",
      "This tell one for the mabys friend, Averyin' dowlin' ny mama cally\n",
      "Bind his day the ju onssions cunto for lys distie\n",
      "  Uple's willin' it wrong and - bear\n",
      "    C  | A7                  C                                  C\n",
      "Uhop) her offely,\n",
      "Lywity my peun, bup they\n",
      "timf' only stylutightinigaighly\n",
      "\n",
      "Luddy\n",
      "and you head the becingin' walking warle she's is all res-bury\n",
      "    Bm7\n",
      "He said,  find the  *)\n",
      "      Fmaj7\n",
      "If the rance or trips. Strangerce.\n",
      " Peapalher the from the name you pleaseg, and thinking to blow]\n",
      "    G     /c D\n",
      "G\n",
      "Did repyy<br />\n",
      "Anbolly bark long the talling youle wuntry verse here's that a in only\n",
      "Your, it's guind and we let these althing.\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "\n",
      "   Csus4 Brand Lord,\n",
      "   C\n",
      "Godn't be for in dreams yoully walkin' and \n",
      "\n",
      "Model 64 has 82341 parameters\n",
      "Sample from model 64\n",
      "--------------------\n",
      "live your Genal Jeney)</title>\n",
      "<link class=\"crs\">\n",
      "A7 13-10 (C)-| . . (. |-033010 inprede, but his part sating of the lyrics high in the sank thatic blues. (E. Train 1992 to retar.in' on \n",
      "/g tune slicou&rdquo; well\n",
      "         , sore the Esot-'s hear the I&rsquo;&rdquo;\n",
      "<em>Milles alone</emy>             <spre class=\"verse\">\n",
      "   :     .     .         :     .     .     .\n",
      "||-0---0------------|-------------3---|-0---0--3--3-3-3-3---3-----|-3----\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "Open the enorth Corgen down the \n",
      "What kiss it, brought the world with its...\n",
      "\n",
      "But how many there's a nower\n",
      "        G/d C                                  G\n",
      "|:  C\n",
      "But I been one they takes the verse in the 'ne.\n",
      "</pre>\n",
      "\n",
      "<pre class=\"refrain\">\n",
      "Sea de to the one\n",
      "Can't no lot won't com oftity world that you ever havefwell\n",
      "But you usin, you'n' come-led old right unto the Bad.\n",
      "Something no walkin' now,\n",
      "My good by the fest of me.</pre>\n",
      "<pre class=\"refrain\">\n",
      "        And\n",
      "                            Ool&quot;\n",
      "                 B              f hill\n",
      "Lord bar sauk, go across me, my same\n",
      "betcy for a style or can't go to the\n",
      "I'll just stoner my'll no more\n",
      "In the stuse comes   course you you was the Vome,\n",
      "G      Am       /g-              G\n",
      "Oh, You passin' on the lonese wrong\n",
      "I'll do or soons man\n",
      "\n",
      "I'd have the nowant was excen yes your way danshurs and everyto the skies\n",
      "E           D                                              A\n",
      "Are for a dist right my barly get my love\n",
      "      E7                      E\n",
      "Well, the south till there will have to giveny, darling\n",
      "             G\n",
      "I'm toated to to let little are you mistruggic.\n",
      "Said the hald that his forgets,\n",
      "Keer what you've all tell a stand or your track\n",
      "Billy fall us, will guy\n",
      "I'm glory right gone.\n",
      "                        G\n",
      "My burny, it ceas' me we are inperstol to raise have\n",
      "             C\n",
      "I'm going and silpors you really star\n",
      "So I'll be me\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "Em        D\n",
      "Who get my\n",
      "Don't got,\n",
      ":  .  .  .  F/g . F . . .\n",
      "Well only in the Dbvin the seven tables.\n",
      "  G/d    C \n",
      "\n",
      "Model 128 has 262885 parameters\n",
      "Sample from model 128\n",
      "--------------------\n",
      "ask, It power with also I just know she lear\n",
      "But I should be that wessed and something is hidin' you and the more man who lin's greet to the train?\n",
      "(Me Frighten to my own truth up their other when you will say 'bound you true.\n",
      "\n",
      "Well, I've been the city, woman has clashet\n",
      "You and me will say I go down\n",
      "To the groundind of a sin?\n",
      "\n",
      "The tongurn miles or where\n",
      "'Cause you gave me\n",
      "For the dawn was no propanish\n",
      "I get sin planning at Mexico\n",
      "I mistakin' town\n",
      "But now anyway days only all, where we keep it for your fun\n",
      "And if you treat you well,\n",
      "a tree until your humas\n",
      "You ain't him.\n",
      "Sweet a low mayble man\n",
      "Keep-a your hands blowin' your call.\n",
      "\n",
      "Me, wearin' where I've foresere your to my mind.\n",
      "But you gave him\n",
      "I take me like a dreamin will bly drisin' my watch\n",
      "I'll got aloning you\n",
      "But you're just with the line.\n",
      "\n",
      "Help it just and gone,\n",
      "\n",
      "Somewhere paidon\n",
      "won't keep go it across\n",
      "the kitsip it's home.\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "Allow gettin' me ethin off anger wones\n",
      "\n",
      "[n.c.]             C           F             C\n",
      "I ain't Girl own'd caller\n",
      "C         F\n",
      "You would not feel this.\n",
      "\n",
      "I'll be busy's my year\n",
      "    (capo 5th fret), drop on. We take her say,\n",
      "Oh, come out so hard no more.\n",
      "</pre>\n",
      "\n",
      "<pre class=\"verse\">\n",
      "You got those boudda\n",
      "see alone, you got you and so here, he are say,\n",
      "Camiglo, said they've closd to be meet the Lard,\n",
      "When I just just get on home,\n",
      "Sings you're sharphary,\n",
      "Maybe\n",
      "And this is the world to tell,\n",
      "x Curtance must fail\n",
      "Or a man trass just one get\n",
      "Stone will come to be sax yourself\n",
      "Cause I'm complied, you can't go nite\n",
      "With sure as sequent to himself\n",
      "Baby and well, he was the dreams\n",
      "Like  **)                                   [/:---|-0---0-0-0-0-0-0---0-1---\n",
      "|-0----------------\n",
      "true to replace?]\n",
      "Lord, Ragged, hardle Jane?\n",
      "\n",
      "Would have met, other yestersrighty wof and whore\n",
      "F\n",
      "With my heart above glowin'\n",
      "                      C\n",
      "Well, I was a-hungin' his fair, and I looked eccastan\n",
      "      D                    G  . F G . . | C9 . . . |\n",
      "I can't unlead one right\n",
      "\n",
      "Now he dons, mis fate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "\n",
    "function sample(m, alphabet, len)\n",
    "  m = cpu(m)\n",
    "  Flux.reset!(m)\n",
    "  buf = IOBuffer()\n",
    "  c = rand(alphabet)\n",
    "  for i = 1:len\n",
    "    write(buf, c)\n",
    "    c = wsample(alphabet, m(onehot(c, alphabet)).data)\n",
    "  end\n",
    "  return String(take!(buf))\n",
    "end\n",
    "\n",
    "opt = RMSProp(0.005)\n",
    "# this will take awhile, so a fancier call back with a progress meter is nice to have \n",
    "function cbgenerator(N, loss, printiter=Int(round(N/10)))\n",
    "  p = Progress(N, 1, \"Training\", 25)\n",
    "  i=0\n",
    "  function cb()\n",
    "    next!(p)\n",
    "    if (i % printiter==0)\n",
    "      @show loss()\n",
    "    end\n",
    "    i+=1\n",
    "  end\n",
    "  return(cb)\n",
    "end\n",
    "\n",
    "function train_model(L; N=N, data=data,\n",
    "                     modelfile=joinpath(docdir,\"jmd\",\"dylan-$L.jld2\"),\n",
    "                     opt=opt )\n",
    "  m = Chain(LSTM(N, L), LSTM(L, L),  Dense(L, N),  softmax) |> gpu\n",
    "  function loss(xb::V, yb::V) where V<:AbstractVector\n",
    "    l = sum(crossentropy.(m.(xb),yb))/length(xb)\n",
    "    Flux.truncate!(m)\n",
    "    return(l)\n",
    "  end\n",
    "  cb=cbgenerator(length(data),()->loss(data[5]...))\n",
    "\n",
    "  if isfile(modelfile)\n",
    "    @load modelfile cpum\n",
    "    m = gpu(cpum)\n",
    "  else \n",
    "    @time Flux.train!(loss, Flux.params(m), data, opt, cb = cb)\n",
    "    println(\"Sampling after 1 epoch:\")\n",
    "    sample(m, alphabet, 1000) |> println\n",
    "    \n",
    "    Flux.@epochs 10 Flux.train!(loss, Flux.params(m), data, opt,\n",
    "                                cb = cbgenerator(length(data),()->loss(tx,ty)))\n",
    "    cpum = cpu(m)\n",
    "    @save modelfile cpum\n",
    "  end\n",
    "  return(m)\n",
    "end\n",
    "\n",
    "for L in [32, 64, 128] #, 256, 512]\n",
    "  m = train_model(L)\n",
    "  println(\"Model $L has $(sum([prod(size(p)) for p in Flux.params(m)])) parameters\")  \n",
    "  println(\"Sample from model $L\")\n",
    "  println(\"--------------------\")\n",
    "  println(sample(m, alphabet, 2000))\n",
    "  println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
