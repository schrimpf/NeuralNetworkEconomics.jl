<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>With Julia -  </title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">
        <link href="../assets/extra.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href=".."> </a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="..">Package Docs</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">ML in Economics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../ml-intro/">Introduction</a>
</li>
                                    
<li >
    <a href="../ml-methods/">Methods</a>
</li>
                                    
<li >
    <a href="../ml-doubledebiased/">Inference</a>
</li>
                                    
<li >
    <a href="../mlExamplePKH/">Detecting heterogeneity</a>
</li>
                                    
<li class="active">
    <a href="./">With Julia</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Neural Networks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../slp/">Introduction</a>
</li>
                                    
<li >
    <a href="../mlp/">Multi-Layer</a>
</li>
                                    
<li >
    <a href="../conv/">Convolutional</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../license/">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li >
                                <a rel="next" href="../mlExamplePKH/">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li >
                                <a rel="prev" href="../slp/">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl/edit/master/docs/ml-julia.md"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#about-this-document">About this document</a></li>
        <li class="main "><a href="#introduction">Introduction</a></li>
        <li class="main "><a href="#rcall">RCall</a></li>
        <li class="main "><a href="#mljjl">MLJ.jl</a></li>
        <li class="main "><a href="#fluxjl">Flux.jl</a></li>
        <li class="main "><a href="#additional-resources">Additional Resources</a></li>
        <li class="main "><a href="#references-references">References [references]</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h3 id="about-this-document">About this document<a class="headerlink" href="#about-this-document" title="Permanent link">&para;</a></h3>
<p>This document was created using Weave.jl. The code is available in <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl">on
github</a>. The same
document generates both static webpages and associated <a href="../ml-julia.ipynb">jupyter
notebook</a>.</p>
<p>
<script type="math/tex; mode=display">
\def\indep{\perp\!\!\!\perp}
\def\Er{\mathrm{E}}
\def\R{\mathbb{R}}
\def\En{{\mathbb{E}_n}}
\def\Pr{\mathrm{P}}
\newcommand{\norm}[1]{\left\Vert {#1} \right\Vert}
\newcommand{\abs}[1]{\left\vert {#1} \right\vert}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
</script>
</p>
<h1 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h1>
<p>This document is a companion to my <a href="../ml-intro/">“Machine learning in
economics”</a>. Those notes discuss the recent use of machine
learning in economics, with a focus on lasso and random forests. The
code in those notes is written in R. This document will look at similar
code in Julia.</p>
<h1 id="rcall">RCall<a class="headerlink" href="#rcall" title="Permanent link">&para;</a></h1>
<p>If you want to use the methods of Chernozhukov and coauthors implements
in the R packaga Chernozhukov, Hansen, and Spindler (<a href="#ref-hdm">2016</a>)
or the methods of Athey and coauthors implemented in the R package
Tibshirani et al. (<a href="#ref-grf">2018</a>) , then it makes sense to use the R
pacakge. You could simply write all your code in R. However, if you
prefer using Julia, you can just call the necessary R functions with
<a href="https://github.com/JuliaInterop/RCall.jl"><code>RCall.jl</code></a>.</p>
<p>Here, we load the pipeline data used in the <a href="../ml-methods/">machine learning methods
notes</a>, and do some cleaning in Julia.</p>
<pre><code class="julia">using RCall, DataFrames, Missings, Statistics
R&quot;load(paste($(docdir),\&quot;/rmd/pipelines.Rdata\&quot;,sep=\&quot;\&quot;))&quot;
println(R&quot;ls()&quot;)
</code></pre>

<pre><code>RObject{StrSxp}
[1] "#JL"  "data"
</code></pre>
<pre><code class="julia">data = @rget data # data on left is new Julia variable, data on right is the one in R
println(R&quot;summary(data[,1:5])&quot;)
</code></pre>

<pre><code>RObject{StrSxp}
 respondent_id     report_yr      report_prd     major        
 Min.   :  1.0   Min.   :1991   Min.   :12     Mode :logical  
 1st Qu.: 64.0   1st Qu.:1997   1st Qu.:12     FALSE:1192     
 Median :148.0   Median :2003   Median :12     TRUE :2797     
 Mean   :184.3   Mean   :2003   Mean   :12     NA's :2180     
 3rd Qu.:214.0   3rd Qu.:2010   3rd Qu.:12                    
 Max.   :745.0   Max.   :2016   Max.   :12                    
                                NA's   :3371                  
                             respondent_name
 Centra Pipelines Minnesota Inc.     :  22  
 Tuscarora Gas Transmission Company  :  22  
 Eastern Shore Natural Gas Company   :  22  
 Kern River Gas Transmission Company :  21  
 National Fuel Gas Supply Corporation:  21  
 (Other)                             :2938  
 NA's                                :3123
</code></pre>
<pre><code class="julia">println(describe(data[:,1:5]))
</code></pre>

<pre><code>5×8 DataFrame
│ Row │ variable        │ mean     │ min                                │ median │ max                                           │ nunique │ nmissing │ eltype                                    │
│     │ Symbol          │ Union…   │ Any                                │ Union… │ Any                                           │ Union…  │ Union…   │ Type                                      │
├─────┼─────────────────┼──────────┼────────────────────────────────────┼────────┼───────────────────────────────────────────────┼─────────┼──────────┼───────────────────────────────────────────┤
│ 1   │ respondent_id   │ 184.3    │ 1                                  │ 148.0  │ 745                                           │         │          │ Int64                                     │
│ 2   │ report_yr       │ 2003.49  │ 1991                               │ 2003.0 │ 2016                                          │         │          │ Int64                                     │
│ 3   │ report_prd      │ 12.0     │ 12                                 │ 12.0   │ 12                                            │         │ 3371     │ Union{Missing, Int64}                     │
│ 4   │ major           │ 0.701178 │ 0                                  │ 1.0    │ 1                                             │         │ 2180     │ Union{Missing, Bool}                      │
│ 5   │ respondent_name │          │ Algonquin Gas Transmission Company │        │ Southern Natural Gas Company                  │ 440     │ 3123     │ Union{Missing, CategoricalString{UInt32}} │
</code></pre>
<pre><code class="julia">for c in 59:107 # columns of state mileage, want missing-&gt;0
  replace!(x-&gt;(ismissing(x) || isnan(x)) ? 0.0 : x, data[!,c])
end
println(describe(data[:,59:65]))
</code></pre>

<pre><code>7×8 DataFrame
│ Row │ variable       │ mean       │ min     │ median  │ max      │ nunique │ nmissing │ eltype                  │
│     │ Symbol         │ Float64    │ Float64 │ Float64 │ Float64  │ Nothing │ Int64    │ Union                   │
├─────┼────────────────┼────────────┼─────────┼─────────┼──────────┼─────────┼──────────┼─────────────────────────┤
│ 1   │ North Carolina │ 0.00358525 │ 0.0     │ 0.0     │ 1.0      │         │ 0        │ Union{Missing, Float64} │
│ 2   │ Tennessee      │ 0.0061488  │ 0.0     │ 0.0     │ 0.635202 │         │ 0        │ Union{Missing, Float64} │
│ 3   │ Virginia       │ 0.00552028 │ 0.0     │ 0.0     │ 1.0      │         │ 0        │ Union{Missing, Float64} │
│ 4   │ Illinois       │ 0.0134891  │ 0.0     │ 0.0     │ 1.0      │         │ 0        │ Union{Missing, Float64} │
│ 5   │ Indiana        │ 0.0058707  │ 0.0     │ 0.0     │ 0.550302 │         │ 0        │ Union{Missing, Float64} │
│ 6   │ Kentucky       │ 0.0133474  │ 0.0     │ 0.0     │ 1.0      │         │ 0        │ Union{Missing, Float64} │
│ 7   │ Gulf of Mexico │ 0.0140981  │ 0.0     │ 0.0     │ 0.825409 │         │ 0        │ Union{Missing, Float64} │
</code></pre>
<p>Suppose we want to estimate the coefficient on <code>transPlant</code> (capital) in
a partially linear model with <code>transProfit</code> (profit) as the outcome.
This can be done with the R function <code>hdm::rlassoEffects</code>.</p>
<pre><code class="julia">R&quot;library(hdm)&quot;
completedata = dropmissing(data,[1:10..., 59:122...], disallowmissing=true)
y = completedata[:transProfit]
inc = .!isnan.(y)
y = y[inc]
X = completedata[inc,[6:7..., 59:121...]]
cols = [std(X[c])&gt;0 for c in 1:ncol(X)]
X = X[:,cols]
est = R&quot;rlassoEffects($(X), $(y), index=c(1:2))&quot;
R&quot;summary($est)&quot;
</code></pre>

<pre><code>RObject{VecSxp}
[1] "Estimates and significance testing of the effect of target variables"
                      Estimate. Std. Error t value Pr(&gt;|t|)    
transPlant_bal_end_yr  0.034434   0.008878   3.879 0.000105 ***
transPlant_bal_beg_yr  0.086580   0.009383   9.228  &lt; 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</code></pre>
<h1 id="mljjl">MLJ.jl<a class="headerlink" href="#mljjl" title="Permanent link">&para;</a></h1>
<p><a href="https://github.com/alan-turing-institute/MLJ.jl"><code>MLJ.jl</code></a> is a machine
learning framework for Julia. It gives a unified interface for many
machine learning algorithms and tasks. Similar R packages include
<code>caret</code> and <code>MLR</code>. <a href="https://scikit-learn.org/stable/"><code>scikit-learn</code></a> is
a similar Python package.</p>
<p>For more information on MLJ see</p>
<ul>
<li>
<p><a href="https://alan-turing-institute.github.io/MLJ.jl/stable/"><code>MLJ.jl docs</code></a></p>
</li>
<li>
<p><a href="https://alan-turing-institute.github.io/MLJTutorials/">MLJ
    tutorials</a></p>
</li>
</ul>
<p>You can see a list of models registered to work with <code>MLJ.jl</code> on
<a href="https://github.com/alan-turing-institute/MLJModels.jl/blob/master/src/registry/Models.toml">github</a>,
or by calling <code>MLJ::models()</code>.</p>
<pre><code class="julia">using MLJ
models()
</code></pre>

<pre><code>109-element Array{NamedTuple,1}:
 (name = ARDRegressor, package_name = ScikitLearn, ... )             
 (name = AdaBoostClassifier, package_name = ScikitLearn, ... )       
 (name = AdaBoostRegressor, package_name = ScikitLearn, ... )        
 (name = BaggingClassifier, package_name = ScikitLearn, ... )        
 (name = BaggingRegressor, package_name = ScikitLearn, ... )         
 (name = BayesianLDA, package_name = MultivariateStats, ... )        
 (name = BayesianLDA, package_name = ScikitLearn, ... )              
 (name = BayesianQDA, package_name = ScikitLearn, ... )              
 (name = BayesianRidgeRegressor, package_name = ScikitLearn, ... )   
 (name = BernoulliNBClassifier, package_name = ScikitLearn, ... )    
 ⋮                                                                   
 (name = Standardizer, package_name = MLJModels, ... )               
 (name = StaticTransformer, package_name = MLJModels, ... )          
 (name = TheilSenRegressor, package_name = ScikitLearn, ... )        
 (name = UnivariateBoxCoxTransformer, package_name = MLJModels, ... )
 (name = UnivariateDiscretizer, package_name = MLJModels, ... )      
 (name = UnivariateStandardizer, package_name = MLJModels, ... )     
 (name = XGBoostClassifier, package_name = XGBoost, ... )            
 (name = XGBoostCount, package_name = XGBoost, ... )                 
 (name = XGBoostRegressor, package_name = XGBoost, ... )
</code></pre>
<p>To use these models, you need the corresponding package to be installed
and loaded. The <code>@load</code> macro will load the needed package(s) for any
model.</p>
<pre><code class="julia">lasso_model = @load LassoRegressor pkg=MLJLinearModels
</code></pre>

<pre><code>LassoRegressor(lambda = 1.0,
               fit_intercept = true,
               penalize_intercept = false,
               solver = nothing,) @ 2…60
</code></pre>
<p>Let’s fit lasso to the same pipeline data as above.</p>
<pre><code class="julia">lasso_model.lambda = 1.0
lasso = machine(lasso_model, X, y)
train,test = partition(eachindex(y), 0.6, shuffle=true)
fit!(lasso, rows=train)
yhat = predict(lasso, rows=test)
println(yhat[1:10])
</code></pre>

<pre><code>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
</code></pre>
<pre><code class="julia">println(&quot;MSE/var(y) = $(mean((y[test].-yhat).^2)/var(y[test]))&quot;)
</code></pre>

<pre><code>MSE/var(y) = 1.4734944469534543
</code></pre>
<p>That doesn’t look very good. All the predictions are zero. This could
happen when the regularization parameter, <code>lambda</code>, is too large.
However, in this case the problem is something else. The warning
messages indicate numeric problems when minimizing the lasso objective
function. This can happen when <code>X</code> is poorly scaled. The algorithm used
to compute the lasso estimates works best when the coefficients are all
roughly the same scale. The existing <code>X</code>’s have wildly different scales,
which causes problems. This situation is common, so <code>MLJ.jl</code> has
functions to standardize variables. It is likely that the <code>hdm</code> package
in R does something similar internally.</p>
<pre><code class="julia">lasso_stdx = @pipeline PipeLasso(std=Standardizer(),
                  lasso=LassoRegressor(lambda=1.0*std(y),
                                       solver=MLJLinearModels.ISTA(max_iter=10000)
                                       )
                                 )
m = machine(lasso_stdx, X, y)
fit!(m, rows=train)
yhat = predict(m , rows=test)
println(&quot;MSE/var(y) = $(mean((y[test].-yhat).^2)/var(y[test]))&quot;)
</code></pre>

<pre><code>MSE/var(y) = 0.1302218664602367
</code></pre>
<pre><code class="julia">
# Get the fitted coefficients
coef = fitted_params(m).fitted_params[1].coefs
intercept = fitted_params(m).fitted_params[1].intercept
sum(abs.(coef).&gt;1e-8) # number non-zero
</code></pre>

<pre><code>56
</code></pre>
<p>If we want to tune <code>lambda</code> using cross-validation, we can use the
<code>range</code> and <code>TunedModel</code> functions.</p>
<pre><code class="julia">r = range(lasso_stdx, :(lasso.lambda), lower=1e1, upper=1e10, scale=:log)
t=TunedModel(model=lasso_stdx,
             resampling=CV(nfolds=5),
             tuning=Grid(resolution=10), 
             ranges=r,
             measure=rms)
m = machine(t, X, y)
fit!(m, rows=train, verbosity=1)
yhat = predict(m , rows=test)
println(&quot;MSE/var(y) = $(mean((y[test].-yhat).^2)/var(y[test]))&quot;)
</code></pre>

<pre><code>MSE/var(y) = 0.13170341963283844
</code></pre>
<pre><code class="julia">using Plots
cvmse = m.report.measurements
λ = Float64.(m.report.parameter_values[:])
plot(λ, cvmse, xlab=&quot;λ&quot;, ylab=&quot;CV(MSE)&quot;)
</code></pre>

<p><img alt="" src="../figures/ml-julia_9_1.png" /></p>
<h1 id="fluxjl">Flux.jl<a class="headerlink" href="#fluxjl" title="Permanent link">&para;</a></h1>
<p><a href="https://fluxml.ai/Flux.jl/stable/"><code>Flux.jl</code></a> is another Julia package
for machine learning. It seems to be emerging as the leading Julia
package for neural networks and deep learning, but other machine
learning models can also be implemented using <code>Flux.jl</code>.</p>
<p>Let’s create a lasso model in <code>Flux.jl</code>.</p>
<pre><code class="julia">using Flux, LinearAlgebra
# Scale the variables
Xstd = Flux.normalise(Matrix(X))
X_train = Xstd[train,:]
X_test = Xstd[test,:]
yscale = std(y)
ymean = mean(y)
ystd = (y .- ymean)./yscale
y_train = ystd[train]
y_test = ystd[test]

# Set up the model parameters and initial values
βols = (X_train'*X_train) \ (X_train'*(y_train .- mean(y_train)))
β = param(zeros(ncol(X))) #βols) #zeros(ncol(X)))
b = param([mean(y_train)])
θ = Tracker.Params([β,b])

# Define the loss function
ψ = ones(length(β))
λ = 2.0
pred(x) = b .+ x*β
mse(x,y) = mean( (pred(x) .- y).^2 )
penalty(y) = λ/length(y)*norm(ψ.*β,1)
loss(x,y) =  mse(x,y) + penalty(y)
@show loss(X_train,y_train)
</code></pre>

<pre><code>loss(X_train, y_train) = 1.017489917959785 (tracked)
</code></pre>
<pre><code class="julia">
# minimize loss
maxiter=2000
obj = zeros(maxiter)
mse_train = zeros(maxiter)
mse_test = zeros(maxiter)
for i in 1:maxiter
  Flux.train!(loss, θ, [(X_train, y_train)], Flux.AMSGrad())
  mse_train[i] = Tracker.data(mse(X_train,y_train))
  mse_test[i] = Tracker.data(mse(X_test, y_test))
  obj[i] = Tracker.data(loss(X_train,y_train))
end
lo = 1
hi = 250
plot(obj[lo:hi], ylab=&quot;Loss=MSE + λ/n*||β||₁&quot;, xlab=&quot;Iteration&quot;)
</code></pre>

<p><img alt="" src="../figures/ml-julia_10_1.png" /></p>
<pre><code class="julia">plot(lo:hi, [mse_train[lo:hi] mse_test[lo:hi]], ylab=&quot;MSE&quot;, xaxis=(&quot;Iteration&quot;)
     , lab=[&quot;Train&quot; &quot;Test&quot;])
</code></pre>

<p><img alt="" src="../figures/ml-julia_11_1.png" /></p>
<p>The minimization methods in <code>Flux.train!</code> are all variants of gradient
descent. Each call to <code>Flux.train!</code> runs one iteration of the specified
solver. To find a locaol minimum, <code>Flux.train!</code> can be called repeatedly
until progress stops. The above loop is a simple way to do this. The
<code>@epoch</code> macro can also be useful.</p>
<p>Gradient descent works well for neural networks, but is not ideal for
Lasso. Without further adjustment, gradient descent gets stuck in a
cycle as jumps from one side of the other of the absolute value in the
lasso penalty. Nonetheless, the results are near the true minimum, even
though it never exactly gets there.</p>
<h1 id="additional-resources">Additional Resources<a class="headerlink" href="#additional-resources" title="Permanent link">&para;</a></h1>
<ul>
<li>Klok and Nazarathy (<a href="#ref-klok2019">2019</a>) <em>Statistics with
    Julia:Fundamentals for Data Science, MachineLearning and Artificial
    Intelligence</em></li>
</ul>
<h1 id="references-references">References [references]<a class="headerlink" href="#references-references" title="Permanent link">&para;</a></h1>
<div class="references" id="refs">
<div id="ref-hdm">
<p>Chernozhukov, Victor, Chris Hansen, and Martin Spindler. 2016. “hdm:
High-Dimensional Metrics.” <em>R Journal</em> 8 (2): 185–99.
<a href="https://journal.r-project.org/archive/2016/RJ-2016-040/index.html">https://journal.r-project.org/archive/2016/RJ-2016-040/index.html</a>.</p>
</div>
<div id="ref-klok2019">
<p>Klok, Hayden, and Yoni Nazarathy. 2019. <em>Statistics with
Julia:Fundamentals for Data Science, Machinelearning and Artificial
Intelligence</em>. DRAFT.
<a href="https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf">https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf</a>.</p>
</div>
<div id="ref-grf">
<p>Tibshirani, Julie, Susan Athey, Stefan Wager, Rina Friedberg, Luke
Miner, and Marvin Wright. 2018. <em>Grf: Generalized Random Forests
(Beta)</em>. <a href="https://CRAN.R-project.org/package=grf">https://CRAN.R-project.org/package=grf</a>.</p>
</div>
</div></div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
