<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>With Julia -  </title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">
        <link href="../assets/extra.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href=".."> </a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Package Docs</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">ML in Economics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../ml-intro/" class="dropdown-item">Introduction</a>
</li>
                                    
<li>
    <a href="../ml-methods/" class="dropdown-item">Methods</a>
</li>
                                    
<li>
    <a href="../ml-doubledebiased/" class="dropdown-item">Inference</a>
</li>
                                    
<li>
    <a href="../mlExamplePKH/" class="dropdown-item">Detecting heterogeneity</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">With Julia</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Neural Networks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../slp/" class="dropdown-item">Introduction</a>
</li>
                                    
<li>
    <a href="../mlp/" class="dropdown-item">Multi-Layer</a>
</li>
                                    
<li>
    <a href="../conv/" class="dropdown-item">Convolutional</a>
</li>
                                    
<li>
    <a href="../rnn/" class="dropdown-item">Recurrent</a>
</li>
                                    
<li>
    <a href="../transformers/" class="dropdown-item">Transformers</a>
</li>
                                    
<li>
    <a href="../nn-semiparametric/" class="dropdown-item">In semiparametric models</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../license/" class="dropdown-item">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../mlExamplePKH/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../slp/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl/edit/master/docs/ml-julia.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            
            <li class="nav-item" data-level="1"><a href="#introduction" class="nav-link">Introduction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#rcall" class="nav-link">RCall</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#mljjl" class="nav-link">MLJ.jl</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#fluxjl" class="nav-link">Flux.jl</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#luxjl" class="nav-link">Lux.jl</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#additional-resources" class="nav-link">Additional Resources</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#references" class="nav-link">References</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h3 id="about-this-document">About this document<a class="headerlink" href="#about-this-document" title="Permanent link">&para;</a></h3>
<p>This document was created using Weave.jl. The code is available in <a href="https://github.com/schrimpf/NeuralNetworkEconomics.jl">on
github</a>. The same
document generates both static webpages and associated <a href="../ml-julia.ipynb">jupyter
notebook</a>.</p>
<p>
<script type="math/tex; mode=display">
\def\indep{\perp\!\!\!\perp}
\def\Er{\mathrm{E}}
\def\R{\mathbb{R}}
\def\En{{\mathbb{E}_n}}
\def\Pr{\mathrm{P}}
\newcommand{\norm}[1]{\left\Vert {#1} \right\Vert}
\newcommand{\abs}[1]{\left\vert {#1} \right\vert}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
</script>
</p>
<h1 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h1>
<p>This document is a companion to my <a href="../ml-intro/">“Machine learning in
economics”</a>. Those notes discuss the recent use of machine
learning in economics, with a focus on lasso and random forests. The
code in those notes is written in R. This document will look at similar
code in Julia.</p>
<h1 id="rcall">RCall<a class="headerlink" href="#rcall" title="Permanent link">&para;</a></h1>
<p>If you want to use the methods of Chernozhukov and coauthors implements
in the R packaga @hdm or the methods of Athey and coauthors implemented
in the R package @grf , then it makes sense to use the R pacakge. You
could simply write all your code in R. However, if you prefer using
Julia, you can just call the necessary R functions with
<a href="https://github.com/JuliaInterop/RCall.jl"><code>RCall.jl</code></a>.</p>
<p>Here, we load the pipeline data used in the <a href="../ml-methods/">machine learning methods
notes</a>, and do some cleaning in Julia.</p>
<pre><code class="language-julia">using RCall, DataFrames, Missings, Statistics
R&quot;load(paste($(docdir),\&quot;/rmd/pipelines.Rdata\&quot;,sep=\&quot;\&quot;))&quot;
println(R&quot;ls()&quot;)
data = @rget data # data on left is new Julia variable, data on right is the one in R
println(R&quot;summary(data[,1:5])&quot;)
println(describe(data[:,1:5]))
for c in 59:107 # columns of state mileage, want missing-&gt;0
  replace!(x-&gt;(ismissing(x) || isnan(x)) ? 0.0 : x, data[!,c])
end
println(describe(data[:,59:65]))
</code></pre>
<pre><code>Error: InitError: Try adding /usr/lib64/R/lib to the "LD_LIBRARY_PATH" environmental variable and restarting Julia.
during initialization of module RCall
</code></pre>
<p>Suppose we want to estimate the coefficient on <code>transPlant</code> (capital) in
a partially linear model with <code>transProfit</code> (profit) as the outcome.
This can be done with the R function <code>hdm::rlassoEffects</code>.</p>
<pre><code class="language-julia">R&quot;library(hdm)&quot;
completedata = dropmissing(data,[1:10..., 59:122...], disallowmissing=true)
y = completedata[!,:transProfit]
inc = .!isnan.(y)
y = y[inc]
X = completedata[inc,[6:7..., 59:121...]]
cols = [std(X[!,c])&gt;0 for c in 1:ncol(X)]
X = X[:,cols]
est = R&quot;rlassoEffects($(X), $(y), index=c(1:2))&quot;
R&quot;summary($est)&quot;
</code></pre>
<pre><code>Error: LoadError: UndefVarError: @R_str not defined
in expression starting at /home/paul/.julia/dev/NeuralNetworkEconomics/docs/jmd/ml-julia.jmd:2
</code></pre>
<h1 id="mljjl">MLJ.jl<a class="headerlink" href="#mljjl" title="Permanent link">&para;</a></h1>
<p><a href="https://github.com/alan-turing-institute/MLJ.jl"><code>MLJ.jl</code></a> is a machine
learning framework for Julia. It gives a unified interface for many
machine learning algorithms and tasks. Similar R packages include
<code>caret</code> and <code>MLR</code>. <a href="https://scikit-learn.org/stable/"><code>scikit-learn</code></a> is
a similar Python package.</p>
<p>For more information on MLJ see</p>
<ul>
<li>
<p><a href="https://alan-turing-institute.github.io/MLJ.jl/stable/"><code>MLJ.jl docs</code></a></p>
</li>
<li>
<p><a href="https://alan-turing-institute.github.io/MLJTutorials/">MLJ
    tutorials</a></p>
</li>
</ul>
<p>You can see a list of models registered to work with <code>MLJ.jl</code> on
<a href="https://github.com/alan-turing-institute/MLJModels.jl/blob/master/src/registry/Models.toml">github</a>,
or by calling <code>MLJ::models()</code>.</p>
<pre><code class="language-julia">using MLJ
models()
</code></pre>
<pre><code>200-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstr
act_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hy
perparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_
methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteratio
n_parameter, :load_path, :package_license, :package_url, :package_uuid, :pr
edict_scitype, :prediction_type, :reporting_operations, :reports_feature_im
portances, :supports_class_weights, :supports_online, :supports_training_lo
sses, :supports_weights, :transform_scitype, :input_scitype, :target_scityp
e, :output_scitype)}}:
 (name = ABODDetector, package_name = OutlierDetectionNeighbors, ... )
 (name = ABODDetector, package_name = OutlierDetectionPython, ... )
 (name = AEDetector, package_name = OutlierDetectionNetworks, ... )
 (name = ARDRegressor, package_name = ScikitLearn, ... )
 (name = AdaBoostClassifier, package_name = ScikitLearn, ... )
 (name = AdaBoostRegressor, package_name = ScikitLearn, ... )
 (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )
 (name = AffinityPropagation, package_name = ScikitLearn, ... )
 (name = AgglomerativeClustering, package_name = ScikitLearn, ... )
 (name = BM25Transformer, package_name = MLJText, ... )
 ⋮
 (name = TheilSenRegressor, package_name = ScikitLearn, ... )
 (name = UnivariateBoxCoxTransformer, package_name = MLJModels, ... )
 (name = UnivariateDiscretizer, package_name = MLJModels, ... )
 (name = UnivariateFillImputer, package_name = MLJModels, ... )
 (name = UnivariateStandardizer, package_name = MLJModels, ... )
 (name = UnivariateTimeTypeToContinuous, package_name = MLJModels, ... )
 (name = XGBoostClassifier, package_name = XGBoost, ... )
 (name = XGBoostCount, package_name = XGBoost, ... )
 (name = XGBoostRegressor, package_name = XGBoost, ... )
</code></pre>
<p>To use these models, you need the corresponding package to be installed
and loaded. The <code>@load</code> macro will load the needed package(s) for any
model.</p>
<pre><code class="language-julia">Lasso = @load LassoRegressor pkg=MLJLinearModels
</code></pre>
<pre><code>import MLJLinearModels ✔
MLJLinearModels.LassoRegressor
</code></pre>
<p>Let’s fit lasso to the same pipeline data as above.</p>
<pre><code class="language-julia">lasso = machine(Lasso(lambda=1.0), X, y)
train,test = partition(eachindex(y), 0.6, shuffle=true)
fit!(lasso, rows=train)
yhat = predict(lasso, rows=test)
println(yhat[1:10])
println(&quot;MSE/var(y) = $(mean((y[test].-yhat).^2)/var(y[test]))&quot;)
</code></pre>
<pre><code>Error: UndefVarError: X not defined
</code></pre>
<p>That doesn’t look very good. All the predictions are zero. This could
happen when the regularization parameter, <code>lambda</code>, is too large.
However, in this case the problem is something else. The warning
messages indicate numeric problems when minimizing the lasso objective
function. This can happen when <code>X</code> is poorly scaled. The algorithm used
to compute the lasso estimates works best when the coefficients are all
roughly the same scale. The existing <code>X</code>’s have wildly different scales,
which causes problems. This situation is common, so <code>MLJ.jl</code> has
functions to standardize variables. It is likely that the <code>hdm</code> package
in R does something similar internally.</p>
<pre><code class="language-julia">lasso_stdx = Pipeline(Standardizer(),
                      Lasso(lambda=1.0*std(y[train]),
                            solver=MLJLinearModels.ISTA(max_iter=10000))
                      )
m = machine(lasso_stdx, X, y)
fit!(m, rows=train, force=true)
yhat = predict(m , rows=test)
println(&quot;MSE/var(y) = $(mean((y[test].-yhat).^2)/var(y[test]))&quot;)

# Get the fitted coefficients
coef = fitted_params(m).lasso_regressor.coefs
intercept = fitted_params(m).lasso_regressor.intercept
sum(abs(c[2])&gt;1e-8 for c in coef) # number non-zero
</code></pre>
<pre><code>Error: UndefVarError: y not defined
</code></pre>
<p>If we want to tune <code>lambda</code> using cross-validation, we can use the
<code>range</code> and <code>TunedModel</code> functions.</p>
<pre><code class="language-julia">r = range(lasso_stdx, :(lasso_regressor.lambda), lower=1e1, upper=1e10, scale=:log)
t=TunedModel(model=lasso_stdx,
             resampling=CV(nfolds=5),
             tuning=Grid(resolution=10),
             ranges=r,
             measure=rms)
m = machine(t, X, y)
fit!(m, rows=train, verbosity=1)
yhat = predict(m , rows=test)
println(&quot;MSE/var(y) = $(mean((y[test].-yhat).^2)/var(y[test]))&quot;)
</code></pre>
<pre><code>Error: UndefVarError: lasso_stdx not defined
</code></pre>
<pre><code class="language-julia">using Plots
cvmse = m.report.plotting.measurements
λ = Float64.(m.report.plotting.parameter_values[:])
s = sortperm(λ)
plot(λ[s], cvmse[s], xlab=&quot;λ&quot;, ylab=&quot;CV(MSE)&quot;)
</code></pre>
<pre><code>Error: UndefVarError: m not defined
</code></pre>
<h1 id="fluxjl">Flux.jl<a class="headerlink" href="#fluxjl" title="Permanent link">&para;</a></h1>
<p><a href="https://fluxml.ai/Flux.jl/stable/"><code>Flux.jl</code></a> is another Julia package
for machine learning. It seems to be emerging as the leading Julia
package for neural networks and deep learning, but other machine
learning models can also be implemented using <code>Flux.jl</code>.</p>
<p>Let’s create a lasso model in <code>Flux.jl</code>.</p>
<pre><code class="language-julia">using Flux, LinearAlgebra
# Scale the variables
Xstd = Flux.normalise(Matrix(X), dims=1)
X_train = Xstd[train,:]
X_test = Xstd[test,:]
yscale = std(y[train])
ymean = mean(y[train])
ystd = (y .- ymean)./yscale
y_train = ystd[train]
y_test = ystd[test]

# Set up the model parameters and initial values
βols = (X_train'*X_train) \ (X_train'*(y_train .- mean(y_train)))
β = zeros(ncol(X))
b = [mean(y_train)]

# Define the loss function
ψ = ones(length(β))
λ = 2.0
pred(x) = b .+ x*β
mse(x,y) = mean( (pred(x) .- y).^2 )
penalty(y) = λ/length(y)*norm(ψ.*β,1)
loss(x,y) =  mse(x,y) + penalty(y)
@show loss(X_train,y_train)

# minimize loss
maxiter=2000
obj = zeros(maxiter)
mse_train = zeros(maxiter)
mse_test = zeros(maxiter)
opt = Flux.AMSGrad()
for i in 1:maxiter
  Flux.train!(loss, Flux.params(β, b), [(X_train, y_train)], opt)
  mse_train[i] = mse(X_train,y_train)
  mse_test[i] = mse(X_test, y_test)
  obj[i] = loss(X_train,y_train)
end
lo = 1
hi = 2000
plot(obj[lo:hi], ylab=&quot;Loss=MSE + λ/n*||β||₁&quot;, xlab=&quot;Iteration&quot;)
</code></pre>
<pre><code>Error: UndefVarError: X not defined
</code></pre>
<pre><code class="language-julia">plot(lo:hi, [mse_train[lo:hi] mse_test[lo:hi]], ylab=&quot;MSE&quot;, xaxis=(&quot;Iteration&quot;), lab=[&quot;Train&quot; &quot;Test&quot;])
</code></pre>
<pre><code>Error: UndefVarError: lo not defined
</code></pre>
<p>The minimization methods in <code>Flux.train!</code> are all variants of gradient
descent. Each call to <code>Flux.train!</code> runs one iteration of the specified
solver. To find a local minimum, <code>Flux.train!</code> can be called repeatedly
until progress stops. The above loop is a simple way to do this. The
<code>@epoch</code> macro can also be useful.</p>
<p>Gradient descent works well for neural networks, but is not ideal for
Lasso. Without further adjustment, gradient descent gets stuck in a
cycle as jumps from one side of the other of the absolute value in the
lasso penalty. Nonetheless, the results are near the true minimum, even
though it never exactly gets there.</p>
<h1 id="luxjl">Lux.jl<a class="headerlink" href="#luxjl" title="Permanent link">&para;</a></h1>
<p>A promising alternative to <code>Flux.jl</code> is
<a href="http://lux.csail.mit.edu/dev/"><code>Lux.jl</code></a>.<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup> <code>Lux.jl</code> and <code>Flux.jl</code>
share many features and backend code. <code>Lux.jl</code> has a more function
focused interface with explicit parameter passing. This is a more
“Julian” style of programming.<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup></p>
<p>For comparison, let’s implement the same Lasso model in Lux.</p>
<pre><code class="language-julia">import Lux # Lux shares many function names with Flux, so import instead of using to avoid confusion
import Random, Zygote
using Test
# Seeding
rng = Random.default_rng()
Random.seed!(rng, 0)

# define the model

X_train = Matrix(X)[train,:]
X_test = Matrix(X)[test,:]
y_train = y[train]
y_test = y[test]
function standardizer(xtrain)
  m = std(xtrain, dims=1)
  s = std(xtrain, dims=1)
  (x-&gt;(x .- m)./s , xs-&gt;xs.*s .+ m)
end
stdizex, _ = standardizer(X_train)
stdizey, unstdizey = standardizer(y_train)
@test unstdizey(stdizey(y_test)) ≈ y_test

ys = stdizey(y_train)
Xs = stdizex(X_train)
# Set up the model parameters and initial values
βols = (Xs'*Xs) \ (Xs'*(ys .- mean(ys)))
b = [mean(ys)]

m = Lux.Chain(X-&gt;stdizex(X)', 
  Lux.Dense(size(X_train,2), 1, init_weight=zeros, init_bias=zeros)
  )

ps, st = Lux.setup(rng, m)
ps.layer_2.weight .= βols'
ps.layer_2.bias .= b

mse(m, ps, st, X, y) = mean(abs2, m(X, ps, st)[1]' .- stdizey(y))
mseraw(m,ps,st,X,y) = mean(abs2, unstdizey(m(X, ps, st)[1]') .- y)
ℓ = let λ = 2.0, ψ = ones(size(βols')), st=st
  penalty(ps,y) = λ/length(y)*norm(ψ.*ps.layer_2.weight,1)
  loss(ps, X, y, m) = mse(m, ps, st, X, y) + penalty(ps,y)
end

@show ℓ(ps,X_train,y_train,m)

# minimize loss
opt = Lux.Optimisers.AMSGrad() #ADAM(0.001)
optstate = Lux.Optimisers.setup(opt, ps)
maxiter=2000
obj = zeros(maxiter)
mse_train = zeros(maxiter)
mse_test = zeros(maxiter)
for i in 1:maxiter
    # Compute the gradient
    gs = Zygote.gradient(ps-&gt;ℓ(ps, X_train, y_train, m), ps)[1]
    # Perform parameter update
    optstate, ps = Lux.Optimisers.update(optstate, ps, gs)
    mse_train[i] = mse(m, ps, st, X_train,y_train)
    mse_test[i] = mse(m, ps, st, X_test, y_test)
    obj[i] = ℓ(ps,X_train,y_train,m)
end
lo = 1
hi = 250
plot(lo:hi,obj[lo:hi], ylab=&quot;Loss=MSE + λ/n*||β||₁&quot;, xlab=&quot;Iteration&quot;)
</code></pre>
<pre><code>Error: UndefVarError: X not defined
</code></pre>
<h1 id="additional-resources">Additional Resources<a class="headerlink" href="#additional-resources" title="Permanent link">&para;</a></h1>
<ul>
<li>@klok2019 <em>Statistics with Julia:Fundamentals for Data Science,
    MachineLearning and Artificial Intelligence</em></li>
</ul>
<h1 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h1>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>These notes were originally written before Lux.jl existed. If I
were starting over, I would use Lux.jl instead of Flux.jl.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p><code>Flux.jl</code> drew inspiration for its interface from Tensorflow and
PyTorch. Implicit parameters makes some sense in an object oriented
language like Python, but it is not the most natural style for
Julia.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
